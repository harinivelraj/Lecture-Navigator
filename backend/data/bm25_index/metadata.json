[
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 0.0,
    "t_end": 30.0,
    "text": "I'm sure you all agree\nthat machine learning is one of the hottest Trend in today's\nmarket right Gartner predicts that by 2022 there\nwould be at least 40% of new application development\nproject going on in the market that would be requiring\nmachine learning co-developers on their team. It's expected that these project\nwill generate a revenue of around three point\nnine trillion dollar, isn't it cute so\nlooking at the huge? Upcoming demand of machine\nlearning around the world.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25.0,
    "t_end": 55.0,
    "text": "It's expected that these project\nwill generate a revenue of around three point\nnine trillion dollar, isn't it cute so\nlooking at the huge? Upcoming demand of machine\nlearning around the world. We guys at Eureka have come up and designed a well-structured\nmachine learning full course for you guys. But before we actually\ndrill down over there, let me just introduce myself. Hello all I am Atul from Edureka. And today I'll be guiding you through this entire\nmachine learning course. Well, this course\nhas been designed in a way that you get the most out of it. So we'll slowly\nand gradually start with a beginner level and then\nmove towards the advanced topic.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 50.0,
    "t_end": 80.0,
    "text": "that you get the most out of it. So we'll slowly\nand gradually start with a beginner level and then\nmove towards the advanced topic. So without delaying any further, let's start with the agenda\nof today's Action on machine learning\ncourse has been segregated into six different module\nwill start our first module with introduction to\nmachine learning here. We'll discuss things. Like what exactly\nis machine learning how it differs from artificial\nintelligence and the planning what is various types\nor dead space application and finally we'll end\nup first module with a basic demo and python.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 75.0,
    "t_end": 105.0,
    "text": "how it differs from artificial\nintelligence and the planning what is various types\nor dead space application and finally we'll end\nup first module with a basic demo and python. Okay a second module\nfocuses on starts and probability here\nwill cover things like descriptive statistics and\ninferential statistics to Bob. Rarity Theory and so on our third module\nis unsupervised learning. Well supervised learning is one\nof a type of machine learning which focuses mainly on regression and\nclassification type of problem. It deals with label data sets\nand the algorithm which are a part of it\nare linear regression",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 100.0,
    "t_end": 130.0,
    "text": "on regression and\nclassification type of problem. It deals with label data sets\nand the algorithm which are a part of it\nare linear regression logistic regression Napier's\nrandom Forest decision tree and so on. Our fourth module is\non unsupervised learning. Well this module focuses\nmainly on dealing with unlabeled data sets and the algorithm\nwhich are a part. Offered or k-means algorithm and a priori algorithm as\na part of fifth module. We have reinforcement\nlearning here. We are going to discuss\nabout reinforcement learning and depth on also",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 125.0,
    "t_end": 155.0,
    "text": "We have reinforcement\nlearning here. We are going to discuss\nabout reinforcement learning and depth on also about Q learning algorithm\nfinally in the end. It's all about to make\nyou industry ready. Okay. So here we are going to discuss\nabout three different projects which are based\non supervised learning and unsupervised learning and reinforcement learning\nfinally in the end. I tell you about some\nof the skills that you need to become\na machine learnings and Jean. Nia okay, and also I\nam discussing about some of the important questions that are asked in a\nmachine-learning interview fine",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 150.0,
    "t_end": 180.0,
    "text": "that you need to become\na machine learnings and Jean. Nia okay, and also I\nam discussing about some of the important questions that are asked in a\nmachine-learning interview fine with this we come\nto the end of this agenda before you move ahead don't forget to subscribe\nto a dareka and press the Bell icon to never miss\nany update from us. Hello everyone. This is a toll from Eureka and welcome to today's session\non what is machine learning. As you know, we are living\nin a world of humans and machines humans\nhave been evolving",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 175.0,
    "t_end": 205.0,
    "text": "and welcome to today's session\non what is machine learning. As you know, we are living\nin a world of humans and machines humans\nhave been evolving and learning from the past\nexperience since millions of years on the other hand\nthe era of machines and robots have just\nbegun in today's world. These machines are\nthe rewards are like they need to be program before they actually\nfollow your instructions. But what if the machine\nstarted to learn on their own and this is where machine learning comes into picture machine\nlearning is the core of many futuristic technology\nadvancement in our world.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 200.0,
    "t_end": 230.0,
    "text": "where machine learning comes into picture machine\nlearning is the core of many futuristic technology\nadvancement in our world. And today you can\nsee various examples or implementation of\nmachine learning around us such as Tesla's self-driving\ncar Apple Siri, Sophia. I do bot and many\nmore are there. So what exactly\nis machine learning? Well Machine learning\nis a subfield of artificial intelligence that focuses on\nthe design of system that can learn from\nand make decisions and predictions based\non the experience which is data in the case\nof machines machine learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 225.0,
    "t_end": 255.0,
    "text": "that focuses on\nthe design of system that can learn from\nand make decisions and predictions based\non the experience which is data in the case\nof machines machine learning enables computer to act and make data-driven\ndecisions rather than Being explicitly programmed to carry out a certain\ntask these programs are designed to learn and improve over time when exposed to new data. Let's move on and discuss one of the biggest confusion\nof the people in the world. They think that all\nthe three of them the AI the machine learning and\nthe Deep learning all are same,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 250.0,
    "t_end": 280.0,
    "text": "They think that all\nthe three of them the AI the machine learning and\nthe Deep learning all are same, you know, what they are wrong. Let me clarify things for you artificial intelligence\nis a broader concept of machines being able to carry\nout tasks in a smarter way. It covers anything which enables\nthe computer to be. Have like humans think of a\nfamous Turing test to determine whether a computer is\ncapable of thinking like a human being or not. If you are talking\nto Siri on your phone and you get an answer you're\nalready very close to it. So this was about the artificial\nintelligence now coming",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 275.0,
    "t_end": 305.0,
    "text": "If you are talking\nto Siri on your phone and you get an answer you're\nalready very close to it. So this was about the artificial\nintelligence now coming to the machine learning part. So as I already said\nmachine learning is a subset or a current application\nof AI it is based on the idea that we should be able\nto give machine the access to data and let them learn\nfrom done cells. It's a subset\nof artificial intelligence. Is that deals with the extraction\nof pattern from data set? This means that the machine\ncan not only find the rules for optimal Behavior, but also can adapt\nto the changes in the world many",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 300.0,
    "t_end": 330.0,
    "text": "This means that the machine\ncan not only find the rules for optimal Behavior, but also can adapt\nto the changes in the world many of the algorithms\ninvolved have been known for decades centuries\neven thanks to the advances in the computer science\nand parallel Computing. They can now scale up\nto massive data volumes. So this was about the machine\nlearning part now coming over to deep learning deep learning\nis a subset of machine learning where similar machine learning. Tamar used to train\ndeep neural network. So as to achieve better\naccuracy in those cases",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 325.0,
    "t_end": 355.0,
    "text": "where similar machine learning. Tamar used to train\ndeep neural network. So as to achieve better\naccuracy in those cases where former was not performing\nup to the mark, right? I hope now you understood\nthat machine learning Ai and deep learning\nall three are different. Okay moving on ahead. Let's see in general\nhow a machine learning work. One of the approaches is where the machine learning\nalgorithm is strained using a labeled\nor unlabeled training data set to produce a model new input data is introduced to\nthe machine learning algorithm and it make prediction\nbased on the model.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 350.0,
    "t_end": 380.0,
    "text": "using a labeled\nor unlabeled training data set to produce a model new input data is introduced to\nthe machine learning algorithm and it make prediction\nbased on the model. The prediction is\nevaluated for accuracy. And if the accuracy\nis acceptable the machine learning algorithm is deployed. Now if the accuracy\nis not acceptable the machine learning\nalgorithm is strained again, and again with an argument\na training data set. This was just\nin high-level example as they are many more factor\nand other steps involved in it. Now, let's move on\nand subcategorize the Machine learning into three different\ntypes the supervised learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 375.0,
    "t_end": 405.0,
    "text": "as they are many more factor\nand other steps involved in it. Now, let's move on\nand subcategorize the Machine learning into three different\ntypes the supervised learning and unsupervised learning\nand reinforcement learning and let's see what each\nof them are how they work. Work and how each of them is used in the field\nof banking Healthcare retail and other domains. Don't worry. I'll make sure that I use enough examples\nand implementation of all three of them to give you\na proper understanding of it. So starting with\nsupervised learning. What is it? So let's see\na mathematical definition of supervised learning\nsupervised learning is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 400.0,
    "t_end": 430.0,
    "text": "So starting with\nsupervised learning. What is it? So let's see\na mathematical definition of supervised learning\nsupervised learning is where you have input variables X\nand an output variable Y and you use an algorithm\nto learn the mapping function from the input to the output. That is y Affects the goal is to approximate\nthe mapping function. So well that whenever\nyou have a new input data X you could predict\nthe output variable. That is why\nfor that data, right? I think this\nwas confusing for you. Let me simplify the definition\nof supervised learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 425.0,
    "t_end": 455.0,
    "text": "That is why\nfor that data, right? I think this\nwas confusing for you. Let me simplify the definition\nof supervised learning so we can rephrase\nthe understanding of the mathematical definition\nas a machine learning method where each instances of\na training data set is composed of different input attribute and an expected output\nthe input attributes of a training data set can be\nof any End of data it can be a pixel of the image. It can be a value\nof a data base row or it can even be an audio\nfrequency histogram right for each input instance",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 450.0,
    "t_end": 480.0,
    "text": "It can be a value\nof a data base row or it can even be an audio\nfrequency histogram right for each input instance and expected output values Associated value can be discreet\nrepresenting a category or can be a real or continuous\nvalue in either case. The algorithm learns\nthe input pattern that generate the\nexpected output now once the algorithm is strain, it can be used to predict\nthe correct output of a never seen input. You can see I image\non your screen right in this image. And see that we are feeding\nraw inputs as image of Apple",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 475.0,
    "t_end": 505.0,
    "text": "You can see I image\non your screen right in this image. And see that we are feeding\nraw inputs as image of Apple to the algorithm as a part\nof the algorithm. We have a supervisor\nwho keeps on correcting the machine or who keeps\non training the machine. It keeps on telling him\nthat yes, it is a Apple. No, it is not an apple\nthings like that. So this process keeps on repeating until we\nget a final train model. Once the model is ready. It can easily predict\nthe correct output of a never seen input\nin this slide. You can see that we are giving an image\nof a green apple to the machine",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 500.0,
    "t_end": 530.0,
    "text": "It can easily predict\nthe correct output of a never seen input\nin this slide. You can see that we are giving an image\nof a green apple to the machine and the Machine can easily\nidentify it as yes, it is an apple and it is giving\nthe correct result right? Let me make things\nmore clearer to you. Let's discuss another\nexample of it. So in this Slide, the image shows an example of a supervised learning process\nused to produce a model which is capable of recognizing\nthe ducks in the image. The training data set\nis composed of labeled picture of ducks and non Ducks.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 525.0,
    "t_end": 555.0,
    "text": "which is capable of recognizing\nthe ducks in the image. The training data set\nis composed of labeled picture of ducks and non Ducks. The result of supervised\nlearning process is a predictor model which is capable\nof associating a label duck. Or not duck to the new image\npresented to the model. Now one strain, the resulting predictive\nmodel can be deployed to the production environment. You can see a mobile app. For example once deployed\nit is ready to recognize the new pictures right now. You might be wondering\nwhy this category of machine learning is named\nas supervised learning.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 550.0,
    "t_end": 580.0,
    "text": "the new pictures right now. You might be wondering\nwhy this category of machine learning is named\nas supervised learning. Well, it is called\na supervised learning because the process\nof an algorithm learning from the training data\nset can be thought of as a teacher supervising\nthe learning process if we know the correct answers. I will go Rhythm\niteratively makes while predicting on\nthe training data and is corrected by\nthe teacher the learning stops when the algorithm achieves an\nacceptable level of performance. Now, let's move on and see some of the popular supervised\nlearning algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 575.0,
    "t_end": 605.0,
    "text": "when the algorithm achieves an\nacceptable level of performance. Now, let's move on and see some of the popular supervised\nlearning algorithm. So we have linear\nregression random forest and support Vector machines. These are just\nfor your information. We will discuss\nabout these algorithms in our next video. Now, let's see some\nof the popular use cases of supervised learning so we have Donna codon\nor any other speech Automation in your mobile\nphone trains using your voice and one strain it start working\nbased on the training.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 600.0,
    "t_end": 630.0,
    "text": "Automation in your mobile\nphone trains using your voice and one strain it start working\nbased on the training. This is an application\nof supervised learning suppose. You are telling\nOK Google call Sam or you say Hey Siri call\nSam you get an answer to it and action is performed and automatically\na call goes to Sam. So these are just an example of supervised learning next\ncomes the weather up based on some\nof the prior knowledge like when it is sunny\nthe temperature is high. Fire when it is cloudy humidity\nis higher any kind of that they",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 625.0,
    "t_end": 655.0,
    "text": "like when it is sunny\nthe temperature is high. Fire when it is cloudy humidity\nis higher any kind of that they predict the parameters\nfor a given time. So this is also an example\nof supervised learning as we are feeding the data\nto the machine and telling that whenever it is sunny. The temperature should be higher\nwhenever it is cloudy. The humidity should be higher. So it's an example\nof supervised learning. Another example is\nbiometric attendance where you train the machine\nand after couple of inputs of your biometric identity\nbeat your thumb your iris or yellow or anything",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 650.0,
    "t_end": 680.0,
    "text": "where you train the machine\nand after couple of inputs of your biometric identity\nbeat your thumb your iris or yellow or anything once trained Machine gun\nvalidate your future input and can identify you next comes\nin the field of banking sector in banking sector supervised learning is used\nto predict the credit worthiness of a credit card holder by building a machine\nlearning model to look for faulty attributes\nby providing it with a data on deliquent and non-delinquent customers. Next comes the healthcare sector\nin the healthcare sector.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 675.0,
    "t_end": 705.0,
    "text": "and non-delinquent customers. Next comes the healthcare sector\nin the healthcare sector. It is used to predict\nthe patient's readmission rates by building a regression model by providing data on the patients treatment\nAdministration and readmissions to show variables that best correlate\nwith readmission. Next comes the retail sector\nand Retail sector. It is used to\nanalyze the product that a customer by together. It does this by building\na supervised model to identify frequent itemsets and Association rule\nfrom the transactional data now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 700.0,
    "t_end": 730.0,
    "text": "It does this by building\na supervised model to identify frequent itemsets and Association rule\nfrom the transactional data now, lets learn about\nthe next category of machine learning the\nunsupervised part mathematically unsupervised learning is where you only have Put data X and no\ncorresponding output variable. The goal for unsupervised\nlearning is to model the underlying structure or distribution in the data in order to learn\nmore about the data. So let me rephrase you\nthis in simple terms",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 725.0,
    "t_end": 755.0,
    "text": "or distribution in the data in order to learn\nmore about the data. So let me rephrase you\nthis in simple terms in unsupervised learning\napproach the data instances of a training data\nset do not have an expected output Associated to them instead unsupervised learning algorithm\ndetects pattern based on innate characteristics of the input data an example\nof machine learning tasks. Ask that applies unsupervised\nlearning is clustering in this task similar data\ninstances are grouped together in order to identify clusters\nof data in this slide.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 750.0,
    "t_end": 780.0,
    "text": "in this task similar data\ninstances are grouped together in order to identify clusters\nof data in this slide. You can see that initially\nwe have different varieties of fruits as input. Now these set of fruits as\ninput X are given to the model. Now, what is the model\nis trained using unsupervised learning algorithm. The model will create clusters\non the basis of its training. It will grip the similar fruits\nand make their cluster. Let me make things\nmore clearer to you. Let's take another\nexample of it. So in this Slide the image\nbelow shows an example",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 775.0,
    "t_end": 805.0,
    "text": "Let me make things\nmore clearer to you. Let's take another\nexample of it. So in this Slide the image\nbelow shows an example of unsupervised learning process\nthis algorithm processes an unlabeled training data set and based on\nthe characteristics. It grips the picture into three different clusters\nof data despite the ability of grouping similar\ndata into clusters. The algorithm is not capable\nto add labels to the crow. The algorithm only knows which\ndata instances are similar, but it cannot identify\nthe meaning of this group.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 800.0,
    "t_end": 830.0,
    "text": "The algorithm only knows which\ndata instances are similar, but it cannot identify\nthe meaning of this group. So, Now you might be wondering\nwhy this category of machine learning is named\nas unsupervised learning. So these are called as unsupervised learning because\nunlike supervised learning ever. There are no correct answer and there is no teacher\nalgorithms are left on their own to discover and present the interesting\nstructure in the data. Let's move on and see some of the popular unsupervised\nlearning algorithm. So we have here\nk-means apriori algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 825.0,
    "t_end": 855.0,
    "text": "Let's move on and see some of the popular unsupervised\nlearning algorithm. So we have here\nk-means apriori algorithm and hierarchical clustering now, let's move on and see\nsome of the examples of Is learning suppose a friend\ninvites you to his party and where you meet\ntotally strangers. Now, you will classify them\nusing unsupervised learning as you don't have\nany prior knowledge about them and this classification\ncan be done on the basis of gender age group\ndressing education qualification or whatever way you\nmight like now why",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 850.0,
    "t_end": 880.0,
    "text": "and this classification\ncan be done on the basis of gender age group\ndressing education qualification or whatever way you\nmight like now why this learning is different\nfrom supervised learning since you didn't use\nany pasta prior knowledge about the people you kept on\nclassifying them on the go as they kept on coming you\nkept on classifying them. Yeah, this category\nof people belong to this group this category of people belong\nto that group and so on. Okay, let's see\none more example. Let's suppose you have never\nseen a football match before and by chance you watch\na video on the internet. Now, you can easily classify\nthe players on the basis",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 875.0,
    "t_end": 905.0,
    "text": "Let's suppose you have never\nseen a football match before and by chance you watch\na video on the internet. Now, you can easily classify\nthe players on the basis of different Criterion, like player wearing\nthe same kind of Jersey are in one class player\nwearing different kind of Jersey aren't different class or you can classify\nthem on the basis of their playing style\nlike the guys are attacker. So he's in one class. He's a Defender\nhe's Another class or you can classify them. Whatever Way You\nobserve the things so this was also an example\nof unsupervised learning. Let's move on and see",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 900.0,
    "t_end": 930.0,
    "text": "Whatever Way You\nobserve the things so this was also an example\nof unsupervised learning. Let's move on and see how unsupervised learning\nis used in the sectors of banking Healthcare undertale. So starting at banking sector. So in banking sector it\nis used to segment customers by behavioral characteristic\nby surveying prospects and customers to develop\nmultiple segments using clustering and\nHealthcare sector. It is used to categorize the MRI\ndata by normal or abnormal. Ages it uses deep learning\ntechniques to build a model that learns from different\nfeatures of images to recognize",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 925.0,
    "t_end": 955.0,
    "text": "It is used to categorize the MRI\ndata by normal or abnormal. Ages it uses deep learning\ntechniques to build a model that learns from different\nfeatures of images to recognize a different pattern. Next is the retail sector\nand Retail sector. It is used to recommend\nthe products to customer based on their past purchases. It does this by building\na collaborative filtering model based on the past\npurchases by them. I assume you guys now have a proper idea of\nwhat unsupervised learning means if you have any slightest doubt don't hesitate and add your\ndoubt to the I'm in section.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 950.0,
    "t_end": 980.0,
    "text": "now have a proper idea of\nwhat unsupervised learning means if you have any slightest doubt don't hesitate and add your\ndoubt to the I'm in section. So let's discuss the third and the last type\nof machine learning that is reinforcement learning. So what is\nreinforcement learning? Well reinforcement learning is a type of machine\nlearning algorithm which allows software agents and machine to automatically\ndetermine the ideal Behavior within a specific context\nto maximize its performance. The reinforcement learning\nis about interaction between two elements",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 975.0,
    "t_end": 1005.0,
    "text": "within a specific context\nto maximize its performance. The reinforcement learning\nis about interaction between two elements the environment and\nthe learning agent the learning agent leverages\nto mechanism namely exploration. And exploitation when\nlearning agent acts on trial and error basis, it is termed as exploration and when it acts based\non the knowledge gained from the environment, it is referred\nto as exploitation. Now this environment rewards\nthe agent for correct actions, which is reinforcement signal\nleveraging the rewards obtain the agent",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1000.0,
    "t_end": 1030.0,
    "text": "Now this environment rewards\nthe agent for correct actions, which is reinforcement signal\nleveraging the rewards obtain the agent improves its environment\nknowledge to select the next action in this image. You can see\nthat the machine is confused whether it is an apple\nor it's not an apple then the Sheena's chain\nusing reinforcement learning. If it makes correct decision. It get rewards point for it and in case of wrong it gets\na penalty for that. Once the training is done. Now. The machine can easily identify\nwhich one of them is an apple.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1025.0,
    "t_end": 1055.0,
    "text": "and in case of wrong it gets\na penalty for that. Once the training is done. Now. The machine can easily identify\nwhich one of them is an apple. Let's see an example here. We can see that we have an agent who has to judge\nfrom the environment to find out which of the two is\na duck the first task he did is to observe\nthe environment next. We select some action\nusing some policy. It seems that the machine\nhas made a wrong decision. Bye. Choosing a bunny as a duck. So the machine will\nget penalty for it. For example -\n50.4 a wrong answer right now. The machine will\nupdate its policy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1050.0,
    "t_end": 1080.0,
    "text": "So the machine will\nget penalty for it. For example -\n50.4 a wrong answer right now. The machine will\nupdate its policy and this will continue till the machine gets\nan optimal policy from the next time machine will\nknow that bunny is not a duck. Let's see some of the use cases\nof reinforcement learning but before that lets see how Pavlo trained his dog\nusing reinforcement learning or how he applied the reinforcement method\nto train his dog. Babu integrated learning in four stages initially\nPavlo gave me to his dog",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1075.0,
    "t_end": 1105.0,
    "text": "the reinforcement method\nto train his dog. Babu integrated learning in four stages initially\nPavlo gave me to his dog and in response to the meet\nthe dog started salivating next what he did he created a sound with the bell for this the dog\ndid not respond anything in the third part it\ntried to condition the dog by using the bell and then giving him\nthe food seeing the food the dog started salivating\neventually a situation came when the dog started salivating\njust after hearing the Bell even if the food was not given to him\nas the The dog was reinforced",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1100.0,
    "t_end": 1130.0,
    "text": "the dog started salivating\neventually a situation came when the dog started salivating\njust after hearing the Bell even if the food was not given to him\nas the The dog was reinforced that whenever the master\nwill ring the bell he will get the food now. Let's move on and see how reinforcement learning\nis applied in the field of banking Healthcare\nand Retail sector. So starting with\nthe banking sector in banking sector reinforcement\nlearning is used to create a next best offer model for a call center\nby building a predictive model that learns over time as user accept or reject offer\nmade by the sales staff fine now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1125.0,
    "t_end": 1155.0,
    "text": "for a call center\nby building a predictive model that learns over time as user accept or reject offer\nmade by the sales staff fine now in healthcare sector it\nis used to allocate the scars. Resources to handle\ndifferent type of er cases by building\na Markov decision process that learns treatment strategies\nfor each type of er case next and the last comes\nin retail sector. So let's see how reinforcement learning\nis applied to retail sector and Retail sector. It can be used to\nreduce excess stock with Dynamic pricing by building\na dynamic pricing model",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1150.0,
    "t_end": 1180.0,
    "text": "how reinforcement learning\nis applied to retail sector and Retail sector. It can be used to\nreduce excess stock with Dynamic pricing by building\na dynamic pricing model that are just the price based on customer response\nto the offers. I hope by now you have attained\nsome understanding of what is machine learning\nand you are ready to move. Move ahead. Welcome to today's topic\nof discussion on AI versus machine learning\nversus deep learning. These are the term\nwhich have confused a lot of people and if you\ntwo are one among them,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1175.0,
    "t_end": 1205.0,
    "text": "versus machine learning\nversus deep learning. These are the term\nwhich have confused a lot of people and if you\ntwo are one among them, let me resolve it for you. Well artificial intelligence\nis a broader umbrella under which machine learning and deep learning come you\ncan also see in the diagram that even deep learning is a subset of machine\nlearning so you can say that all three of them The AI\nand machine learning and deep learning are just\nthe subset of each other. So let's move on and understand how exactly the differ\nfrom each other.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1200.0,
    "t_end": 1230.0,
    "text": "and deep learning are just\nthe subset of each other. So let's move on and understand how exactly the differ\nfrom each other. So let's start\nwith artificial intelligence. The term artificial intelligence was first coined\nin the year 1956. The concept is pretty old, but it has gained\nits popularity recently. But why well, the reason is earlier we had\nvery small amount of data the data we had was not enough\nto predict the Turret result but now there's\na tremendous increase in the amount of data statistics",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1225.0,
    "t_end": 1255.0,
    "text": "the data we had was not enough\nto predict the Turret result but now there's\na tremendous increase in the amount of data statistics suggest that by 2020\nthe accumulated volume of data will increase from 4.4 zettabyte stew\nroughly around 44 zettabytes or 44 trillion jeebies of data along with such\nenormous amount of data. Now, we have more\nadvanced algorithm and high-end computing\npower and storage that can deal with such large\namount of data as a result. It is expected",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1250.0,
    "t_end": 1280.0,
    "text": "and high-end computing\npower and storage that can deal with such large\namount of data as a result. It is expected that 70% of The price\nwill Implement a i over the next 12 months which is up from 40 percent\nin 2016 and 51 percent in 2017. Just for your understanding. What does AI well, it's nothing but a technique that enables the machine\nto act like humans by replicating the behavior\nand nature with AI it is possible for machine to learn\nfrom the experience. The machines are just\ntheir responses based",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1275.0,
    "t_end": 1305.0,
    "text": "by replicating the behavior\nand nature with AI it is possible for machine to learn\nfrom the experience. The machines are just\ntheir responses based on new input there by performing human-like tasks\nartificial intelligence can be and to accomplish specific tasks by processing\nlarge amount of data and recognizing pattern in them. You can consider that building an artificial\nintelligence is like Building a Church the first church\ntook generations to finish. So most of the workers\nwere working in it never saw the final outcome those working on it took pride\nin their craft building bricks",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1300.0,
    "t_end": 1330.0,
    "text": "So most of the workers\nwere working in it never saw the final outcome those working on it took pride\nin their craft building bricks and chiseling stone that was going to be placed\ninto the great structure. So as AI researchers, we should think of ourselves\nas humble brick makers was job. It's just study how to build components\nexample Parts is planners or learning algorithm\nor Etc anything that someday someone\nand somewhere will integrate into the intelligent systems\nsome of the examples of artificial intelligence\nfrom our day-to-day life",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1325.0,
    "t_end": 1355.0,
    "text": "that someday someone\nand somewhere will integrate into the intelligent systems\nsome of the examples of artificial intelligence\nfrom our day-to-day life are Apple series chess-playing\ncomputer Tesla self-driving car and many more these examples\nare based on deep learning and natural language processing. Well, this was about what is AI\nand how it gains its hype. So moving on ahead. Let's Gus about machine\nlearning and see what it is and why it was the\nwhen introduced well Machine learning came\ninto existence in the late 80s and the early 90s,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1350.0,
    "t_end": 1380.0,
    "text": "and why it was the\nwhen introduced well Machine learning came\ninto existence in the late 80s and the early 90s, but what were the issues\nwith the people which made the machine learning\ncome into existence let us discuss them one by one\nin the field of Statistics. The problem was how to efficiently train\nlarge complex model in the field of computer science\nand artificial intelligence. The problem was\nhow to train more robust version of AI system while in\nthe case of Neuroscience. Problem faced by\nthe researchers was how to design operation\nmodel of the brain.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1375.0,
    "t_end": 1405.0,
    "text": "of AI system while in\nthe case of Neuroscience. Problem faced by\nthe researchers was how to design operation\nmodel of the brain. So these were some of the issues which had the largest influence\nand led to the existence of the machine learning. Now this machine learning\nshifted its focus from the symbolic approaches. It had inherited\nfrom the AI and move towards the methods and model. It had borrowed from statistics\nand probability Theory. So let's proceed and see what exactly is\nmachine learning. Well Machine learning\nis a subset of AI which enables the\ncomputer to act",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1400.0,
    "t_end": 1430.0,
    "text": "what exactly is\nmachine learning. Well Machine learning\nis a subset of AI which enables the\ncomputer to act and make data-driven decisions\nto carry out a certain task. These programs are algorithms\nare designed in a way that they can learn\nand improve over time when exposed to new data. Let's see an example\nof machine learning. Let's say you want\nto create a system which tells the expected weight\nof a person based on its side. The first thing you do\nis you collect the data. Let's see there is how your data looks\nlike now each point on the graph represent\none data point to start",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1425.0,
    "t_end": 1455.0,
    "text": "The first thing you do\nis you collect the data. Let's see there is how your data looks\nlike now each point on the graph represent\none data point to start with we can draw a simple line\nto predict the weight based on the height for Sample\na simple line W equal x minus hundred with W\nis waiting kgs and edges hide and centimeter this line can\nhelp us to make the prediction. Our main goal is\nto reduce the difference between the estimated value\nand the actual value. So in order to achieve it, we try to draw a straight line\nthat fits through all",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1450.0,
    "t_end": 1480.0,
    "text": "between the estimated value\nand the actual value. So in order to achieve it, we try to draw a straight line\nthat fits through all these different points\nand minimize the error. So our main goal is\nto minimize the error and make them as small as\npossible decreasing the error or the difference between\nthe actual value and estimated. Value increases the performance\nof the model further on the more data points. We collect the better. Our model will become we\ncan also improve our model by adding more variables and creating different\nproduction lines for them. Once the line is created. So from the next time\nif we feed a new data,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1475.0,
    "t_end": 1505.0,
    "text": "by adding more variables and creating different\nproduction lines for them. Once the line is created. So from the next time\nif we feed a new data, for example height\nof a person to the model, it would easily predict the data\nfor you and it will tell you what has predicted\nweight could be. I hope you got\na clear understanding of machine learning. So moving on ahead. Let's learn about deep learning\nnow what is deep learning? You can consider deep learning\nmodel as a rocket engine and its fuel is\nits huge amount of data that we feed to\nthese algorithms the concept of deep learning is not new,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1500.0,
    "t_end": 1530.0,
    "text": "and its fuel is\nits huge amount of data that we feed to\nthese algorithms the concept of deep learning is not new, but recently it's\nhype as increase and deep learning\nis getting more attention. This field is a particular kind\nof machine learning that is inspired by the functionality of\nour brain cells called neurons which led to the concept\nof artificial neural network. It simply takes the data connection between all\nthe artificial neurons and adjust them according\nto the data pattern. More neurons are added at the size of the data is large\nit automatically features",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1525.0,
    "t_end": 1555.0,
    "text": "and adjust them according\nto the data pattern. More neurons are added at the size of the data is large\nit automatically features learning at multiple\nlevels of abstraction. Thereby allowing a system to learn complex function\nmapping without depending on any specific algorithm. You know, what no one\nactually knows what happens inside a neural network\nand why it works so well, so currently you can call\nit as a black box. Let us discuss some\nof the example of deep learning and understand it\nin a better way. Let me start with\nin simple example and explain you how things And\nat a conceptual level,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1550.0,
    "t_end": 1580.0,
    "text": "Let us discuss some\nof the example of deep learning and understand it\nin a better way. Let me start with\nin simple example and explain you how things And\nat a conceptual level, let us try and understand how you would recognize\na square from other shapes. The first thing\nyou do is you check whether there are four lines\nassociated with a figure or not simple concept, right? If yes, we further check if they are connected\nand closed again a few years. We finally check\nwhether it is perpendicular and all its sides\nare equal, correct. If everything fulfills.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1575.0,
    "t_end": 1605.0,
    "text": "We finally check\nwhether it is perpendicular and all its sides\nare equal, correct. If everything fulfills. Yes, it is a square. Well, it is nothing but\na nested hierarchy of Concepts. What we did here we\ntook a complex task of identifying a square and this case and broken\ninto simpler tasks. Now this deep learning\nalso does the same thing but at a larger scale, let's take an example\nof machine which recognizes the animal the task\nof the machine is to recognize whether the given image is\nof a cat or a dog.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1600.0,
    "t_end": 1630.0,
    "text": "the animal the task\nof the machine is to recognize whether the given image is\nof a cat or a dog. What if we were asked to resolve\nthe same issue using the concept of machine learning\nwhat we would do first. We would Define\nthe features such as check whether the animal has\nwhiskers or not a check. The animal has pointed ears or not or whether its tail\nis straight or curved in short. We will Define\nthe facial features and let the system identify which\nfeatures are more important in classifying a\nparticular animal now when it comes to deep learning\nit takes this to one step ahead",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1625.0,
    "t_end": 1655.0,
    "text": "the system identify which\nfeatures are more important in classifying a\nparticular animal now when it comes to deep learning\nit takes this to one step ahead deep learning automatically\nfinds are the feature which are most important\nfor classification compare into machine learning where we had to manually give\nout that features by now. I guess you have understood\nthat AI is the bigger picture and machine learning and\ndeep learning are it's apart. So let's move on and focus our discussion\non machine learning and deep learning the easiest\nway to understand the difference between the machine learning\nand deep learning is to know",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1650.0,
    "t_end": 1680.0,
    "text": "and focus our discussion\non machine learning and deep learning the easiest\nway to understand the difference between the machine learning\nand deep learning is to know that deep learning is machine\nlearning more specifically. It is the next evolution\nof machine learning. Let's take few\nimportant parameter and compare machine learning\nwith deep learning. So starting with\ndata dependencies, the most important difference\nbetween deep learning and machine learning is\nits performance as the volume of the data gets\nFrom the below graph. You can see that when the size of the data\nis small deep learning algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1675.0,
    "t_end": 1705.0,
    "text": "of the data gets\nFrom the below graph. You can see that when the size of the data\nis small deep learning algorithm doesn't perform that well, but why well, this is because deep\nlearning algorithm needs a large amount of data\nto understand it perfectly on the other hand the machine\nlearning algorithm can easily work with smaller data set fine. Next comes the hardware\ndependencies deep learning algorithms are heavily dependent\non high-end machines while the machine learning\nalgorithm can work",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1700.0,
    "t_end": 1730.0,
    "text": "algorithms are heavily dependent\non high-end machines while the machine learning\nalgorithm can work on low and machines as Well, this is because the requirement of deep learning\nalgorithm include gpus which is an integral part of its working the Deep learning\nalgorithm requires gpus as they do a large amount of matrix\nmultiplication operations, and these operations can only be efficiently\noptimized using a GPU as it is built for this purpose. Only our third parameter will be feature engineering well\nfeature engineering is a process",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1725.0,
    "t_end": 1755.0,
    "text": "as it is built for this purpose. Only our third parameter will be feature engineering well\nfeature engineering is a process of putting the domain knowledge\nto reduce the complexity of the data. Make patterns more visible\nto learning algorithms. This process is difficult\nand expensive in terms of time and expertise in case\nof machine learning most other features are needed\nto be identified by an expert and then hand coded\nas per the domain and the data type. For example, the features can be a pixel value shapes\ntexture position orientation",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1750.0,
    "t_end": 1780.0,
    "text": "and then hand coded\nas per the domain and the data type. For example, the features can be a pixel value shapes\ntexture position orientation or anything fine the performance of most of the machine\nlearning algorithm depends on how accurately the features\nare identified and stood where as in case of deep learning algorithms it\ntry to learn high level features from the data. This is a very distinctive part\nof deep learning which makes it way ahead of traditional machine learning\ndeep learning reduces the task of developing new feature\nextractor for every problem",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1775.0,
    "t_end": 1805.0,
    "text": "which makes it way ahead of traditional machine learning\ndeep learning reduces the task of developing new feature\nextractor for every problem like in the case of CNN algorithm it first try\nto learn the low-level features of the image such as\nedges and lines and then it proceeds\nto the parts of faces of people and then finally to\nthe high-level representation of the face. I hope that things\nGetting clearer to you. So let's move on ahead and see\nthe next parameter. So our next parameter is\nproblem solving approach when we are solving a problem\nusing traditional machine",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1800.0,
    "t_end": 1830.0,
    "text": "So let's move on ahead and see\nthe next parameter. So our next parameter is\nproblem solving approach when we are solving a problem\nusing traditional machine learning algorithm. It is generally recommended that we first break\ndown the problem into different sub parts\nsolve them individually and then finally combine them\nto get the desired result. This is how the machine learning\nalgorithm handles the problem on the other hand\nthe Deep learning algorithm solves the problem\nfrom end to end. Let's take an example. To understand this\nsuppose you have a task of multiple object detection.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1825.0,
    "t_end": 1855.0,
    "text": "Let's take an example. To understand this\nsuppose you have a task of multiple object detection. And your task is to identify. What is the object and where it\nis present in the image. So, let's see and compare. How will you tackle\nthis issue using the concept of machine learning and deep learning starting\nwith machine learning in a typical machine\nlearning approach. You would first divide\nthe problem into two step first object detection\nand then object recognization. First of all, you would use a bounding\nbox detection algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1850.0,
    "t_end": 1880.0,
    "text": "first object detection\nand then object recognization. First of all, you would use a bounding\nbox detection algorithm like grab could fight. Sample to scan through the image and find out all\nthe possible objects. Now, once the objects\nare recognized you would use object recognization algorithm, like svm with hog\nto recognize relevant objects. Now, finally, when you combine the result you\nwould be able to identify. What is the object\nand where it is present in the image on the other hand\nin deep learning approach. You would do the process\nfrom end to end for example",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1875.0,
    "t_end": 1905.0,
    "text": "What is the object\nand where it is present in the image on the other hand\nin deep learning approach. You would do the process\nfrom end to end for example in a yellow net which is a type of deep learning\nalgorithm you would pass. An image and it would give out\nthe location along with the name of the object. Now, let's move on to\nour fifth comparison parameter its execution time. Usually a deep learning\nalgorithm takes a long time to train this is because there's so many parameter in\na deep learning algorithm that makes the training longer than usual the training\nmight even last for two weeks",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1900.0,
    "t_end": 1930.0,
    "text": "because there's so many parameter in\na deep learning algorithm that makes the training longer than usual the training\nmight even last for two weeks or more than that. If you are training\ncompletely from the scratch, whereas in the case\nof machine learning, it relatively takes much\nless time to train ranging from a few weeks. Too few Arts. Now. The execution time\nis completely reversed when it comes to the testing\nof data during testing the Deep learning algorithm\ntakes much less time to run. Whereas if you compare it\nwith a KNN algorithm, which is a type of machine\nlearning algorithm the test",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1925.0,
    "t_end": 1955.0,
    "text": "the Deep learning algorithm\ntakes much less time to run. Whereas if you compare it\nwith a KNN algorithm, which is a type of machine\nlearning algorithm the test time increases as the size\nof the data increase last but not the least we\nhave interpretability as a factor for comparison\nof machine learning and deep learning. This fact is the main reason\nwhy deep learning is still thought ten times\nbefore anyone knew. Uses it in the industry. Let's take an example suppose. We use deep learning to give automated scoring two essays\nthe performance it gives and scoring is quite\nexcellent and is near",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1950.0,
    "t_end": 1980.0,
    "text": "We use deep learning to give automated scoring two essays\nthe performance it gives and scoring is quite\nexcellent and is near to the human performance, but there's an issue with it. It does not reveal white has given that score\nindeed mathematically. It is possible to find out that which node of a deep\nneural network were activated, but we don't know what the neurons\nare supposed to model and what these layers of neurons\nare doing collectively. So if To interpret the result on the other hand machine\nlearning algorithm,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 1975.0,
    "t_end": 2005.0,
    "text": "and what these layers of neurons\nare doing collectively. So if To interpret the result on the other hand machine\nlearning algorithm, like decision tree gives us\na crisp rule for void chose and watered chose. So it is particularly easy\nto interpret the reasoning behind therefore the algorithms\nlike decision tree and linear or logistic regression are primarily used in\nindustry for interpretability. Let me summarize things for you machine learning\nuses algorithm to parse the data learn from the data and make informed decision based\non what it has learned fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2000.0,
    "t_end": 2030.0,
    "text": "for you machine learning\nuses algorithm to parse the data learn from the data and make informed decision based\non what it has learned fine. in this deep learning structures\nalgorithms in layers to create artificial neural network that can learn and make Intelligent Decisions\non their own finally deep learning is a subfield\nof machine learning while both fall\nunder the broad category of artificial intelligence\ndeep learning is usually what's behind the most human-like artificial\nintelligence now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2025.0,
    "t_end": 2055.0,
    "text": "what's behind the most human-like artificial\nintelligence now in early days scientists\nused to have a lab notebook to Test progress results and conclusions now\nJupiter is a modern-day to that allows data scientists to record the complete\nanalysis process much in the same way other scientists\nuse a lab notebook. Now, the Jupiter product was\noriginally developed as a part of IPython project the iPad and project was used to provide\ninteractive online access",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2050.0,
    "t_end": 2080.0,
    "text": "Now, the Jupiter product was\noriginally developed as a part of IPython project the iPad and project was used to provide\ninteractive online access to python over time. It became useful to interact with other data analysis tools\nsuch as are in the same manner with the split from python the tool crew in in his current\nmanifestation of Jupiter. Now IPython is\nstill an active tool that's available for use. The name Jupiter itself is\nderived from the combination of Julia Python. And our while Jupiter runs code in many programming languages\npython is a requirement",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2075.0,
    "t_end": 2105.0,
    "text": "The name Jupiter itself is\nderived from the combination of Julia Python. And our while Jupiter runs code in many programming languages\npython is a requirement for installing the jupyter\nnotebook itself now to download jupyter notebook. There are a few ways\nin their official website. It is strongly recommended\ninstalling Python and Jupiter using Anaconda distribution, which includes python\nDon't know what book and other commonly used packages for scientific Computing\nas well as data science. Although one can also do so using the pipe\ninstallation method personally.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2100.0,
    "t_end": 2130.0,
    "text": "for scientific Computing\nas well as data science. Although one can also do so using the pipe\ninstallation method personally. What I would suggest\nis downloading an app on a navigator, which is a desktop graphical user\ninterface included in Anaconda. Now, this allows you\nto launch application and easily manage\nconda packages environments and channels without the need\nto use command line commands. So all you need to do is go\nto another Corner dot orgy and inside you go. To Anaconda Navigators. So as you can see here, we have the conda installation\ncode which you're going",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2125.0,
    "t_end": 2155.0,
    "text": "and inside you go. To Anaconda Navigators. So as you can see here, we have the conda installation\ncode which you're going to use to install it\nin your particular PC. So either you can\nuse these installers. So once you download\nthe Anaconda Navigator, it looks something like this. So as you can see here, we have Jupiter lab jupyter\nnotebook you have QT console, which is IPython console. We have spider which is\nsomewhat similar to a studio in terms of python again, we have a studio\nso we have orange three",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2150.0,
    "t_end": 2180.0,
    "text": "We have spider which is\nsomewhat similar to a studio in terms of python again, we have a studio\nso we have orange three We have glue is\nand we have VSC code. Our Focus today would be\non this jupyter notebook itself. Now when you\nlaunch the Navigator, you can see there are\nmany options available for launching python as well. As our instances Now\nby definition are jupyter. Notebook is fundamentally a Json file with\na number of annotations. Now, it has three main parts which are the metadata\nThe Notebook format and the list of cells now you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2175.0,
    "t_end": 2205.0,
    "text": "Now, it has three main parts which are the metadata\nThe Notebook format and the list of cells now you should get yourself acquainted\nwith the environment that Jupiter user interface\nhas a number of components. So it's important to know what our components\nyou should be using on a daily basis and you\nshould get acquainted with it. So as you can see here our Focus today will be\non the jupyter notebook. So let me just launched\nthe Japan and notebook. Now what it does is creates\na online python instance for you to use it over the web. So let's launch now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2200.0,
    "t_end": 2230.0,
    "text": "Now what it does is creates\na online python instance for you to use it over the web. So let's launch now as you can see we have\nJupiter on the top left as expected and this acts\nas a button to go to your home page\nwhenever you click on this you get back\nto your particular home paste. Is the dashboard now there are\nthree tabs displayed with other files\nrunning and clusters. Now, what will do is\nwill understand all of these three and understand what are the importance of these three tabs\nother file tab shows the list",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2225.0,
    "t_end": 2255.0,
    "text": "of these three and understand what are the importance of these three tabs\nother file tab shows the list of the current files\nin the directory. So as you can see we have\nso many files here. Now the running tab presents another screen of\nthe currently running processes and the notebooks now the\ndrop-down list for the terminals and notebooks are\npopulated with there. Running numbers. So as you can see inside, we do not have\nany running terminals or there no running\nnotebooks as of now and the cluster tab presents another screen\nto display the list",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2250.0,
    "t_end": 2280.0,
    "text": "we do not have\nany running terminals or there no running\nnotebooks as of now and the cluster tab presents another screen\nto display the list of clusters available see in the\ntop right corner of the screen. There are three buttons\nwhich are upload new and the refresh button. Let me go back\nso you can see here. We have the upload new\nand the refresh button. Now the upload button\nis used to add files to The Notebook space and you\nmay also just drag and drop as you would\nwhen handling files. Similarly, you can drag and drop notebooks\ninto specific folders as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2275.0,
    "t_end": 2305.0,
    "text": "as you would\nwhen handling files. Similarly, you can drag and drop notebooks\ninto specific folders as well. Now the menu with the new\nin the top residents of further many\nof text file folders terminal and Python 3. Now, the test file option\nis used to add a text file to the current directory Jupiter\nwill open a new browser window for you for the running\nnew text editor. Now, the text entered\nis automatically saved and will be displayed\nin your notebooks files display. Now the folder option what it does is\ncreates a new folder.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2300.0,
    "t_end": 2330.0,
    "text": "and will be displayed\nin your notebooks files display. Now the folder option what it does is\ncreates a new folder. With the name Untitled folder\nand remember all the files and folder names are editable. Now the terminal option\nallows you to start and IPython session. The node would options\navailable will be activated when additional note books are\navailable in your environment. The Python 3 option is used\nto begin pythons recession interactively in your note. The interface looks\nlike the following screen shot. Now what you have is\nfull file editing capabilities",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2325.0,
    "t_end": 2355.0,
    "text": "interactively in your note. The interface looks\nlike the following screen shot. Now what you have is\nfull file editing capabilities for your script\nincluding saving as new file. You also have a complete ID for your python script now we\ncome to the refresh button. The refresh button is used\nto update the display. It's not really necessary\nas a display is reactive to any changes in\nthe underlying file structure. I had a talk with\nthe files tab item. There is a check box drop down menu and a home button\nas you can see here. We have the checkbox\nthe drop-down menu",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2350.0,
    "t_end": 2380.0,
    "text": "I had a talk with\nthe files tab item. There is a check box drop down menu and a home button\nas you can see here. We have the checkbox\nthe drop-down menu and the home button. Now the check box is used\nto toggle all the checkboxes in the item list. So as you can see you can select\nall of these when either move or either delete all\nof the file selected, It or what you\ncan do is select all and deselect some of the files as your wish now the drop\ndown menu presents a list of choices available, which are the folders\nall notebooks running and files to the folder section will select all the folders\nin the display",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2375.0,
    "t_end": 2405.0,
    "text": "which are the folders\nall notebooks running and files to the folder section will select all the folders\nin the display and present account\nof the folders in the small box. So as you can see here, we have 18 number of folders\nnow all the notebooks section will change the count\nof the number of nodes and provide you\nwith three option so you can see here. It has selected all\nthe given notebooks which are a In a number and you get the option to either\nduplicate the current notebook. You need to move it view\nit edit it or delete. Now, the writing section\nwill select any running scripts",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2400.0,
    "t_end": 2430.0,
    "text": "and you get the option to either\nduplicate the current notebook. You need to move it view\nit edit it or delete. Now, the writing section\nwill select any running scripts as you can see here. We have zero running scripts and update the count\nto the number selected. Now the file section\nwill select all the files in the notebook display and\nupdate the counts accordingly. So if you select the files here, we are seven files\nas you can see here. We have seven files\nsome datasets CSV files and text files now\nthe home button. Brings you back to the home\nscreen of the notebook. So on you to do is click\non the jupyter.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2425.0,
    "t_end": 2455.0,
    "text": "and text files now\nthe home button. Brings you back to the home\nscreen of the notebook. So on you to do is click\non the jupyter. Notebook lower. It will bring you back to\nthe Jupiter notebook dashboard. Now, as you can see\non the left hand side of every item is a checkbox\nand I can and the items name. The checkbox is used to build\na set of files to operate upon and the icon is indicated\nof of the type of the item. And in this case, all of the items are\nfolder here coming down. We have the ring notebooks. And finally we have certain\nfiles which are the text files",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2450.0,
    "t_end": 2480.0,
    "text": "all of the items are\nfolder here coming down. We have the ring notebooks. And finally we have certain\nfiles which are the text files and the As we files\nnow a typical workflow of any jupyter. Notebook is to first\nof all create a notebook for the project\nor your data analysis. Add your analysis step coding and output and Surround\nyour analysis with organization and presentation mark\ndown to communicate and entire story\nnow interactive notebooks that include widgets\nand display modules will then be used by others\nby modifying parameters and the data to note the effects\nof the changes now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2475.0,
    "t_end": 2505.0,
    "text": "that include widgets\nand display modules will then be used by others\nby modifying parameters and the data to note the effects\nof the changes now if we talk about security\njupyter notebooks are created in order to Be shared\nwith other users in many cases over the Internet. However, jupyter notebook\ncan execute arbitrary code and generate arbitrary code. This can be a problem. If malicious aspects\nhave been placed in the note Now the default\nsecurity mechanism for Japan or notebooks include raw HTML, which is always sanitized\nand check for malicious coding.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2500.0,
    "t_end": 2530.0,
    "text": "in the note Now the default\nsecurity mechanism for Japan or notebooks include raw HTML, which is always sanitized\nand check for malicious coding. Another aspect is you cannot run\nexternal Java scripts. Now the cell contents, especially the HTML and\nthe JavaScript are not trusted it requires user value. Nation to continue and the output from any cell\nis not trusted all other HTML or JavaScript is never trusted and clearing the output\nwill cause the notebook to become trusted when save now notebooks\ncan also use a security digest to ensure the correct user\nis modifying the contents.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2525.0,
    "t_end": 2555.0,
    "text": "and clearing the output\nwill cause the notebook to become trusted when save now notebooks\ncan also use a security digest to ensure the correct user\nis modifying the contents. So for that what you\nneed to do is a digest what it does is takes\ninto the account the entire contents\nof the notebook and a secret which is only known by\nThe Notebook Creator and this combination ensures that malicious coding is\nis not going to be added to the notebook so you can add security\nto address to notebook using the following command\nwhich I have given here. So it's Jupiter the profile what you have selected\nand inside you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2550.0,
    "t_end": 2580.0,
    "text": "so you can add security\nto address to notebook using the following command\nwhich I have given here. So it's Jupiter the profile what you have selected\nand inside you what you need to do is security\nand notebook secret. So what you can do is\nreplace the notebooks secret with your putter secret and that will act as a key\nfor the particular notebook. So what you need to do\nis share that particular key with all your colleagues or whoever you want to share\nthat particular notebook with and in that case, it keeps the notebooks. Geode and away from\nother malicious coders and all other aspect\nof Jupiter is configuration.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2575.0,
    "t_end": 2605.0,
    "text": "it keeps the notebooks. Geode and away from\nother malicious coders and all other aspect\nof Jupiter is configuration. So you can configure some\nof the display parameters used and presenting notebooks. Now, these aren't configurable\ndue to the use of product known as code mirror to present\nand modify the notebook. So cold mirror water basically\nis it is a JavaScript based editor for the u.s. Within the web pages\nand notebooks. So what you do is\nwhat you do code mirror, so as you can see here code mirror is a versatile\ntext editor implemented.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2600.0,
    "t_end": 2630.0,
    "text": "So what you do is\nwhat you do code mirror, so as you can see here code mirror is a versatile\ntext editor implemented. In JavaScript for the browser. So what it does is allow you to configure\nthe options for Jupiter. So now let's execute\nsome python code and understand the notebook\nin A Better Way Jupiter does not interact with your scripts as\nmuch as it executes your script and request the result. So I think this is\nhow jupyter notebooks have been extended to other\nlanguages besides python as it just takes a script runs it against\na particular language engine",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2625.0,
    "t_end": 2655.0,
    "text": "So I think this is\nhow jupyter notebooks have been extended to other\nlanguages besides python as it just takes a script runs it against\na particular language engine and across the output\nfrom the engine all the while not Really\nknowing what kind of a script is being executed\nnow the new windows shows and empty cell for you to enter\nthe python code know what you need to do is under new\nyou select the Python 3 and what I will do is open\na new notebook. Now this notebook is Untitled. So let's give the new work area\nand name python code.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2650.0,
    "t_end": 2680.0,
    "text": "what I will do is open\na new notebook. Now this notebook is Untitled. So let's give the new work area\nand name python code. So as you can see we have\nrenamed this particular cell now order save option should be\non the next to the title as you can see last. Checkpoint a few days\nago, unsaved changes. The autosave option is\nalways on what we do is with an accurate name. We can find the selection and this particular\nnotebook very easily from The Notebook home page. So if you select\nyour browser's Home tab",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2675.0,
    "t_end": 2705.0,
    "text": "We can find the selection and this particular\nnotebook very easily from The Notebook home page. So if you select\nyour browser's Home tab and refresh you will find this new window name\ndisplayed here again. So if you just go\nto a notebook home and as you can see, I mentioned it by then quotes\nand under running. Also, you have the pilot\nand quotes here. So let's get back\nto the Particular page or the notebook\none thing to note here that it has and does an item icon\nversus a folder icon though automatically\nassigned extension",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2700.0,
    "t_end": 2730.0,
    "text": "that it has and does an item icon\nversus a folder icon though automatically\nassigned extension as you can see here is ipy\nand be the IPython note and says the item is in a browser\nin a Jupiter environment. It is marked as running answer is a file by that name\nin this directory as well. So if you go\nto your directory, let me go and check it. So as you can see\nif you go into the users are you can see we have the\nin class projects that Python codes\nlike the series automatically have that particular\nIPython notebook created",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2725.0,
    "t_end": 2755.0,
    "text": "can see we have the\nin class projects that Python codes\nlike the series automatically have that particular\nIPython notebook created in our working environment and the local disk space also. So if you open the IP y +\nB file in a text editor, you will see basic context\nof a Jupiter code as you can see if I'm opening it. The cells are empty. Nothing is there so let's type\nin some code here. For example, I'm going to put\nin name equals edgy Rekha. Next what I'm going to do\nis provide subscribers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2750.0,
    "t_end": 2780.0,
    "text": "For example, I'm going to put\nin name equals edgy Rekha. Next what I'm going to do\nis provide subscribers that equals seven hundred gay\nand to run this particular cell. What you need to do\nis click on the run Icon and it will see\nhere we have one. So this is the first set to be\nexecuted in the second cell. We enter python code that references the variables\nfrom the first cell. So as you can see here, we have friend named\nhas strings subscribers.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2775.0,
    "t_end": 2805.0,
    "text": "that references the variables\nfrom the first cell. So as you can see here, we have friend named\nhas strings subscribers. So let me just\nrun this particular. So as you can see here note. Now that we have an output here that Erica has 700k\nYouTube subscriber now since more than 700 K now\nto know more about Jupiter and other Technologies, what you can do is subscribe\nto our Channel and get updates on the latest\ntrending Technologies. So note that Jupiter color codes your python just as\ndecent editor vote and we have empty braces",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2800.0,
    "t_end": 2830.0,
    "text": "So note that Jupiter color codes your python just as\ndecent editor vote and we have empty braces to the left of each code block\nsuch as you can see here. If we execute the cell the results are displayed\nin line now, it's interesting that Jupiter keeps. The output last generated\nin the saved version of the file and it's a save checkpoints. Now, if we were to rerun\nyour cells using the rerun or the run all the output\nwould be generated and c8y autosave now, the cell number is incremented\nand as you can see if I rerun this you see\nthe cell number change",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2825.0,
    "t_end": 2855.0,
    "text": "and c8y autosave now, the cell number is incremented\nand as you can see if I rerun this you see\nthe cell number change from one to three and if I rerun this the Selma\nwill change from 2 to 4. So what Jupiter does is keeps\na track of the latest version of each cell so similarly if you are to close\nthe browser tab It's the display in the Home tab. You will find\na new item we created which is the python code\nyour notebook saved autosaved as you can see here\nin the bracket has autosaved. So if we close this\nin the home button,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2850.0,
    "t_end": 2880.0,
    "text": "which is the python code\nyour notebook saved autosaved as you can see here\nin the bracket has autosaved. So if we close this\nin the home button, you can see here. We have python codes. So as you can see if we click\nthat it opens the same notebook. It has the previously displayed items will be always\nthere showing the output sweat that we generated\nin the last run now that we have seen\nhow python Works in Jupiter including\nthe underlying encoding then how this python. This allows data set\nor data set Works in Jupiter. So let me create\nanother new python notebook.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2875.0,
    "t_end": 2905.0,
    "text": "This allows data set\nor data set Works in Jupiter. So let me create\nanother new python notebook. So what I'm going to do\nis name this as pandas. So from here, what we will do is read\nin last dataset and compute some standard\nstatistics of data. Now what we are interested\nin in seeing how to use the pandas in Jupiter how well the script performs and what information\nis stored in the metadata, especially if it's\na large dataset so our Python script accesses\nthe iris dataset here",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2900.0,
    "t_end": 2930.0,
    "text": "and what information\nis stored in the metadata, especially if it's\na large dataset so our Python script accesses\nthe iris dataset here that's built into one\nof the Python packages. Now. All we are looking in to do is\nto read in slightly large number of items and calculate\nsome basic operations on the data set. So first of all, what we need to do is from sklearn import\nthe data set so sklearn is scikit-learn and it is\nanother library of python. It contains a lot of data sets\nfor machine learning and all the algorithms",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2925.0,
    "t_end": 2955.0,
    "text": "is scikit-learn and it is\nanother library of python. It contains a lot of data sets\nfor machine learning and all the algorithms which are present\nfor machine learning and the data sets\nwhich are there so, So import was successful. So what we're going to do\nnow is pull in the IRS data. What we're going to do is Iris\nunderscore data set equals and the load on the screen now\nthat should do and I'm sorry, it's data set start lower.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2950.0,
    "t_end": 2980.0,
    "text": "and the load on the screen now\nthat should do and I'm sorry, it's data set start lower. So so as you can see here, the number here\nis considered three now because in the second drawer and we encountered\nan error it was data set. He's not data set. So so what we're going to do is grab the first\ntwo corner of the data. So let's pretend x equals. If you press the tab,\nit automatically detects what you're going to write\nas Todd datasets dot data. And what we're going to do is\ntake the first two rows comma",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 2975.0,
    "t_end": 3005.0,
    "text": "what you're going to write\nas Todd datasets dot data. And what we're going to do is\ntake the first two rows comma not to run it\nfrom your keyboard. All you need to do is\npress shift + enter. So next what we're going\nto do is calculate some basic statistics. So what we're going\nto do is X underscore. Count equals x I'm going to use\nthe length function and said that we're going to use x\ndot flat similarly. We going to see X-Men",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3000.0,
    "t_end": 3030.0,
    "text": "Count equals x I'm going to use\nthe length function and said that we're going to use x\ndot flat similarly. We going to see X-Men and X Max and the Min\nour display our results. What we're going to do is you\njust play the results now, so as you can see the counter 300\nthe minimum value is 3.8 m/s. And what is 0.4 and the mean is five point\neight four three three three. So let me connect you\nto the real life and tell you what\nall are the things which you can easily do using\nthe concepts of machine learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3025.0,
    "t_end": 3055.0,
    "text": "So let me connect you\nto the real life and tell you what\nall are the things which you can easily do using\nthe concepts of machine learning so you can easily get\nanswer to the questions like which types of house\nlies in this segment or what is the market value\nof this house or is this a male as spam or not spam? Is there any fraud? Well, these are some\nof the question you could ask to the machine but for getting an answer\nto these you need some algorithm the machine need to train\non the basis of some algorithm. Okay, but how will you\ndecide which algorithm to choose and when?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3050.0,
    "t_end": 3080.0,
    "text": "the machine need to train\non the basis of some algorithm. Okay, but how will you\ndecide which algorithm to choose and when? Okay. So the best option for us is\nto explore them one by one. So the first is\nclassification algorithm where the categories\npredicted using the data if you have some question, like is this person a male or a female or is\nthis male a Spam or not? Spam then these category\nof question would fall under the classification\nalgorithm classification is a supervised learning approach in which the computer program\nlearns from the input",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3075.0,
    "t_end": 3105.0,
    "text": "under the classification\nalgorithm classification is a supervised learning approach in which the computer program\nlearns from the input given to it and then uses this learning to classify\nnew observation some examples of classification problems are speech organization\nhandwriting recognized. Shouldn't biometric\nidentification document classification Etc. So next is the anomaly\ndetection algorithm where you identify\nthe unusual data point. So what is an anomaly detection. Well, it's a technique that is used to\nidentify unusual pattern",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3100.0,
    "t_end": 3130.0,
    "text": "where you identify\nthe unusual data point. So what is an anomaly detection. Well, it's a technique that is used to\nidentify unusual pattern that does not conform\nto expected Behavior or you can say the outliers. It has many application in business like\nintrusion detection, like identifying strange\npatterns in the network traffic that could signal a hack\nor system Health monitoring that is sporting a deadly tumor\nin the MRI scan or you can even use it for fraud detection\ncredit card transaction or to deal with fault detection\nin operating environment. So next comes\nthe clustering algorithm,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3125.0,
    "t_end": 3155.0,
    "text": "for fraud detection\ncredit card transaction or to deal with fault detection\nin operating environment. So next comes\nthe clustering algorithm, you can use this clustering\nalgorithm to group the data based on some similar condition. Now you can get answer\nto which type of houses lies in this segment or what type\nof customer buys this product. The clustering is a task\nof dividing the population or data points into\nnumber of groups such that the data point\nand the same groups are more. Hello to other data points\nin the same group than those in the other groups\nin simple words.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3150.0,
    "t_end": 3180.0,
    "text": "that the data point\nand the same groups are more. Hello to other data points\nin the same group than those in the other groups\nin simple words. The aim is to segregate\ngroups with similar trait and assigning them into cluster. Now this clustering is a task\nof dividing the population or data points into\na number of groups such that the data points in the X group is more similar\nto the other data points in the same group rather than\nthose in the other group. In other words. The aim is to segregate\nthe groups with similar traits and assigning them\ninto different clusters. Let's understand this with an example Suppose you are\nthe head of a rental store",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3175.0,
    "t_end": 3205.0,
    "text": "The aim is to segregate\nthe groups with similar traits and assigning them\ninto different clusters. Let's understand this with an example Suppose you are\nthe head of a rental store and you wish to understand\nthe preference of your customer to scale up your business. So is it possible for you to look at the detail\nof each customer and design a unique business strategy\nfor each of them? Definitely not right? But what you can do is to\nCluster all your customer saying to 10 different groups based\non their purchasing habit and you can use\na separate strategy for customers in each\nof these ten different groups.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3200.0,
    "t_end": 3230.0,
    "text": "to 10 different groups based\non their purchasing habit and you can use\na separate strategy for customers in each\nof these ten different groups. And this is\nwhat we call clustering. Next we have regression\nalgorithm where the data itself is predicted question. You may ask to this type\nof model is like what is the market value of this house or is it going to rain\ntomorrow or not? So regression is one of the most\nimportant and broadly used machine learning\nand statistics tool. It allows you to make prediction\nfrom data by learning the relationship between\nthe features of your data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3225.0,
    "t_end": 3255.0,
    "text": "used machine learning\nand statistics tool. It allows you to make prediction\nfrom data by learning the relationship between\nthe features of your data and some observe continuous\nvalued response regulation is used in a massive\nnumber of application. You know, what stock Isis\nprediction can be done using regression now, you know about different\nmachine learning algorithm. How will you decide\nwhich algorithm to choose and when so let's cover\nthis part using a demo. So in this demo part what we will do will create six\ndifferent machine learning model and pick the best model\nand build the confidence such",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3250.0,
    "t_end": 3280.0,
    "text": "what we will do will create six\ndifferent machine learning model and pick the best model\nand build the confidence such that it has the most\nreliable accuracy. So far our demo part\nwill be using the IRS data set. This data set is\nquite very famous and is considered one of\nthe best small project to start with you can consider this as a hello world data set\nfor machine learning. So this data set consists of 150 observation\nof Iris flower. Therefore Columns of measurement\nof flowers in centimeters the fifth column\nbeing the species of the flower observe all\nthe observed flowers belong",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3275.0,
    "t_end": 3305.0,
    "text": "Therefore Columns of measurement\nof flowers in centimeters the fifth column\nbeing the species of the flower observe all\nthe observed flowers belong to one of the three species\nof Iris setosa Iris virginica and Iris versicolor. Well, this is\na good good project because it is so\nwell to understand the attributes are numeric. So you have to figure out\nhow to load and handle the data. It is a classification problem. Thereby allowing you to practice with perhaps an easier type of\nsupervised learning algorithm. It has only four\nattributes and 150 rose. Meaning it is very small and can easily fit\ninto the memory and even all",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3300.0,
    "t_end": 3330.0,
    "text": "with perhaps an easier type of\nsupervised learning algorithm. It has only four\nattributes and 150 rose. Meaning it is very small and can easily fit\ninto the memory and even all of the numeric attributes\nare in same unit and the same scale means you do\nnot require any special scaling or transformation\nto get started. So let's start coding and\nas I told earlier for the But I'll be using Anaconda\nwith python 3.0 install on it. So when you install Anaconda how your Navigator\nwould look like. So there's my home page of\nmy anaconda navigator on this. I'll be using\nthe jupyter notebook,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3325.0,
    "t_end": 3355.0,
    "text": "how your Navigator\nwould look like. So there's my home page of\nmy anaconda navigator on this. I'll be using\nthe jupyter notebook, which is a web-based interactive\nComputing notebook environment, which will help me to write and\nexecute my python codes on it. So let's hit the launch\nbutton and execute our jupyter notebook. So as you can see that my jupyter notebook\nis starting on localhost double eight nine zero. Okay, so there's\nmy jupyter notebook what I'll do here. I'll select new. book Python 3 Does\nmy environment where I can write and execute all\nmy python codes on it?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3350.0,
    "t_end": 3380.0,
    "text": "book Python 3 Does\nmy environment where I can write and execute all\nmy python codes on it? So let's start\nby checking the version of the libraries in order\nto make this video short and more interactive\nand more informative. I've already written\nthe set of code. So let me just copy\nand paste it down. I'll explain you\nthen one by one. So let's start by checking the version\nof the Python libraries. Okay, so there is\nthe code let's just copy it copied and let's paste it. Okay first let me summarize things for you\nwhat we are doing here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3375.0,
    "t_end": 3405.0,
    "text": "it copied and let's paste it. Okay first let me summarize things for you\nwhat we are doing here. We are just checking the version of the different\nlibraries starting with python will first\ncheck what version of python we are working\non then we'll check what are the version\nof sci-fi we are using the numpy matplotlib then\nPanda then scikit-learn. Okay. So let's execute\nthe Run button and see what are the various\nversions of libraries which we are using it the run. So we are working on Python 3\npoint 6 point 4 PSI by 1.0 now. By 1.1 for matplotlib 2.12\npandas 0.22 and scikit-learn",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3400.0,
    "t_end": 3430.0,
    "text": "So we are working on Python 3\npoint 6 point 4 PSI by 1.0 now. By 1.1 for matplotlib 2.12\npandas 0.22 and scikit-learn or version 0.19. Okay. So these are the version which I'm using ideally your\nversion should be more recent or it should match\nbut don't worry if you lack\na few versions behind as the API is do not change\nso quickly everything in this tutorial will very\nlikely still work for you. Okay, but in case you are getting an error stop\nand try to fix that error in case you are unable to find\nthe solution for the error, feel free to reach out at Eureka\neven after the This class.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3425.0,
    "t_end": 3455.0,
    "text": "are getting an error stop\nand try to fix that error in case you are unable to find\nthe solution for the error, feel free to reach out at Eureka\neven after the This class. Let me tell you this if you are not able to run\nthe script properly, you will not be able\nto complete this tutorial. Okay, so whenever you\nget a doubt reach out to a deal-breaker\nand just resolve it now, everything is working\nsmoothly then now is the time to load the data set. So as I said, I'll be using the iris flower\ndata set for this tutorial but before loading the data set, let's import all the modules\nfunction and the object which we are going to use\nin this tutorial same",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3450.0,
    "t_end": 3480.0,
    "text": "but before loading the data set, let's import all the modules\nfunction and the object which we are going to use\nin this tutorial same I've already written\nthe set of code. So let's just copy\nand paste them. Let's load all the libraries. So these are\nthe various libraries which will be using\nin our tutorial. So everything should work\nfine without an error. If you get an error just\nstop you need to work on your cyber environment\nbefore you continue any further. So I guess everything\nshould work fine. Let's hit the Run\nbutton and see. Okay, it worked. So let's now move ahead\nand load the data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3475.0,
    "t_end": 3505.0,
    "text": "Let's hit the Run\nbutton and see. Okay, it worked. So let's now move ahead\nand load the data. We can load the data direct from the UCI machine\nlearning repository. First of all, let me tell you we are using\nPanda to load the data. Okay. So let's say my URL. Is this so This is My URL for the use\nyour machine learning repository from where I will be\ndownloading the data set. Okay. Now what I'll do, I'll specify the name\nof each column when loading the data. This will help me later\nto explore the data. Okay, so I'll just copy\nand paste it down.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3500.0,
    "t_end": 3530.0,
    "text": "This will help me later\nto explore the data. Okay, so I'll just copy\nand paste it down. Okay, so I'm defining\na variable names which consists of\nvarious parameters including sepal length sepal\nwidth petal length battle with and class. So these are just the name\nof column from the data set. Okay. Now let's define the data set. So data set equals Panda\ndot read underscore CSV inside that we are defining\nURL and the names that is equal to name. As I already said we'll be using\nPanda to load the data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3525.0,
    "t_end": 3555.0,
    "text": "that we are defining\nURL and the names that is equal to name. As I already said we'll be using\nPanda to load the data. Alright, so we are using\nPanda dot read CSV, so we are reading. The CSV file and inside that from where that CSV is coming\nfrom the URL which you are. So there's my URL. Okay name sequel names. It's just specifying the names\nof the various columns in that particular CSV file. Okay. So let's move forward\nand execute it. So even our data set is loaded. In case you have some network\nissues just go ahead",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3550.0,
    "t_end": 3580.0,
    "text": "So let's move forward\nand execute it. So even our data set is loaded. In case you have some network\nissues just go ahead and download the iris data file\ninto your working directory and loaded using the same method\nbut your make sure that you change the url\nto the local name or else you might get an error. Okay. Yeah, our data set is loaded. So let's move ahead\nand check out data set. Let's see how many columns\nor rows we have in our data set. Okay. So let's print the number of rows and columns\nin our data set. So our data set is\ndata set dot shape what this will do. It will just give you\nthe numbers of total number",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3575.0,
    "t_end": 3605.0,
    "text": "of rows and columns\nin our data set. So our data set is\ndata set dot shape what this will do. It will just give you\nthe numbers of total number of rows and 2. Little more of column\nor you can say the total number of instances are attributes\nin your data set fine. So print data set dot shape\naudio getting 150 and 500. So 150 is the total number\nof rows in your data set and five is the total number\nof columns fine. So moving on ahead. What if I want to see\nthe sample data set? Okay. So let me just print\nthe first certain instances of the data set. Okay, so print data set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3600.0,
    "t_end": 3630.0,
    "text": "What if I want to see\nthe sample data set? Okay. So let me just print\nthe first certain instances of the data set. Okay, so print data set. Head. What I want is the first\n30 instances fine. This will give me the first\n30 result of my data set. Okay. So when I hit the Run button what I am getting is\nthe first 30 result, okay 0 to 29. So this is how my sample data set looks\nlike sepal length sepal width petal and petal width\nand the class, okay.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3625.0,
    "t_end": 3655.0,
    "text": "how my sample data set looks\nlike sepal length sepal width petal and petal width\nand the class, okay. So this is how our data\nset looks like now, let's move on and look at the summary\nof each attribute. What if I want to find out\nthe count mean the minimum and the maximum values and\nsome other percentiles as well. So what should I do then for that print data\nset dot described. What did we give let's see. So you can see that all the numbers are\nthe same scales of similar range",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3650.0,
    "t_end": 3680.0,
    "text": "What did we give let's see. So you can see that all the numbers are\nthe same scales of similar range between 0 to 8 centimeters, right the mean value\nthe standard deviation the minimum value\nthe 25 percentile 50 percentile 75 percentile the maximum value all\nthese values lies in the range between\n0 to 8 centimeter. Okay. So what we just did is\nwe just took a summary of each attribute. Now, let's look\nat the number of instances that belong to each class. So for that what we'll do\nprint data set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3675.0,
    "t_end": 3705.0,
    "text": "of each attribute. Now, let's look\nat the number of instances that belong to each class. So for that what we'll do\nprint data set. First of all, so let's print data set and I want to group it\nGroup by using class and I want the size\nof it size of each class fine, and let's hit the Run.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3700.0,
    "t_end": 3730.0,
    "text": "Okay. So what I want to do, I want to print\nprint out data set. However want to get it. I want it by class. So Group by class. Okay. Now I want the size of each class find\nthe size of each class. So Group by class dot size\nand skewed the run so you can see that I have 50 instances\nof Iris setosa 50 instances",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3725.0,
    "t_end": 3755.0,
    "text": "So Group by class dot size\nand skewed the run so you can see that I have 50 instances\nof Iris setosa 50 instances of Iris versicolor and 50 instances\nof Iris virginica. Okay, all our of data type\ninteger of base64 fine. So now we have a basic\nidea of Data, now, let's move ahead and create\nsome visualization for it. So for this we are going\nto create two different types of plot first would be\nthe univariate plot and the next would be\nthe multivariate plot. So we'll be creating univariate\nplots to better understand about each attribute and the next will be creating\nthe multivariate plot to better",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3750.0,
    "t_end": 3780.0,
    "text": "and the next would be\nthe multivariate plot. So we'll be creating univariate\nplots to better understand about each attribute and the next will be creating\nthe multivariate plot to better understand the relationship\nbetween different attributes. Okay. So we start with\nsome univariate plot that is plot\nof each individual variable. So given that the input\nvariables are numeric we can create box\nand whiskers plot for it. Okay. So let's move ahead and create\na box and whiskers plot so data set Dot Plot. What kind I want it's a box. Okay, I'm do I need a subplot? Yeah, I need subplots for that. So subplots equal to what type",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3775.0,
    "t_end": 3805.0,
    "text": "Okay, I'm do I need a subplot? Yeah, I need subplots for that. So subplots equal to what type of layout do I won't so\nmy layout structure is 2 cross 2 next do I want\nto share my coordinates X and Y coordinates. No, I don't want to share it. So share x equal false and even share why\nthat 2 equals false? Okay. So we have our data set\nDot Plot kind equal box. My subplots is to lay out\nto Us too and then what I want to do it,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3800.0,
    "t_end": 3830.0,
    "text": "So we have our data set\nDot Plot kind equal box. My subplots is to lay out\nto Us too and then what I want to do it, I want to see so Plot show\nwhatever I created short. Okay, execute it. Not just gives us\na much clearer idea about the distribution\nof the input attribute. Now what if I had given\nthe layout to 2 cross 2 instead of that I would have given\nit for cross for so what it will result\njust see fine. Everything would be printed\nin just one single row. Hold on guys area is a doubt. He's asking that why\nwe're using the sheriff's and share y values.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3825.0,
    "t_end": 3855.0,
    "text": "Everything would be printed\nin just one single row. Hold on guys area is a doubt. He's asking that why\nwe're using the sheriff's and share y values. What are these why we have\nassigned false values to it? Okay Ariel. So in order to\nresolve this query, I need to show you\nwhat will happen if I give True Values to them. Okay, so be with me\nso share its go. Pull through and share why\nthat equals true. So let's see\nwhat result will get. You're getting it the X and y-coordinates are just\nshared among all the for visualization. Right? So are you can see that the sepal length\nand sepal width has y values ranging from zero point\nzero two seven point five",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3850.0,
    "t_end": 3880.0,
    "text": "and y-coordinates are just\nshared among all the for visualization. Right? So are you can see that the sepal length\nand sepal width has y values ranging from zero point\nzero two seven point five which are being shared among both the visualization so\nis with the petal length. It has shared value between zero point\nzero two seven point five. Okay, so that is why\nI don't want to share the value of X and Y, so it's just giving us\na cluttered visualization. So Aria why I'm doing this. I'm just doing it cause I don't want my X\nand Y coordinates To be shared among any visualization. Okay. That is why my share X and share\nby value are false.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3875.0,
    "t_end": 3905.0,
    "text": "cause I don't want my X\nand Y coordinates To be shared among any visualization. Okay. That is why my share X and share\nby value are false. Okay, let's execute it. So this is a pretty\nmuch Clear visualization which gives a clear idea\nabout the distribution of the input attribute. Now if you want you\ncan also create a histogram of each input variable\nto get a clear idea of the distribution. So let's create\na histogram for it. So data set dot his okay. I would need to see it. So plot dot show. Let's see. So there's my histogram\nand it seems that we have two input variables\nthat have a go.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3900.0,
    "t_end": 3930.0,
    "text": "So plot dot show. Let's see. So there's my histogram\nand it seems that we have two input variables\nthat have a go. And distribution so\nthis is useful to note as we can use the algorithms that can exploit\nthis assumption. Okay. So next comes\nthe multivariate lat now that we have created the\nunivariate plot to understand about each attribute. Let's move on and look\nat the multivariate plot and see the interaction between\nthe different variables. So first, let's look\nat the scatter plot of all the attribute\nthis can be helpful to spot structured relationship\nbetween input variables. Okay. So let's create\na scatter Matrix.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3925.0,
    "t_end": 3955.0,
    "text": "of all the attribute\nthis can be helpful to spot structured relationship\nbetween input variables. Okay. So let's create\na scatter Matrix. So for creating a scatter plot,\nwe need scatter Matrix, and we need to pass\nour data set into It okay. And then what I want\nI want to see it. So plot dot show. So this is\nhow my scatter Matrix looks like it's like that the diagonal grouping\nof some pear, right? So this suggests\na high correlation and a predictable relationship. All right. This was our multivariate plot. Now, let's move on\nand evaluate some algorithm that's time to create\nsome model of the data and estimate the accuracy\non the basis of unseen data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3950.0,
    "t_end": 3980.0,
    "text": "This was our multivariate plot. Now, let's move on\nand evaluate some algorithm that's time to create\nsome model of the data and estimate the accuracy\non the basis of unseen data. Okay. So now we know all\nabout our data set, right? We know how many instances and attributes are\nthere in our data set. We know the summary\nof each attribute. So I guess we have seen much\nabout our data set. Now. Let's move on\nand create some algorithm and estimate their accuracy\nbased on the Unseen data. Okay. Now what we'll do we'll create\nsome model of the data and estimate the accuracy based\non the some unseen data. Okay. So for that first of all,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 3975.0,
    "t_end": 4005.0,
    "text": "Now what we'll do we'll create\nsome model of the data and estimate the accuracy based\non the some unseen data. Okay. So for that first of all, let's create a\nvalidation data set. What is the validation data\nset validation data set is your training data set that will be using it\nto trainer model fine. All right. So how will create\na validation data set for creating\na validation data set? What we are going to do is we\nare going to split our data set into two point. Okay. So the very first thing\nwe'll do is to create a validation data set. So why do we even need\na validation data set? So we need a validation\ndata set know that the model we\ncreated is any good later.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4000.0,
    "t_end": 4030.0,
    "text": "So why do we even need\na validation data set? So we need a validation\ndata set know that the model we\ncreated is any good later. What we'll do we'll use\nthe statistical method to estimate the accuracy\nof the model that we create on the Unseen data. We also want a more concrete\nestimate of the accuracy of the best model on unseen data by evaluating it\non the actual unseen data. Okay confused. Let me simplify this for you. What we'll do we'll\nsplit the loaded data into two parts the first\n80 percent of the data. User to train our model\nand the rest 20% will hold back as the validation data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4025.0,
    "t_end": 4055.0,
    "text": "into two parts the first\n80 percent of the data. User to train our model\nand the rest 20% will hold back as the validation data set that will use it to verify\nour trained model. Okay fine. So let's define an array. This is my ra water it\nwill consist of will consist of all the values\nfrom the data set. So data set dot values. Okay next. I'll Define a variable X which will consist\nof all the column from the array from 0\nto 4 starting from 0 to 4 and the next variable Y which would consist of\nof the array starting from this.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4050.0,
    "t_end": 4080.0,
    "text": "from the array from 0\nto 4 starting from 0 to 4 and the next variable Y which would consist of\nof the array starting from this. So first of all, we will Define a variable X\nthat will consist of the values in the array starting\nfrom the beginning 0 Del for okay. So these are the column\nwhich will include in the X variable and for a y variable I'll Define\nit as a class or the output. So what I need, I just need the fourth column\nthat is my class column. So I'll start it\nfrom the beginning and I just want\nthe fourth column.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4075.0,
    "t_end": 4105.0,
    "text": "I just need the fourth column\nthat is my class column. So I'll start it\nfrom the beginning and I just want\nthe fourth column. Okay now I'll Define\nthe my validation size. Validation underscore sighs, I'll Define it as 0.20\nand our use a seed I Define CD equals 6. So this method seed sets\nthe integers starting value used in generating random number. Okay, I'll Define the value\nof C R equals x. I'll tell you what is\nthe importance of that later on? Okay. So let me Define first\nfew variables such as X",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4100.0,
    "t_end": 4130.0,
    "text": "Okay, I'll Define the value\nof C R equals x. I'll tell you what is\nthe importance of that later on? Okay. So let me Define first\nfew variables such as X underscore train test\nwhy underscore train and why underscore test Okay, so What do you want to do\nis Select some model. Okay, so module\nunderscore selection. But before doing that what we have to do\nis split our training data set into two halves. Okay, so dot train underscore\ntest underscore split what you want to split\nis a value of X and Y. Okay and my test size is equals\nto validation size,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4125.0,
    "t_end": 4155.0,
    "text": "Okay, so dot train underscore\ntest underscore split what you want to split\nis a value of X and Y. Okay and my test size is equals\nto validation size, which is a 0.20 correct\nand my random state. Is equal to seed\nso what the city is doing? It's helping me to keep the same\nRandomness in the training and testing data set fine. So let's execute it and see\nwhat is our result. It's executed next. We'll create a test\nharness for this. We'll use 10-fold\ncross-validation to",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4150.0,
    "t_end": 4180.0,
    "text": "So let's execute it and see\nwhat is our result. It's executed next. We'll create a test\nharness for this. We'll use 10-fold\ncross-validation to estimate the accuracy. So what it will do it\nwill split a data set into 10 parts crane\non the nine part and test on the one part and this will repeat\nfor all combination of train and test pilots. Okay. So for that, let's define again my CD\nthat was six already Define and scoring\nequals accuracy fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4175.0,
    "t_end": 4205.0,
    "text": "let's define again my CD\nthat was six already Define and scoring\nequals accuracy fine. So we are using the metric of\naccuracy to evaluate the model. So what is this? This is a ratio of number\nof correctly predicted instances divided by the total number\nof instances in the data set x hundred giving a\npercentage example. It's 98% accurate or 99%\naccurate things like that. Okay, so we'll be\nIn the scoring variable when we run the build and evaluate each model\nin the next step. The next part is building\nmodel till now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4200.0,
    "t_end": 4230.0,
    "text": "Okay, so we'll be\nIn the scoring variable when we run the build and evaluate each model\nin the next step. The next part is building\nmodel till now. We don't know which algorithm\nwould be good for this problem or what configuration to use. So let's begin with\nsix different algorithm. I'll be using logistic regression linear\ndiscriminant analysis, k-nearest neighbor\nclassification and regression trees neighbor buys. And what Vector machine well these algorithms chime using is\na good mixture of simple linear or non-linear algorithms\nin simple linear switch. Included the logistic regression",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4225.0,
    "t_end": 4255.0,
    "text": "these algorithms chime using is\na good mixture of simple linear or non-linear algorithms\nin simple linear switch. Included the logistic regression and the linear discriminant\nanalysis or the nonlinear part which included the KNN\nalgorithm the card algorithm that the neighbor buys\nand the support Vector machines. Okay. So we reset\nthe random number seed before each run\nto ensure that evaluation of each algorithm is performed using exactly\nthe same data spreads. It ensures the result\nare directly comparable. Okay, so, let me\njust copy and paste it. Okay.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4250.0,
    "t_end": 4280.0,
    "text": "Okay, so, let me\njust copy and paste it. Okay. So what we're doing here, we are building\nfive different types of model. We are building\nlogistic regression linear discriminant analysis, k-nearest neighbor decision\ntree ghajini buys and the support Vector machine. Okay next what we'll do we'll\nevaluate model in each turn. Okay. So what is this? So we have six different model and accuracy estimation\nfor each one of them now we need to compare\nthe model to each other and select the most\naccurate of them all.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4275.0,
    "t_end": 4305.0,
    "text": "and accuracy estimation\nfor each one of them now we need to compare\nthe model to each other and select the most\naccurate of them all. So running the script we\nsaw the following result so we can see some\nof the results on the screen. What is It is just the accuracy score using\ndifferent set of algorithms. Okay, when we are using\nlogistic regression, what is the accuracy rate when we are using\nlinear discriminant algorithm? What is the accuracy\nand so-and-so? Okay. So from the output with seems that LD algorithm was\nthe most accurate model that we tested now, we want to get an idea\nof the accuracy of the model",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4300.0,
    "t_end": 4330.0,
    "text": "that LD algorithm was\nthe most accurate model that we tested now, we want to get an idea\nof the accuracy of the model on our validation set\nor the testing data set. So this will give us\nan independent final check on the accuracy\nof the best model. It is always valuable\nto keep our testing data set for just in case you\nmade a our overfitting to the testing data set or you made a data leak\nboth will result in an overly optimistic result. Okay, you can run the ldo model\ndirectly on the validation set and summarize the result as\na final score a confusion Matrix and a classification statistics\nand probability are essential",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4325.0,
    "t_end": 4355.0,
    "text": "Okay, you can run the ldo model\ndirectly on the validation set and summarize the result as\na final score a confusion Matrix and a classification statistics\nand probability are essential because these disciples\nform the basic Foundation of all machine learning\nalgorithms deep learning. Social intelligence\nand data science, in fact mathematics\nand probability is behind everything around us\nfrom shapes patterns and colors to the count",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4350.0,
    "t_end": 4380.0,
    "text": "in fact mathematics\nand probability is behind everything around us\nfrom shapes patterns and colors to the count of petals in a flower\nmathematics is embedded in each and every\naspect of our lives. So I'm going to go ahead\nand discuss the agenda for today with you\nall we're going to begin the session by understanding what is data after that. We'll move on and look\nat the different categories of data like quantitative\nand Qualitative data, then we'll discuss what\nexactly statistics is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4375.0,
    "t_end": 4405.0,
    "text": "of data like quantitative\nand Qualitative data, then we'll discuss what\nexactly statistics is the basic terminologies in\nstatistics and a couple of sampling techniques. Once we're done with that. We'll discuss a different\ntypes of Statistics which involve descriptive\nand inferential statistics. Then in the next session, we will mainly be focusing\non descriptive statistics here will understand\nthe different measures of center measures\nof spread Information Gain and entropy will also understand all of these measures\nwith the help of a user.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4400.0,
    "t_end": 4430.0,
    "text": "of center measures\nof spread Information Gain and entropy will also understand all of these measures\nwith the help of a user. And finally, we'll discuss what\nexactly a confusion Matrix is. Once we've covered the entire descriptive\nstatistics module will discuss the probability module here will understand\nwhat exactly probability is the different\nterminologies in probability. We will also study the different\nprobability distributions, then we'll discuss the types\nof probability which include",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4425.0,
    "t_end": 4455.0,
    "text": "We will also study the different\nprobability distributions, then we'll discuss the types\nof probability which include marginal probability joint\nand conditional probability. Then we move on and discuss a use case\nwherein we will see examples that show us how the different types\nof probability work and to better\nunderstand Bayes theorem. We look at a small example. Also, I forgot to mention that at the end of the\ndescriptive statistics module will be running a small demo\nin the our language. So for those of you\nwho don't know much",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4450.0,
    "t_end": 4480.0,
    "text": "that at the end of the\ndescriptive statistics module will be running a small demo\nin the our language. So for those of you\nwho don't know much about our I'll be explaining\nevery line in depth, but if you want to have\na more in-depth understanding about our I'll leave\na couple of blocks. And a couple of videos\nin the description box you all can definitely\ncheck out that content. Now after we've completed the\nprobability module will discuss the inferential statistics\nmodule will start this module by understanding what is point\nestimation will discuss",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4475.0,
    "t_end": 4505.0,
    "text": "the inferential statistics\nmodule will start this module by understanding what is point\nestimation will discuss what is confidence interval\nand how you can estimate the confidence interval will\nalso discuss margin of error and will understand all\nof these concepts by looking at a small use case. We finally end the inferential\nReal statistic module by looking at what hypothesis\ntesting is hypothesis. Testing is a very important part\nof inferential statistics. So we'll end the session\nby looking at a use case",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4500.0,
    "t_end": 4530.0,
    "text": "Testing is a very important part\nof inferential statistics. So we'll end the session\nby looking at a use case that discusses how\nhypothesis testing works and to sum everything up. We'll look at a demo that explains how\ninferential statistics works. Right? So guys, there's\na lot to cover today. So let's move ahead and take\na look at our first topic which is what is data. Now, this is\na quite simple question if I ask any of You\nwhat is data? You'll see that it's\na set of numbers or some sort of documents that have stored in my computer\nnow data is actually everything.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4525.0,
    "t_end": 4555.0,
    "text": "if I ask any of You\nwhat is data? You'll see that it's\na set of numbers or some sort of documents that have stored in my computer\nnow data is actually everything. All right, look around you there\nis data everywhere each click on your phone generates\nmore data than you know, now this generated data\nprovides insights for analysis and helps us make\nBetter Business decisions. This is why data is\nso important to give you a formal definition data refers\nto facts and statistics. Collected together\nfor reference or analysis.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4550.0,
    "t_end": 4580.0,
    "text": "This is why data is\nso important to give you a formal definition data refers\nto facts and statistics. Collected together\nfor reference or analysis. All right. This is the definition\nof data in terms of statistics and probability. So as we know data\ncan be collected it can be measured and analyzed it can be visualized by\nusing statistical models and graphs now data is divided\ninto two major subcategories. Alright, so first we\nhave qualitative data and quantitative data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4575.0,
    "t_end": 4605.0,
    "text": "and graphs now data is divided\ninto two major subcategories. Alright, so first we\nhave qualitative data and quantitative data. These are the two\ndifferent types of data under qualitative data. I'll be have nominal\nand ordinal data and under quantitative data. We have discrete\nand continuous data. Now, let's focus\non qualitative data. Now this type of data deals with\ncharacteristics and descriptors that can't be easily measured but can be observed subjectively now qualitative data\nis further divided",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4600.0,
    "t_end": 4630.0,
    "text": "that can't be easily measured but can be observed subjectively now qualitative data\nis further divided into nominal and ordinal data. So nominal data is\nany sort of data that doesn't have\nany order or ranking? Okay. An example of nominal\ndata is gender. Now. There is no ranking in gender. There's only male female\nor other right? There is no one two, three four or any sort\nof ordering in gender race is another example of nominal data. Now ordinal data is basically an\nordered series of information.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4625.0,
    "t_end": 4655.0,
    "text": "three four or any sort\nof ordering in gender race is another example of nominal data. Now ordinal data is basically an\nordered series of information. Okay, let's say\nthat you went to a restaurant. Okay. Your information is stored\nin the form of customer ID. All right. So basically you are represented\nwith a customer ID. Now you would have rated\ntheir service as either good or average. All right, that's\nhow no ordinal data is and similarly they'll have\na record of other customers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4650.0,
    "t_end": 4680.0,
    "text": "All right, that's\nhow no ordinal data is and similarly they'll have\na record of other customers who visit the restaurant\nalong with their ratings. All right. So any data which has\nsome sort of sequence or some sort of order\nto it is known as ordinal data. All right, so guys, this is pretty simple\nto understand now, let's move on and look\nat quantitative data. So quantitative data\nbasically these He's with numbers and things. Okay, you can understand that by the word quantitative\nitself quantitative is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4675.0,
    "t_end": 4705.0,
    "text": "with numbers and things. Okay, you can understand that by the word quantitative\nitself quantitative is basically quantity. Right Saudis with numbers\na deals with anything that you can measure\nobjectively, right? So there are two types of quantitative data there is\ndiscrete and continuous data now discrete data is also\nknown as categorical data and it can hold a finite number\nof possible values. Now, the number of students\nin a class is a finite Number.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4700.0,
    "t_end": 4730.0,
    "text": "and it can hold a finite number\nof possible values. Now, the number of students\nin a class is a finite Number. All right, you can't\nhave infinite number of students in a class. Let's say in your fifth grade. There were a hundred students\nin your class. All right, there weren't\ninfinite number but there was a definite finite number\nof students in your class. Okay, that's discrete data. Next. We have continuous data. Now this type of data\ncan hold infinite number of possible values. Okay. So when you say weight\nof a person is an example of continuous data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4725.0,
    "t_end": 4755.0,
    "text": "Okay. So when you say weight\nof a person is an example of continuous data what I mean to see is\nmy weight can be 50 kgs or it Can be 50.1 kgs or it can be 50.00 one kgs\nor 50.000 one or is 50.0 2 3 and so on right? There are infinite number\nof possible values, right? So this is what I mean\nby continuous data. All right. This is the difference between\ndiscrete and continuous data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4750.0,
    "t_end": 4780.0,
    "text": "So this is what I mean\nby continuous data. All right. This is the difference between\ndiscrete and continuous data. And also I would like to mention\na few other things over here. Now, there are a couple\nof types of variables as well. We have a discrete variable and we have a continuous\nvariable discrete variable is also known as\na categorical variable or and it can hold values\nof different categories. Let's say that you have\na variable called message",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4775.0,
    "t_end": 4805.0,
    "text": "or and it can hold values\nof different categories. Let's say that you have\na variable called message and there are two types\nof values that this variable can hold let's say that your message\ncan either be a Spam message or a non spam message. Okay, that's when you call\na variable as discrete or categorical variable. All right, because it\ncan hold values that represent different\ncategories of data now continuous variables\nare basically variables that can store in\nfinite number of values.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4800.0,
    "t_end": 4830.0,
    "text": "now continuous variables\nare basically variables that can store in\nfinite number of values. So the weight of a person\ncan be denoted as a continuous variable. All right, let's say there is\na variable called weight and it can store infinite number\nof possible values. That's why we'll call it\na continuous variable. So guys basically\nvariable is anything that can store a value right? So if you associate any sort\nof data with a A table, then it will become\neither discrete variable or continuous variable. There is also dependent and\nindependent type of variables.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4825.0,
    "t_end": 4855.0,
    "text": "So if you associate any sort\nof data with a A table, then it will become\neither discrete variable or continuous variable. There is also dependent and\nindependent type of variables. Now, we won't discuss all\nwith that in depth because that's pretty understandable. I'm sure all of you know, what is independent variable\nand dependent variable right? Dependent variable is\nany variable whose value depends on any other\nindependent variable? So guys that much\nknowledge I expect or if you do have all right. So now let's move on and look\nat our next topic which Which is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4850.0,
    "t_end": 4880.0,
    "text": "if you do have all right. So now let's move on and look\nat our next topic which Which is what is statistics now coming\nto the formal definition of statistics statistics is\nan area of Applied Mathematics, which is concerned with data collection\nanalysis interpretation and presentation now usually when I speak about statistics\npeople think statistics is all about analysis but statistics has other path\ntoward it has data collection is also part of Statistics data\ninterpretation presentation.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4875.0,
    "t_end": 4905.0,
    "text": "but statistics has other path\ntoward it has data collection is also part of Statistics data\ninterpretation presentation. All of this comes into statistics already are\ngoing to use statistical methods to visualize data to collect\ndata to interpret data. Alright, so the area\nof mathematics deals with understanding how data can be used\nto solve complex problems. Okay. Now I'll give you\na couple of examples that can be solved\nby using statistics.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4900.0,
    "t_end": 4930.0,
    "text": "how data can be used\nto solve complex problems. Okay. Now I'll give you\na couple of examples that can be solved\nby using statistics. Okay, let's say that your company\nhas created a new drug that may cure cancer. How would you conduct\na test to confirm the As Effectiveness now, even though this sounds\nlike a biology problem. This can be\nsolved with Statistics. All right, you will have\nto create a test which can confirm\nthe effectiveness of the drum or a this is a common problem that can be solved\nusing statistics. Let me give you\nanother example you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4925.0,
    "t_end": 4955.0,
    "text": "which can confirm\nthe effectiveness of the drum or a this is a common problem that can be solved\nusing statistics. Let me give you\nanother example you and a friend are at a baseball\ngame and out of the blue. He offers you a bet that neither team will hit\na home run in that game. Should you take the BET? All right here you just\ndiscuss the probability of I know you'll win or lose. All right, this\nis another problem that comes under statistics. Let's look at another example. The latest sales data\nhas just come in and your boss wants\nyou to prepare a report",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4950.0,
    "t_end": 4980.0,
    "text": "Let's look at another example. The latest sales data\nhas just come in and your boss wants\nyou to prepare a report for management on places where the company\ncould improve its business. What should you look for? And what should you\nnot look for now? This problem involves a lot of data analysis will have to\nlook at the different variables that are causing\nyour business to go down or the you have to look\nat a few variables. That are increasing\nthe performance of your models and does growing your business. Alright, so this involves\na lot of data analysis",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 4975.0,
    "t_end": 5005.0,
    "text": "That are increasing\nthe performance of your models and does growing your business. Alright, so this involves\na lot of data analysis and the basic idea behind data analysis is\nto use statistical techniques in order to figure\nout the relationship between different variables or different components\nin your business. Okay. So now let's move on and look at our next topic which is basic\nterminologies and statistics. Now before you dive deep\ninto statistics, it is important that you understand\nthe basic terminologies",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5000.0,
    "t_end": 5030.0,
    "text": "Now before you dive deep\ninto statistics, it is important that you understand\nthe basic terminologies used in statistics. The two most important\nterminologies in statistics are population and Sample. So throughout the statistics\ncourse or throughout any problem that you're trying\nto stall with Statistics. You will come\nacross these two words, which is population and Sample\nNow population is a collection or a set of individuals\nor objects or events. Events whose properties\nare to be analyzed.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5025.0,
    "t_end": 5055.0,
    "text": "which is population and Sample\nNow population is a collection or a set of individuals\nor objects or events. Events whose properties\nare to be analyzed. Okay. So basically you can refer\nto population as a subject that you're trying to analyze\nnow a sample is just like the word suggests. It's a subset of the population. So you have to make sure\nthat you choose the sample in such a way that it represents\nthe entire population. All right. It shouldn't Focus add one part\nof the population instead. It should represent\nthe entire population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5050.0,
    "t_end": 5080.0,
    "text": "All right. It shouldn't Focus add one part\nof the population instead. It should represent\nthe entire population. That's how your sample\nshould be chosen. So Well chosen sample\nwill contain most of the information about a\nparticular population parameter. Now, you must be wondering\nhow can one choose a sample that best represents\nthe entire population now sampling is a statistical method that deals with the selection\nof individual observations within a population. So sampling is performed",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5075.0,
    "t_end": 5105.0,
    "text": "that deals with the selection\nof individual observations within a population. So sampling is performed in order to infer statistical\nknowledge about a population. All right, if you\nwant to understand the different statistics\nof a population like the mean the median Median the mode\nor the standard deviation or the variance of a population. Then you're going\nto perform sampling. All right, because it's not reasonable for\nyou to study a large population and find out the mean median\nand everything else. So why is sampling\nperformed you might ask?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5100.0,
    "t_end": 5130.0,
    "text": "because it's not reasonable for\nyou to study a large population and find out the mean median\nand everything else. So why is sampling\nperformed you might ask? What is the point of sampling? We can just study\nthe entire population now guys, think of a scenario where in you're asked\nto perform a survey about the eating habits\nof teenagers in the US. So at present there are\nover 42 million teens in the US and this number is growing as we are speaking\nright now, correct. Is it possible to survey each\nof these 42 million individuals",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5125.0,
    "t_end": 5155.0,
    "text": "as we are speaking\nright now, correct. Is it possible to survey each\nof these 42 million individuals about their health? Is it possible? Well, it might be possible but this will take\nforever to do now. Obviously, it's not it's\nnot reasonable to go around knocking each door and asking for what does\nyour teenage son eat and all of that right? This is not very reasonable. That's Why sampling is used? It's a method wherein a sample\nof the population is studied in order to draw inferences\nabout the entire population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5150.0,
    "t_end": 5180.0,
    "text": "It's a method wherein a sample\nof the population is studied in order to draw inferences\nabout the entire population. So it's basically\na shortcut to starting the entire population instead\nof taking the entire population and finding out\nall the solutions. You just going to take\na part of the population that represents the\nentire population and you're going to perform\nall your statistical analysis your inferential statistics\non that small sample. All right, and that sample basically here\nPresents the entire population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5175.0,
    "t_end": 5205.0,
    "text": "your inferential statistics\non that small sample. All right, and that sample basically here\nPresents the entire population. All right, so I'm sure\nhave made this clear to you all what is sample\nand what is population now? There are two main types\nof sampling techniques that are discussed today. We have probability sampling\nand non-probability sampling now in this video will only be focusing on\nprobability sampling techniques because non-probability sampling\nis not within the scope of this video. All right will only discuss\nthe probability part",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5200.0,
    "t_end": 5230.0,
    "text": "because non-probability sampling\nis not within the scope of this video. All right will only discuss\nthe probability part because we're focusing on Statistics and\nprobability correct. Now again under\nprobability sampling. We have three different types. We have random\nsampling systematic and stratified sampling. All right, and just\nto mention the different types of non-probability sampling zwi have\nno ball Kota judgment and convenience sampling. All right now guys\nin this session.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5225.0,
    "t_end": 5255.0,
    "text": "sampling zwi have\nno ball Kota judgment and convenience sampling. All right now guys\nin this session. I'll only be\nfocusing on probability. So let's move on and look at the different types\nof probability sampling. So what is Probability sampling. It is a sampling technique in which samples\nfrom a large population are chosen by using\nthe theory of probability. All right, so there\nare three types of probability sampling. All right first we have\nthe random sampling now in this method each member",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5250.0,
    "t_end": 5280.0,
    "text": "All right, so there\nare three types of probability sampling. All right first we have\nthe random sampling now in this method each member of the population\nhas an equal chance of being selected in the sample. All right. So each and every individual\nor each and every object in the population\nhas an equal chance of being a A part of the sample. That's what random\nsampling is all about. Okay, you are randomly going\nto select any individual or any object. So this Bay each individual has an equal chance\nof being selected.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5275.0,
    "t_end": 5305.0,
    "text": "Okay, you are randomly going\nto select any individual or any object. So this Bay each individual has an equal chance\nof being selected. Correct? Next. We have systematic sampling now in systematic sampling\nevery nth record is chosen from the population to be\na part of the sample. All right. Now refer this image that I've shown over here\nout of these six groups every Skinned group\nis chosen as a sample. Okay. So every second record\nis chosen here and this is our systematic sampling works.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5300.0,
    "t_end": 5330.0,
    "text": "every Skinned group\nis chosen as a sample. Okay. So every second record\nis chosen here and this is our systematic sampling works. Okay, you're randomly\nselecting the nth record and you're going to add\nthat to your sample. Next. We have stratified sampling. Now in this type of technique a stratum\nis used to form samples from a large population. So what is a stratum\na stratum is basically a subset of the population that shares at\nleast one comment. Characteristics so let's say that your population has a mix\nof both male and female",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5325.0,
    "t_end": 5355.0,
    "text": "of the population that shares at\nleast one comment. Characteristics so let's say that your population has a mix\nof both male and female so you can create to straightens out of this one will have\nonly the male subset and the other will have\nthe female subset or a this is what stratum is\nit is basically a subset of the population that shares at least\none common characteristics. All right in our example,\nit is gender. So after you've created a stratum you're going\nto use random sampling on the stratums and you're going\nto choose a final Samba.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5350.0,
    "t_end": 5380.0,
    "text": "All right in our example,\nit is gender. So after you've created a stratum you're going\nto use random sampling on the stratums and you're going\nto choose a final Samba. But so random sampling meaning that all of the individuals in each of the stratum\nwill have an equal chance of being selected\nin the sample, correct. So Guys, these were\nthe three different types of sampling techniques. Now, let's move on and look\nat our next topic which is the different\ntypes of Statistics. So after this, we'll be looking at the more\nadvanced concepts of Statistics,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5375.0,
    "t_end": 5405.0,
    "text": "which is the different\ntypes of Statistics. So after this, we'll be looking at the more\nadvanced concepts of Statistics, right so far we discuss\nthe basics of Statistics, which is basically what is statistics\nthe different sampling. Techniques and the\nterminologies and statistics. All right. Now we look at the different\ntypes of Statistics. So there are two major\ntypes of Statistics descriptive statistics and inferential statistics\nin today's session. We will be discussing\nboth of these types of Statistics in depth. All right, we'll also\nbe looking at a demo",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5400.0,
    "t_end": 5430.0,
    "text": "and inferential statistics\nin today's session. We will be discussing\nboth of these types of Statistics in depth. All right, we'll also\nbe looking at a demo which I'll be running\nin the our language in order to make\nyou understand what exactly descriptive and inferential\nstatistics is so guys, which is going to look\nat the 600 don't worry, if you don't\nhave much knowledge, I'm explaining everything\nfrom the basic level. All right, so guys descriptive\nstatistics is a method which is used to describe\nand understand the features",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5425.0,
    "t_end": 5455.0,
    "text": "All right, so guys descriptive\nstatistics is a method which is used to describe\nand understand the features of specific data set by giving\na short summary of the data. Okay, so it is mainly focused upon the\ncharacteristics of data. It also provides a graphical\nsummary of the data now in order to make you understand\nwhat descriptive statistics is, let's suppose. Pose that you want to gift all\nyour classmates or t-shirt. So to study the average\nshirt size of a student in a classroom.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5450.0,
    "t_end": 5480.0,
    "text": "Pose that you want to gift all\nyour classmates or t-shirt. So to study the average\nshirt size of a student in a classroom. So if you were to use\ndescriptive statistics to study the average shirt size\nof students in your classroom, then what you would do is you\nwould record the shirt size of all students in the class and then you would find out\nthe maximum minimum and average shirt size of the club. Okay. So coming to inferential\nstatistics inferential statistics makes Is and predictions about\na population based",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5475.0,
    "t_end": 5505.0,
    "text": "So coming to inferential\nstatistics inferential statistics makes Is and predictions about\na population based on the sample of data taken\nfrom the population? Okay. So in simple words, it generalizes a large data set\nand it applies probability to draw a conclusion. Okay. So it allows you\nto infer data parameters based on a statistical model\nby using sample data. So if we consider\nthe same example of finding the average shirt size\nof students in a class",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5500.0,
    "t_end": 5530.0,
    "text": "So if we consider\nthe same example of finding the average shirt size\nof students in a class in infinite shal statistics, you will take a sample. All set of the class which is basically a few people\nfrom the entire class. All right, you already\nhave had grouped the class into large medium and small. All right in this method\nyou basically build a statistical model and expand it for the entire\npopulation in the class. So guys, there was a brief\nunderstanding of descriptive and inferential statistics. So that's the difference\nbetween descriptive",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5525.0,
    "t_end": 5555.0,
    "text": "So guys, there was a brief\nunderstanding of descriptive and inferential statistics. So that's the difference\nbetween descriptive and inferential now\nin the next section, we will go in depth\nabout descriptive statistics. All right, so, That's a discuss more\nabout descriptive statistics. So like I mentioned earlier descriptive\nstatistics is a method that is used to describe\nand understand the features of a specific data set by giving\nshort summaries about the sample and measures of the data. There are two important measures\nin descriptive statistics.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5550.0,
    "t_end": 5580.0,
    "text": "of a specific data set by giving\nshort summaries about the sample and measures of the data. There are two important measures\nin descriptive statistics. We have measure\nof central tendency, which is also known as measure of center and we have\nmeasures of variability. This is also known as\nmeasures of spread. Ed so measures of center\ninclude mean median and mode now what is measures of center measures of the center\nare statistical measures that represent the summary\nof a data set?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5575.0,
    "t_end": 5605.0,
    "text": "of center measures of the center\nare statistical measures that represent the summary\nof a data set? Okay, the three main measures\nof center are mean median and mode coming\nto measures of variability or measures of spread. We have range\ninterquartile range variance and standard deviation. All right. So now let's discuss each of these measures\nin a little more. Up starting with\nthe measures of center. Now. I'm sure all of you know what\nthe mean is mean is basically",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5600.0,
    "t_end": 5630.0,
    "text": "Up starting with\nthe measures of center. Now. I'm sure all of you know what\nthe mean is mean is basically the measure of the average\nof all the values in a sample. Okay, so it's basically\nthe average of all the values in a sample. How do you measure the mean I\nhope all of you know how the main is measured if there are 10 numbers and you want to find the mean\nof these 10 numbers. All you have to do is you have\nto add up all the 10 numbers and you have to divide\nit by 10 then here represents the Number\nof samples in your data set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5625.0,
    "t_end": 5655.0,
    "text": "and you have to divide\nit by 10 then here represents the Number\nof samples in your data set. All right, since we\nhave 10 numbers, we're going to\ndivide this by 10. All right, this will\ngive us the average or the mean so to better\nunderstand the measures of central tendency. Let's look at an example. Now the data set over here is\nbasically the cars data set and it contains a few variables. All right, it has\nsomething known as cars. It has mileage per gallon cylinder\ntype displacement horsepower",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5650.0,
    "t_end": 5680.0,
    "text": "All right, it has\nsomething known as cars. It has mileage per gallon cylinder\ntype displacement horsepower and roll axle ratio. All right, all of these measures\nare related to cars. Okay. So what you're going\nto do is you're going to use descriptive analysis and you're going to analyze\neach of the variables in the sample data set for the mean standard\ndeviation median mode and so on. So let's say that you want\nto find out the mean or the average horsepower of the cars among\nthe population of cards.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5675.0,
    "t_end": 5705.0,
    "text": "So let's say that you want\nto find out the mean or the average horsepower of the cars among\nthe population of cards. Like I mentioned earlier what you'll do is you will check\nthe average of all the values. So in this case, we will take the sum\nof the horizontal. Horsepower of each car and we'll divide that\nby the total number of cards. Okay, that's exactly what I've done here\nin the calculation part. So this hundred\nand ten basically represents the horsepower\nfor the first car. Alright, similarly. I've just added up all\nthe values of horsepower",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5700.0,
    "t_end": 5730.0,
    "text": "represents the horsepower\nfor the first car. Alright, similarly. I've just added up all\nthe values of horsepower for each of the cars and I've divided it by 8 now\n8 is basically the number of cars in our data set. All right, so hundred and three\npoint six two five is what our mean is or Average\nof horsepower is all right. Now, let's understand\nwhat median is with an example? Okay. So to Define median median\nis basically a measure of the central value of the sample set\nis called the median.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5725.0,
    "t_end": 5755.0,
    "text": "So to Define median median\nis basically a measure of the central value of the sample set\nis called the median. All right, you can see\nthat it is a middle value. So if we want to find\nout the center value of the mileage per gallon\namong the population of cars first, what we'll do is we'll arrange\nthe MGP values in ascending or descending order and Choose a middle value\nright in this case since we have\neight values, right? We have eight values\nwhich is an even entry.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5750.0,
    "t_end": 5780.0,
    "text": "and Choose a middle value\nright in this case since we have\neight values, right? We have eight values\nwhich is an even entry. So whenever you have even\nnumber of data points or samples in your data set, then you're going\nto take the average of the two middle values. If we had nine values over here. We can easily figure\nout the middle value and you know choose\nthat as a median. But since they're even number\nof values we're going to take the average\nof the two middle values. All right, so, Eight and twenty three\nare my two middle values",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5775.0,
    "t_end": 5805.0,
    "text": "to take the average\nof the two middle values. All right, so, Eight and twenty three\nare my two middle values and I'm taking\nthe mean of those 2 and hence I get\ntwenty two point nine, which is my median. All right. Lastly let's look at\nhow mode is calculated. So what is mode the value that is most recurrent in the sample set is known as\nmode or basically the value that occurs most often. Okay, that is known as mode. So let's say that we want to find out\nthe most common type of cylinder",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5800.0,
    "t_end": 5830.0,
    "text": "Okay, that is known as mode. So let's say that we want to find out\nthe most common type of cylinder among the population of cards all we have to Do\nis we will check the value which is repeated\nthe most number of times here. We can see that the cylinders\ncome in two types. We have cylinder of Type\n4 and cylinder of type 6, right? So take a look at the data set. You can see that the most\nrecurring value is 6 right. We have one two,\nthree four and five. We have five six\nand we have one two, three.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5825.0,
    "t_end": 5855.0,
    "text": "We have one two,\nthree four and five. We have five six\nand we have one two, three. Yeah, we have three four types\nof lenders and 5/6. Cylinders. So basically we have three four type cylinders and we\nhave five six type cylinders. All right. So our mode is going\nto be 6 since 6 is more recurrent than 4 so guys those were the measures of the center or the measures\nof central tendency. Now, let's move on and look\nat the measures of the spread.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5850.0,
    "t_end": 5880.0,
    "text": "recurrent than 4 so guys those were the measures of the center or the measures\nof central tendency. Now, let's move on and look\nat the measures of the spread. All right. Now, what is the measure\nof spread a measure of spread? Sometimes also called as measure of dispersion is used\nto describe the The variability in a sample or population. Okay, you can think\nof it as some sort of deviation in the sample. All right. So you measure this with the help of the different\nmeasure of spreads. We have range\ninterquartile range variance",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5875.0,
    "t_end": 5905.0,
    "text": "of deviation in the sample. All right. So you measure this with the help of the different\nmeasure of spreads. We have range\ninterquartile range variance and standard deviation. Now range is pretty\nself-explanatory, right? It is the given measure of\nhow spread apart the values in a data set are\nthe range can be calculated as shown in this formula. So you're basically going\nto The maximum value in your data set from the minimum value\nin your data set. That's how you calculate\nthe range of the data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5900.0,
    "t_end": 5930.0,
    "text": "in your data set from the minimum value\nin your data set. That's how you calculate\nthe range of the data. Alright, next we\nhave interquartile range. So before we discuss\ninterquartile range, let's understand. What a quartile is red. So quartiles basically tell us\nabout the spread of a data set by breaking the data set\ninto different quarters. Okay, just like how the median breaks\nthe data into two parts. The quartile will break it. In two different quarters, so to better understand\nhow quartile and",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5925.0,
    "t_end": 5955.0,
    "text": "how the median breaks\nthe data into two parts. The quartile will break it. In two different quarters, so to better understand\nhow quartile and interquartile are calculated. Let's look at a small example. Now this data set basically\nrepresents the marks of hundred students\nordered from the lowest to the highest scores red. So the quartiles lie in the following ranges\nthe first quartile, which is also known as q1 it lies between the 25th\nand 26th observation. All right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5950.0,
    "t_end": 5980.0,
    "text": "which is also known as q1 it lies between the 25th\nand 26th observation. All right. So if you look at this\nI've highlighted the 25th and the Six observation. So how you can calculate\nQ 1 or first quartile is by taking the average\nof these two values. Alright, since both\nthe values are 45 when you add them up\nand divide them by two you'll still get 45 now\nthe second quartile or Q 2 is between the 50th\nand the fifty first observation. So you're going to take\nthe average of 58",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 5975.0,
    "t_end": 6005.0,
    "text": "or Q 2 is between the 50th\nand the fifty first observation. So you're going to take\nthe average of 58 and 59 and you will get\na value of 58.5 now, this is my second quarter\nthe third quartile Q3. Is between the 75th and the 76th observation here\nagain will take the average of the two values which is the 75th value\nand the 76 value right and you'll get a value of 71. All right, so guys\nthis is exactly how you calculate\nthe different quarters. Now, let's look at\nwhat is interquartile range.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6000.0,
    "t_end": 6030.0,
    "text": "and you'll get a value of 71. All right, so guys\nthis is exactly how you calculate\nthe different quarters. Now, let's look at\nwhat is interquartile range. So IQR or the interquartile\nrange is a measure of variability based on dividing\na data set into quartiles. Now, the interquartile\nrange is Calculated by subtracting the q1 from Q3. So basically Q3 minus q1 is your IQ are so\nyour IQR is your Q3 minus q1? All right. Now this is how each",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6025.0,
    "t_end": 6055.0,
    "text": "minus q1 is your IQ are so\nyour IQR is your Q3 minus q1? All right. Now this is how each of the quartiles are each core\ntile represents a quarter, which is 25% All right. So guys, I hope all\nof you are clear with the interquartile range\nand what our quartiles now, let's look at\nvariance covariance is basically a measure\nthat shows how much a I'm variable the first\nfrom its expected value. Okay. It's basically the variance\nin any variable now variance can be calculated by using\nthis formula right here x",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6050.0,
    "t_end": 6080.0,
    "text": "I'm variable the first\nfrom its expected value. Okay. It's basically the variance\nin any variable now variance can be calculated by using\nthis formula right here x basically represents\nany data point in your data set n is the total number\nof data points in your data set and X bar is basically\nthe mean of data points. All right. This is how you calculate\nvariance variance is basically a Computing\nthe squares of deviations. Okay. That's why it says\ns Square there now. Look at what is deviation\ndeviation is just the difference",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6075.0,
    "t_end": 6105.0,
    "text": "Okay. That's why it says\ns Square there now. Look at what is deviation\ndeviation is just the difference between each element\nfrom the mean. Okay, so it can be calculated\nby using this simple formula where X I basically\nrepresents a data point and mu is the mean\nof the population or add this is exactly how you calculate the deviation\nNow population variance and Sample variance\nare very specific to whether you're calculating\nthe variance in your population data\nset or in your sample data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6100.0,
    "t_end": 6130.0,
    "text": "and Sample variance\nare very specific to whether you're calculating\nthe variance in your population data\nset or in your sample data set now the only\ndifference between Elation and Sample variance. So the formula for population variance\nis pretty explanatory. So X is basically\neach data point mu is the mean of the population n is the number of samples\nin your data set. All right. Now, let's look at sample. Variance Now sample variance is the average of squared\ndifferences from the mean. All right here x\ni is any data point",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6125.0,
    "t_end": 6155.0,
    "text": "is the average of squared\ndifferences from the mean. All right here x\ni is any data point or any sample in your data\nset X bar is the mean of your sample. All right. It's not the main\nof your population. It's the If your sample and if you notice any here is\na smaller n is the number of data points in your sample. And this is basically\nthe difference between sample and population variance. I hope that is clear coming to standard deviation is\nthe measure of dispersion of a set of data from its mean.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6150.0,
    "t_end": 6180.0,
    "text": "I hope that is clear coming to standard deviation is\nthe measure of dispersion of a set of data from its mean. All right, so it's basically\nthe deviation from your mean. That's what standard deviation\nis now to better understand how the measures\nof spread are calculated. Let's look at a small use case. So let's say the Daenerys\nhas 20 dragons. They have the numbers\nnine to five four and so on as shown on the screen, what you have to do is\nyou have to work out the standard deviation or at in order to calculate\nthe standard deviation.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6175.0,
    "t_end": 6205.0,
    "text": "what you have to do is\nyou have to work out the standard deviation or at in order to calculate\nthe standard deviation. You need to know the mean right? So first you're going to find\nout the mean of your sample set. So how do you calculate\nthe mean you add all the numbers in your data set and divided by the total number\nof samples in your data set so you get a value of 7 here then you I'll clear the rhs of\nyour standard deviation formula. All right, so from\neach data point you're going to subtract the mean\nand you're going to square that.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6200.0,
    "t_end": 6230.0,
    "text": "then you I'll clear the rhs of\nyour standard deviation formula. All right, so from\neach data point you're going to subtract the mean\nand you're going to square that. All right. So when you do that, you will get\nthe following result. You'll basically get\nthis 425 for 925 and so on so finally you\nwill just find the mean of the squared differences. All right. So your standard deviation will come up to two point\nnine eight three once you take the square root. So guys, this is pretty simple. It's a simple\nmathematic technique. All you have to do is you have\nto substitute the values",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6225.0,
    "t_end": 6255.0,
    "text": "So guys, this is pretty simple. It's a simple\nmathematic technique. All you have to do is you have\nto substitute the values in the formula. All right. I hope this was clear\nto all of you. Now let's move on and discuss the next topic\nwhich is Information Gain and entropy now. This is one of my favorite\ntopics in statistics. It's very interesting and\nthis topic is mainly involved in machine learning algorithms, like decision trees\nand random forest. All right, it's very important for you to know how Information Gain and entropy\nreally work and why they are",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6250.0,
    "t_end": 6280.0,
    "text": "like decision trees\nand random forest. All right, it's very important for you to know how Information Gain and entropy\nreally work and why they are so essential in building\nmachine learning models. We focus on the statistic parts\nof Information Gain and entropy and after that we'll discuss\nAs a use case and see how Information Gain and entropy is used\nin decision trees. So for those of you who don't know what\na decision tree is it is basically a machine\nlearning algorithm. You don't have to know\nanything about this. I'll explain\neverything in depth. So don't worry.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6275.0,
    "t_end": 6305.0,
    "text": "basically a machine\nlearning algorithm. You don't have to know\nanything about this. I'll explain\neverything in depth. So don't worry. Now. Let's look at what exactly\nentropy and Information Gain Is As entropy is\nbasically the measure of any sort of uncertainty\nthat is present in the data. All right, so it can be measured\nby using this formula. So here s is the set\nof all instances in the data set or although data items\nin the data set n is the different type of classes in your data set\nPi is the event probability.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6300.0,
    "t_end": 6330.0,
    "text": "or although data items\nin the data set n is the different type of classes in your data set\nPi is the event probability. Now this might seem\na little confusing to you all but when we\ngo to the use case, you'll understand all\nof these terms even better. All right cam. To Information Gain as the word suggests\nInformation Gain indicates how much information\na particular feature or a particular variable gives\nus about the final outcome. Okay, it can be measured\nby using this formula. So again here hedge\nof s is the entropy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6325.0,
    "t_end": 6355.0,
    "text": "or a particular variable gives\nus about the final outcome. Okay, it can be measured\nby using this formula. So again here hedge\nof s is the entropy of the whole data set\ns SJ is the number of instances with the J value of an attribute a s is\nthe total number of instances in the data set V is the set of distinct values\nof an attribute a hedge of SJ is the entropy\nof subsets of instances and hedge of a comma s is\nthe entropy of an attribute a even though\nthis seems confusing.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6350.0,
    "t_end": 6380.0,
    "text": "and hedge of a comma s is\nthe entropy of an attribute a even though\nthis seems confusing. I'll clear out the confusion. All right, let's discuss\na small problem statement where we will understand how Information Gain and entropy is used to study\nthe significance of a model. So like I said Information Gain and entropy are very\nimportant statistical measures that let us understand the significance of\na predictive model. Okay to get a more\nclear understanding. Let's look at a use case.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6375.0,
    "t_end": 6405.0,
    "text": "the significance of\na predictive model. Okay to get a more\nclear understanding. Let's look at a use case. All right now suppose we\nare given a problem statement. All right, the statement is\nthat you have to predict whether a match can be played or Not by studying\nthe weather conditions. So the predictor variables here\nare outlook humidity wind day is also a predictor variable. The target variable\nis basically played already. The target variable\nis the variable that you're trying to protect. Okay. Now the value of the target\nvariable will decide",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6400.0,
    "t_end": 6430.0,
    "text": "The target variable\nis the variable that you're trying to protect. Okay. Now the value of the target\nvariable will decide whether or not a game\ncan be played. All right, so that's\nwhy The play has two values. It has no and yes, no, meaning that the weather\nconditions are not good. And therefore you\ncannot play the game. Yes, meaning that the weather\nconditions are good and suitable for you to play the game. Alright, so that was\na problem statement. I hope the problem statement\nis clear to all of you now to solve such a problem.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6425.0,
    "t_end": 6455.0,
    "text": "Alright, so that was\na problem statement. I hope the problem statement\nis clear to all of you now to solve such a problem. We make use of something\nknown as decision trees. So guys think\nof an inverted tree and each branch of the tree\ndenotes some decision. All right, each branch is\nIs known as the branch node and at each branch node, you're going to take\na decision in such a manner that you will get an outcome\nat the end of the branch. All right. Now this figure\nhere basically shows that out of 14 observations\n9 observations result in a yes,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6450.0,
    "t_end": 6480.0,
    "text": "All right. Now this figure\nhere basically shows that out of 14 observations\n9 observations result in a yes, meaning that out of 14 days. The match can be played\nonly on nine days. Alright, so here if you see on day 1 Day\n2 Day 8 day 9 and 11. The Outlook has been Alright, so basically we try\nto plaster a data set depending on the Outlook. So when the Outlook is sunny, this is our data set\nwhen the Outlook is overcast.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6475.0,
    "t_end": 6505.0,
    "text": "depending on the Outlook. So when the Outlook is sunny, this is our data set\nwhen the Outlook is overcast. This is what we have and when the Outlook is\nthe rain this is what we have. All right, so when it is sunny we have\ntwo yeses and three nodes. Okay, when the\nOutlook is overcast. We have all four\nas yes has meaning that on the four days\nwhen the Outlook was overcast. We can play the game. All right. Now when it comes to drain, we have three yeses\nand two nodes. All right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6500.0,
    "t_end": 6530.0,
    "text": "All right. Now when it comes to drain, we have three yeses\nand two nodes. All right. So if you notice here, the decision is being made by\nchoosing the Outlook variable as the root node. Okay. So the root node is basically the topmost node\nin a decision tree. Now, what we've done here is\nwe've created a decision tree that starts with\nthe Outlook node. All right, then you're splitting\nthe decision tree further depending on other parameters\nlike Sunny overcast and rain. All right now like we know\nthat Outlook has three values.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6525.0,
    "t_end": 6555.0,
    "text": "depending on other parameters\nlike Sunny overcast and rain. All right now like we know\nthat Outlook has three values. Sunny overcast and brain\nso let me explain this in a more in-depth manner. Okay. So what you're doing\nhere is you're making the decision Tree by choosing\nthe Outlook variable at the root node. The root note is\nbasically the topmost node in a decision tree. Now the Outlook node has three\nbranches coming out from it, which is sunny\novercast and rain. So basically Outlook can have three values\neither it can be sunny.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6550.0,
    "t_end": 6580.0,
    "text": "Now the Outlook node has three\nbranches coming out from it, which is sunny\novercast and rain. So basically Outlook can have three values\neither it can be sunny. It can be overcast\nor it can be rainy. Okay now these three values\nUse are assigned to the immediate Branch\nnodes and for each of these values the possibility of play is equal\nto yes is calculated. So the sunny and the rain branches\nwill give you an impure output. Meaning that there is a mix\nof yes and no right. There are two yeses\nhere three nodes here. There are three yeses here\nand two nodes over here,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6575.0,
    "t_end": 6605.0,
    "text": "Meaning that there is a mix\nof yes and no right. There are two yeses\nhere three nodes here. There are three yeses here\nand two nodes over here, but when it comes\nto the overcast variable, it results in a hundred\npercent pure subset. All right, this shows that\nthe overcast baby. Will result in a definite\nand certain output. This is exactly what entropy\nis used to measure. All right, it calculates\nthe impurity or the uncertainty. Alright, so the lesser\nthe uncertainty or the entropy of a variable more\nsignificant is that variable?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6600.0,
    "t_end": 6630.0,
    "text": "All right, it calculates\nthe impurity or the uncertainty. Alright, so the lesser\nthe uncertainty or the entropy of a variable more\nsignificant is that variable? So when it comes to overcast\nthere's literally no impurity in the data set. It is a hundred percent\npure subset, right? So be want variables like these\nin order to build a model. All right now, we don't always Ways get lucky\nand we don't always find variables that will result\nin pure subsets. That's why we have\nthe measure entropy. So the lesser the entropy of\na particular variable the most",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6625.0,
    "t_end": 6655.0,
    "text": "That's why we have\nthe measure entropy. So the lesser the entropy of\na particular variable the most significant that variable\nwill be so in a decision tree. The root node is assigned\nthe best attribute so that the decision tree\ncan predict the most precise outcome meaning\nthat on the root note. You should have the most\nsignificant variable. All right, that's why\nwe've chosen Outlook or and now some of you might ask\nme why haven't you chosen overcast Okay is overcast\nis not a variable. It is a value\nof the Outlook variable.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6650.0,
    "t_end": 6680.0,
    "text": "overcast Okay is overcast\nis not a variable. It is a value\nof the Outlook variable. All right. That's why we've chosen\noutlook here because it has a hundred percent pure subset\nwhich is overcast. All right. Now the question in your head is\nhow do I decide which variable or attribute best Blitz\nthe data now right now, I know I looked at the data and I told you that, you know here we have\na hundred percent pure subset, but what if it's\na more complex problem and you're not able\nto understand which variable",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6675.0,
    "t_end": 6705.0,
    "text": "you know here we have\na hundred percent pure subset, but what if it's\na more complex problem and you're not able\nto understand which variable will best split the data, so guys when it comes to decision tree\nInformation and gain and entropy will help you understand which variable\nwill best split the data set. All right, or which variable you\nhave to assign to the root node because whichever variable\nis assigned to the dude node. It will best let the data set and it has to be the most\nsignificant variable. All right. So how we can do this\nis we need to use",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6700.0,
    "t_end": 6730.0,
    "text": "It will best let the data set and it has to be the most\nsignificant variable. All right. So how we can do this\nis we need to use Information Gain and entropy. So from the total\nof the 14 instances that we saw nine\nof them said yes and 5 of the instances said know that you cannot play\non that particular day. All right. So how do you\ncalculate the entropy? So this is the formula\nyou just substitute the values in the formula. So when you substitute\nthe values in the formula, you will get a value of 0.9940. All right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6725.0,
    "t_end": 6755.0,
    "text": "So when you substitute\nthe values in the formula, you will get a value of 0.9940. All right. This is the entropy or this is the uncertainty\nof the data present in a sample. Now in order to ensure that we choose the best variable\nfor the root node. Let us look at all\nthe possible combinations that you can use\non the root node. Okay, so these are All\nthe possible combinations you can either have\nOutlook you can have windy humidity or temperature. Okay, these are four variables\nand you can have any one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6750.0,
    "t_end": 6780.0,
    "text": "windy humidity or temperature. Okay, these are four variables\nand you can have any one of these variables\nas your root node. But how do you select which variable best\nfits the root node? That's what we are going\nto see by using Information Gain and entropy. So guys now the task at hand\nis to find the information gain for each of these attributes. All right. So for Outlook for windy for\nhumidity and for temperature, we're going to find\nout the information. Nation gained right now\na point to remember is that the variable",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6775.0,
    "t_end": 6805.0,
    "text": "we're going to find\nout the information. Nation gained right now\na point to remember is that the variable that results in the highest\nInformation Gain must be chosen because it will give us the most\nprecise and output information. All right. So the information gain for\nattribute windy will calculate that first here. We have six instances of true\nand eight instances of false. Okay. So when you substitute all\nthe values in the formula, you will get a value\nof zero point zero four eight.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6800.0,
    "t_end": 6830.0,
    "text": "So when you substitute all\nthe values in the formula, you will get a value\nof zero point zero four eight. So we get a value\nof You 2.0 for it. Now. This is a very low value\nfor Information Gain. All right, so the information that you're going to get from\nWindy attribute is pretty low. So let's calculate\nthe information gain of attribute Outlook. All right, so from the total\nof 14 instances, we have five instances\nwith say Sunny for instances, which are overcast\nand five instances, which are rainy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6825.0,
    "t_end": 6855.0,
    "text": "we have five instances\nwith say Sunny for instances, which are overcast\nand five instances, which are rainy. All right for Sonny. We have three yeses and to nose\nfor overcast we have All the for as yes for any we have\nthree years and two nodes. Okay. So when you calculate\nthe information gain of the Outlook variable\nwill get a value of zero point 2 4 7 now compare\nthis to the information gain of the windy attribute. This value is\nactually pretty good. Right we have zero point 2 4 7\nwhich is a pretty good value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6850.0,
    "t_end": 6880.0,
    "text": "of the windy attribute. This value is\nactually pretty good. Right we have zero point 2 4 7\nwhich is a pretty good value for Information Gain. Now, let's look\nat the information gain of attribute humidity\nnow over here. We have seven instances\nwith say hi and seven instances with say normal. Right and under\nthe high Branch node. We have three instances\nwith say yes, and the rest for instances\nwould say no similarly under the normal Branch. We have one two, three, four, five six seven\ninstances would say yes",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6875.0,
    "t_end": 6905.0,
    "text": "and the rest for instances\nwould say no similarly under the normal Branch. We have one two, three, four, five six seven\ninstances would say yes and one instance with says no. All right. So when you calculate\nthe information gain for the humidity variable, you're going to get\na value of 0.15 one. Now. This is also\na pretty decent value, but when you compare it\nto the Information Gain, Of the attribute Outlook it\nis less right now. Let's look at the information\ngain of attribute temperature. All right, so the temperature\ncan hold repeat.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6900.0,
    "t_end": 6930.0,
    "text": "Let's look at the information\ngain of attribute temperature. All right, so the temperature\ncan hold repeat. So basically the temperature\nattribute can hold hot mild and cool. Okay under hot. We have two instances\nwith says yes and two instances for no under mild. We have four instances of yes\nand two instances of no and under col we have\nthree instances of yes and one instance of no. All right. When you calculate the information gain\nfor this attribute, you will get a value\nof zero point zero to nine,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6925.0,
    "t_end": 6955.0,
    "text": "and one instance of no. All right. When you calculate the information gain\nfor this attribute, you will get a value\nof zero point zero to nine, which is again very less. So what you can summarize\nfrom here is if we look at the information gain for each\nof these variable will see that for Outlook. We have the maximum gain. All right, we have\nzero point two four seven, which is the highest\nInformation Gain value and you must always choose\na variable with the highest Information Gain to split\nthe data at the root node. So that's why we assign\nThe Outlook variable",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6950.0,
    "t_end": 6980.0,
    "text": "and you must always choose\na variable with the highest Information Gain to split\nthe data at the root node. So that's why we assign\nThe Outlook variable at the root node. All right, so guys. I hope this use case with clear\nif any of you have doubts. Please keep commenting\nthose doubts now, let's move on and look at what\nexactly a confusion Matrix is the confusion Matrix\nis the last topic for descriptive statistics\nread after this. I'll be running a short demo\nwhere I'll be showing you how you can calculate\nmean median mode",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 6975.0,
    "t_end": 7005.0,
    "text": "for descriptive statistics\nread after this. I'll be running a short demo\nwhere I'll be showing you how you can calculate\nmean median mode and standard deviation variance\nand all of those values by using our okay. So let's talk about\nconfusion Matrix now guys. What is the confusion Matrix\nnow don't get confused. This is not any complex\ntopic now confusion. Matrix is a matrix that is often used to describe\nthe performance of a model. All right, and this\nis specifically used for classification models",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7000.0,
    "t_end": 7030.0,
    "text": "that is often used to describe\nthe performance of a model. All right, and this\nis specifically used for classification models or a classifier and what it does is it\nwill calculate the accuracy or it will calculate the\nperformance of your classifier by comparing your actual results\nand Your predicted results. All right. So this is what it looks like to positive to\nnegative and all of that. Now this is a little confusing. I'll get back to what\nexactly true positive to negative and all\nof this stands for for now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7025.0,
    "t_end": 7055.0,
    "text": "I'll get back to what\nexactly true positive to negative and all\nof this stands for for now. Let's look at an example and\nlet's try and understand what exactly confusion Matrix is. So guys have made sure that I put examples\nafter each and every topic because it's important you understand the Practical\npart of Statistics. All right statistics has\nliterally nothing to do with Theory you need\nto understand how Calculations are done in statistics. Okay. So here what I've done is now\nlet's look at a small use case. Okay, let's consider that your given data\nabout a hundred and sixty five",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7050.0,
    "t_end": 7080.0,
    "text": "So here what I've done is now\nlet's look at a small use case. Okay, let's consider that your given data\nabout a hundred and sixty five patients out of which hundred\nand five patients have a disease and the remaining 50 patients\ndon't have a disease. Okay. So what you're going to do is\nyou will build a classifier that predicts by using these hundred and\nsixty five observations. You'll feed all of these 165 observations\nto your classifier and it will predict\nthe output every time a new patients detail is fed\nto the classifier right now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7075.0,
    "t_end": 7105.0,
    "text": "of these 165 observations\nto your classifier and it will predict\nthe output every time a new patients detail is fed\nto the classifier right now out of these 165 cases. Let's say that\nthe classifier predicted. Yes hundred and ten times\nand no 55 times. Alright, so yes\nbasically stands for yes. The person has a disease\nand no stands for know. The person does\nnot have a disease. All right, that's\npretty self-explanatory. But yeah, so it predicted\nthat a hundred and ten times.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7100.0,
    "t_end": 7130.0,
    "text": "All right, that's\npretty self-explanatory. But yeah, so it predicted\nthat a hundred and ten times. Patient has a disease\nand 55 times that know the patient\ndoesn't have a disease. However in reality only\nhundred and five patients in the sample have\nthe disease and 60 patients who do not have\nthe disease, right? So how do you calculate\nthe accuracy of your model? You basically build\nthe confusion Matrix? All right. This is how the Matrix looks like and basically denotes\nthe total number of observations",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7125.0,
    "t_end": 7155.0,
    "text": "You basically build\nthe confusion Matrix? All right. This is how the Matrix looks like and basically denotes\nthe total number of observations that you have which is 165 in our case\nactual denotes the actual use in the data set and predicted denotes\nthe predicted values by the classifier. So the actual value is no here and the predicted\nvalue is no here. So your classifier\nwas correctly able to classify 50 cases as no. All right, since both\nof these are no so 50 it was correctly able\nto classify but 10",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7150.0,
    "t_end": 7180.0,
    "text": "to classify 50 cases as no. All right, since both\nof these are no so 50 it was correctly able\nto classify but 10 of these cases it\nincorrectly classified meaning that your actual value here\nis no but you classifier predicted it as yes or I that's why this\nAnd over here similarly it wrongly predicted that five patients\ndo not have diseases whereas they actually\ndid have diseases and it correctly\npredicted hundred patients, which have the disease. All right. I know this is\na little bit confusing.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7175.0,
    "t_end": 7205.0,
    "text": "and it correctly\npredicted hundred patients, which have the disease. All right. I know this is\na little bit confusing. But if you look\nat these values no, no 50 meaning that it correctly\npredicted 50 values No Yes means that it\nwrongly predicted. Yes for the values are it\nwas supposed to predict. No. All right. Now what exactly is? Is this true positive\nto negative and all of that? I'll tell you what\nexactly it is. So true positive are the cases\nin which we predicted a yes",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7200.0,
    "t_end": 7230.0,
    "text": "I'll tell you what\nexactly it is. So true positive are the cases\nin which we predicted a yes and they do not actually\nhave the disease. All right, so it is\nbasically this value already predicted a yes here, even though they\ndid not have the disease. So we have 10 true positives\nright similarly true- is we predicted know and they don't have\nthe disease meaning that this is correct. False positive is be predicted. Yes, but they do not\nactually have the disease",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7225.0,
    "t_end": 7255.0,
    "text": "and they don't have\nthe disease meaning that this is correct. False positive is be predicted. Yes, but they do not\nactually have the disease or at this is also known as type\n1 error falls- is we predicted. No, but they actually\ndo not have the disease. So guys basically falls- and true negatives are basically\ncorrect classifications. All right. So this was confusion Matrix and I hope this concept\nis clear again guys. If you have doubts, please comment your doubt\nin the comment section. So guys, that was\nthe entire descriptive.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7250.0,
    "t_end": 7280.0,
    "text": "If you have doubts, please comment your doubt\nin the comment section. So guys, that was\nthe entire descriptive. X module and now we\nwill discuss about probability. Okay. So before we understand\nwhat exactly probability is, let me clear out a very\ncommon misconception people often tend to ask\nme this question. What is the relationship between\nstatistics and probability? So probability and statistics\nare related fields. All right. So probability is\na mathematical method used",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7275.0,
    "t_end": 7305.0,
    "text": "So probability and statistics\nare related fields. All right. So probability is\na mathematical method used for statistical analysis. Therefore we can say that a probability and\nstatistics are interconnected. Launches of mathematics that deal with analyzing the\nrelative frequency of events. So they're very\ninterconnected feels and probability makes\nuse of statistics and statistics makes use of probability or a they're\nvery interconnected Fields. So that is the relationship\nbetween statistics and probability. Now, let's understand\nwhat exactly is probability.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7300.0,
    "t_end": 7330.0,
    "text": "of probability or a they're\nvery interconnected Fields. So that is the relationship\nbetween statistics and probability. Now, let's understand\nwhat exactly is probability. So probability is the measure of How likely an event\nwill occur to be more precise. It is the ratio. Of desired outcome\nto the total outcomes. Now, the probability of all outcomes always sum up\nto 1 the probability will always sum up to 1 probability\ncannot go beyond one. Okay. So either your probability\ncan be 0 or it can be 1",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7325.0,
    "t_end": 7355.0,
    "text": "sum up to 1 probability\ncannot go beyond one. Okay. So either your probability\ncan be 0 or it can be 1 or it can be in the form\nof decimals like 0.5 to or 0.55 or it can be\nin the form of 0.5 0.7 0.9. But it's valuable always stay\nbetween the range 0 and 1. Okay at the famous example of probability is rolling\na dice example. So when you roll a dice you get\nsix possible outcomes, right? You get one two, three four and five six\nphases of a dice now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7350.0,
    "t_end": 7380.0,
    "text": "of probability is rolling\na dice example. So when you roll a dice you get\nsix possible outcomes, right? You get one two, three four and five six\nphases of a dice now each possibility only\nhas one outcome. So what is the probability\nthat on rolling a dice? You will get 3 the probability\nis 1 by 6, right because there's only one phase which has the number 3 on it\nout of six phases. There's only one phase\nwhich has the number three. So the probability of getting 3 when you roll a dice\nis 1 by 6 similarly,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7375.0,
    "t_end": 7405.0,
    "text": "There's only one phase\nwhich has the number three. So the probability of getting 3 when you roll a dice\nis 1 by 6 similarly, if you want to find\nthe probability of getting a number 5 again, the probability is\ngoing to be 1 by 6. All right, so all\nof this will sum up to 1. All right, so guys this is\nexactly what probability is. It's a very simple concept\nwe all learnt it in 8 standard onwards right now. Let's understand the\ndifferent terminologies that are related to probability. Now the three terminologies\nthat you often come across",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7400.0,
    "t_end": 7430.0,
    "text": "Let's understand the\ndifferent terminologies that are related to probability. Now the three terminologies\nthat you often come across when We talk about probability. We have something known\nas the random experiment. Okay, it's basically\nan experiment or a process for which the outcomes cannot be\npredicted with certainty. All right. That's why you use probability. You're going to use probability\nin order to predict the outcome with some sort of certainty sample space\nis the entire possible set of outcomes of a random\nexperiment an event is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7425.0,
    "t_end": 7455.0,
    "text": "of certainty sample space\nis the entire possible set of outcomes of a random\nexperiment an event is one or more outcomes\nof an experiment. So if you consider the example\nLove rolling a dice. Now. Let's say that you want\nto find out the probability of getting a to\nwhen you roll the dice. Okay. So finding this probability\nis the random experiment the sample space is basically\nyour entire possibility. Okay. So one two, three, four, five six phases are there\nand out of that you need",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7450.0,
    "t_end": 7480.0,
    "text": "the sample space is basically\nyour entire possibility. Okay. So one two, three, four, five six phases are there\nand out of that you need to find the probability\nof getting a 2, right. So all the possible outcomes will basically represent\nyour sample space. Okay. So 1 to 6 are all your possible\noutcomes this represents. Sample space event is\none or more outcome of an experiment. So in this case\nmy event is to get a to when I roll a dice, right? So my event is the probability\nof getting a to when I roll a dice. So guys, this is basically what\nrandom experiment sample space",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7475.0,
    "t_end": 7505.0,
    "text": "So my event is the probability\nof getting a to when I roll a dice. So guys, this is basically what\nrandom experiment sample space and event really means alright. Now, let's discuss\nthe different types of events. There are two types of events\nthat you should know about there is disjoint and non disjoint\nevents disjoint events. These are events that do not have\nany common outcome. For example, if you draw a single card\nfrom a deck of cards, it cannot be a king\nand a queen correct.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7500.0,
    "t_end": 7530.0,
    "text": "For example, if you draw a single card\nfrom a deck of cards, it cannot be a king\nand a queen correct. It can either be king\nor it can be Queen. Now a non disjoint\nevents are events that have common outcomes. For example, a student\ncan get hundred marks in statistics and hundred\nmarks in probability. All right, and also the outcome of a ball delibird\ncan be a no ball and it can be a 6 right. So this is Non\ndisjoint events are or n. These are very simple\nto understand right now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7525.0,
    "t_end": 7555.0,
    "text": "and it can be a 6 right. So this is Non\ndisjoint events are or n. These are very simple\nto understand right now. Let's move on and look\nat the different types of probability distribution. All right, I'll be discussing the three main probability\ndistribution functions. I'll be talking\nabout probability density function normal distribution\nand Central limit theorem. Okay probability density\nfunction also known as PDF is concerned with the relative likelihood for\na continuous random variable.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7550.0,
    "t_end": 7580.0,
    "text": "as PDF is concerned with the relative likelihood for\na continuous random variable. To take on a given value. All right. So the PDF gives the probability of a variable that lies\nbetween the range A and B. So basically what you're trying\nto do is you're going to try and find the probability\nof a continuous random variable over a specified range. Okay. Now this graph denotes the PDF\nof a continuous variable. Now, this graph is also known\nas the bell curve right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7575.0,
    "t_end": 7605.0,
    "text": "Now this graph denotes the PDF\nof a continuous variable. Now, this graph is also known\nas the bell curve right? It's famously called\nthe bell curve because of its shape and there are\nthree important properties that you To know about\na probability density function. Now the graph of a PDF\nwill be continuous over a range. This is because you're\nfinding the probability that a continuous variable lies\nbetween the ranges A and B, right the second property is that the area bounded by\nthe curve of a density function",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7600.0,
    "t_end": 7630.0,
    "text": "right the second property is that the area bounded by\nthe curve of a density function and the x-axis is equal\nto 1 basically the area below the curve is equal\nto 1 all right, because it denotes\nprobability again the probability cannot arrange. More than one it has to be between 0 and 1 property number\nthree is that the probability that our random variable\nassumes a value between A and B is equal to the area under the PDF bounded\nby A and B. Okay. Now what this means is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7625.0,
    "t_end": 7655.0,
    "text": "that our random variable\nassumes a value between A and B is equal to the area under the PDF bounded\nby A and B. Okay. Now what this means is that the probability value\nis denoted by the area of the graph. All right, so whatever value\nthat you get here, which basically one\nis the probability that a random variable will lie\nbetween the range A and B. All right, so I hope If you have understood the\nprobability density function, it's basically the probability\nof finding the value of a continuous random variable\nbetween the range A and B.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7650.0,
    "t_end": 7680.0,
    "text": "it's basically the probability\nof finding the value of a continuous random variable\nbetween the range A and B. All right. Now, let's look\nat our next distribution, which is normal distribution\nnow normal distribution, which is also known as the gaussian distribution is\na probability distribution that denotes the\nsymmetric property of the mean right meaning that the idea\nbehind this function is that The data near the mean occurs more frequently than\nthe data away from the mean.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7675.0,
    "t_end": 7705.0,
    "text": "that the idea\nbehind this function is that The data near the mean occurs more frequently than\nthe data away from the mean. So what it means to say is that the data around the mean\nrepresents the entire data set. Okay. So if you just take\na sample of data around the mean it can represent\nthe entire data set now similar to the probability density\nfunction the normal distribution appears as a bell curve. All right. Now when it comes\nto normal distribution, there are two important factors. All right, we have the mean\nof the population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7700.0,
    "t_end": 7730.0,
    "text": "Now when it comes\nto normal distribution, there are two important factors. All right, we have the mean\nof the population. And the standard deviation. Okay, so the mean and the graph\ndetermines the location of the center of the graph, right and the standard deviation\ndetermines the height of the graph. Okay. So if the standard deviation\nis large the curve is going to look something like this. All right, it'll be\nshort and wide and if the standard deviation\nis small the curve is tall and narrow. All right. So this was it\nabout normal distribution.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7725.0,
    "t_end": 7755.0,
    "text": "if the standard deviation\nis small the curve is tall and narrow. All right. So this was it\nabout normal distribution. Now, let's look\nat the central limit theorem. Now the central\nlimit theorem states that the sampling distribution of the mean of any independent\nrandom variable will be normal or nearly normal if the sample size\nis large enough now, that's a little confusing. Okay. Let me break it down for\nyou now in simple terms if we had a large population and we divided it\ninto many samples.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7750.0,
    "t_end": 7780.0,
    "text": "Let me break it down for\nyou now in simple terms if we had a large population and we divided it\ninto many samples. Then the mean of all the samples from the population\nwill be almost equal to the mean of the entire\npopulation right meaning that each of the sample\nis normally distributed. Right. So if you compare the mean\nof each of the sample, it will almost be equal\nto the mean of the population. Right? So this graph basically shows\na more clear understanding of the central limit theorem red\nyou can see each sample here",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7775.0,
    "t_end": 7805.0,
    "text": "So this graph basically shows\na more clear understanding of the central limit theorem red\nyou can see each sample here and the mean of each sample is almost\nalong the same line, right? Okay. So this is exactly what the central limit theorem\nStates now the accuracy or the resemblance to the normal distribution\ndepends on two main factors. Right. So the first is the number\nof sample points that you consider. All right, and the second is a shape\nof the underlying population. Now the shape obviously depends\non the standard deviation",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7800.0,
    "t_end": 7830.0,
    "text": "and the second is a shape\nof the underlying population. Now the shape obviously depends\non the standard deviation and the mean\nof a sample, correct. So guys the central\nlimit theorem basically states that each sample\nwill be normally distributed in such a way that the mean of each sample\nwill coincide with the mean of the actual population. All right in short terms. That's what central\nlimit theorem States. Alright, and this\nholds true only for a large. Is it mostly\nfor a small data set and there are more deviations when compared to a large\ndata set is because of",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7825.0,
    "t_end": 7855.0,
    "text": "Alright, and this\nholds true only for a large. Is it mostly\nfor a small data set and there are more deviations when compared to a large\ndata set is because of the scaling Factor, right? The small is deviation in a small data set will change\nthe value very drastically, but in a large data\nset a small deviation will not matter at all. Now, let's move on and look\nat our next topic which is the different\ntypes of probability. Now, this is a important topic because most of your problems\ncan be solved by understanding which type of probability\nshould I use to solve?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7850.0,
    "t_end": 7880.0,
    "text": "because most of your problems\ncan be solved by understanding which type of probability\nshould I use to solve? This problem right? So we have three important\ntypes of probability. We have marginal joint\nand conditional probability. So let's discuss each of these now the probability of\nan event occurring unconditioned on any other event is known\nas marginal probability or unconditional probability. So let's say that you want\nto find the probability that a card drawn is a heart.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7875.0,
    "t_end": 7905.0,
    "text": "or unconditional probability. So let's say that you want\nto find the probability that a card drawn is a heart. All right. So if you want to\nfind the probability that a card drawn is\na heart the prophet. B13 by 52 since there\nare 52 cards in a deck and there are 13 hearts\nin a deck of cards. Right and there are\n52 cards in a turtleneck. So your marginal probability\nwill be 13 by 52. That's about\nmarginal probability. Now, let's understand. What is joint probability. Now joint probability is a measure of two events\nhappening at the same time.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7900.0,
    "t_end": 7930.0,
    "text": "That's about\nmarginal probability. Now, let's understand. What is joint probability. Now joint probability is a measure of two events\nhappening at the same time. Okay. Let's say that the two\nevents are A and B. So the probability of event A and B occurring is\nthe dissection of A and B. So for example, if you want to\nfind the probability that a card is a four and a red\nthat would be joint probability. All right, because\nyou're finding a card that is 4 and the card\nhas to be red in color.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7925.0,
    "t_end": 7955.0,
    "text": "that a card is a four and a red\nthat would be joint probability. All right, because\nyou're finding a card that is 4 and the card\nhas to be red in color. So for the answer, this will be 2 by 52\nbecause we have 1/2 in heart and we have 1/2\nand diamonds correct. So both of these are red\nand color therefore. Our probability is to by 52 and if you further down\nit Is 1 by 26, right? So this is what\njoint probability is all about moving on. Let's look at what exactly\nconditional probability is.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7950.0,
    "t_end": 7980.0,
    "text": "So this is what\njoint probability is all about moving on. Let's look at what exactly\nconditional probability is. So if the probability of an event or an outcome\nis based on the occurrence of a previous event\nor an outcome, then you call it as\na conditional probability. Okay. So the conditional probability\nof an event B is the probability that the event will occur given that an event a has\nalready occurred, right? So if a and b are\ndependent events, then the expression for conditional probability\nis given by this.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 7975.0,
    "t_end": 8005.0,
    "text": "that an event a has\nalready occurred, right? So if a and b are\ndependent events, then the expression for conditional probability\nis given by this. Now this first term\non the left hand side, which is p b of a is\nbasically the probability of event B occurring given that event a\nhas already occurred. All right. So like I said, if a and b are dependent events, then this is\nthe expression but if a and b are independent events, and the expression\nfor conditional probability is like this, right? So guys P of A and B of B is\nobviously the probability of A",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8000.0,
    "t_end": 8030.0,
    "text": "and the expression\nfor conditional probability is like this, right? So guys P of A and B of B is\nobviously the probability of A and probability of B right now. Let's move on now in order to understand conditional\nprobability joint probability and marginal probability. Let's look at a small use case. Okay now basically\nwe're going to take a data set which examines the salary\npackage and training undergone my candidates. Okay. Now in this there are\n60 candidates without training",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8025.0,
    "t_end": 8055.0,
    "text": "which examines the salary\npackage and training undergone my candidates. Okay. Now in this there are\n60 candidates without training and forty five candidates, which have enrolled for\nAdder a curse training. Right. Now the task here is you have\nto assess the training with a salary package. Okay, let's look at this\nin a little more depth. So in total, we have hundred and five\ncandidates out of which 60 of them have not enrolled\nFrederick has training and 45 of them have enrolled\nfor a deer Acres training or this is a small survey that was conducted",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8050.0,
    "t_end": 8080.0,
    "text": "of them have not enrolled\nFrederick has training and 45 of them have enrolled\nfor a deer Acres training or this is a small survey that was conducted and this is the rating\nof the package or the salary that they got right? So if you read through the data, you can understand\nthere were five candidates. It's without education or training who got a very\npoor salary package. Okay. Similarly, there are 30 candidates with\nEd Eureka training who got a good package, right? So guys basically you're\ncomparing the salary package of a person depending on",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8075.0,
    "t_end": 8105.0,
    "text": "who got a good package, right? So guys basically you're\ncomparing the salary package of a person depending on whether or not they've enrolled\nfor a director training, right? This is our data set. Now, let's look at our problem\nstatement find the probability that a candidate\nhas undergone a Drake has training quite simple, which type of probability\nis this Is this is marginal probability? Right? So the probability that a candidate has undergone\nedger Acres training is obviously 45 divided\nby a hundred and five",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8100.0,
    "t_end": 8130.0,
    "text": "that a candidate has undergone\nedger Acres training is obviously 45 divided\nby a hundred and five since 45 is the number of candidates with\nEddie record raining and hundred and five is\nthe total number of candidates. So you get a value\nof approximately 0.4 to all right, that's the probability\nof a candidate that has undergone educate\na girl straining next question find the probability that a candidate has attended\nedger Acres training. Also has good package. Now. This is obviously a joint\nprobability problem, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8125.0,
    "t_end": 8155.0,
    "text": "that a candidate has attended\nedger Acres training. Also has good package. Now. This is obviously a joint\nprobability problem, right? So how do you\ncalculate this now? Since our table is quite\nformatted we can directly find that people who have\ngotten a good package along with Eddie record\nraining or 30, right? So out of hundred and\nfive people 30 people have education training\nand a good package, right? They specifically\nasking for people with Eddie record raining. Remember that night. The question is find the\nprobability that a gang Today,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8150.0,
    "t_end": 8180.0,
    "text": "They specifically\nasking for people with Eddie record raining. Remember that night. The question is find the\nprobability that a gang Today, it has attended\neditor Acres training and also has a good package. All right, so we need\nto consider two factors that is a candidate who's addenda deaderick\nhas training and who has a good package. So clearly that number is 30 30 divided by\ntotal number of candidates, which is 1:05, right? So here you get\nthe answer clearly next. We have find the probability that a candidate has\na good package given",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8175.0,
    "t_end": 8205.0,
    "text": "So here you get\nthe answer clearly next. We have find the probability that a candidate has\na good package given that he has not\nundergone training. Okay. Now this is Early\nconditional probability because here you're defining\na condition you're saying that you want to find\nthe probability of a candidate who has a good package given\nthat he's not undergone. Any training, right? The condition is that he's\nnot undergone any training. All right. So the number of people who have not undergone\ntraining are 60 and out",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8200.0,
    "t_end": 8230.0,
    "text": "The condition is that he's\nnot undergone any training. All right. So the number of people who have not undergone\ntraining are 60 and out of that five of them\nhave got a good package that so that's why this is Phi\nby 60 and not five by a hundred and five because here they have clearly\nmentioned has a good pack. Given that he has\nnot undergone training. So you have to only consider people who have\nnot undergone training, right? So any five people who have not undergone\ntraining have gotten a good package, right? So 5 divided by 60 you get\na probability of around 0.08",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8225.0,
    "t_end": 8255.0,
    "text": "who have not undergone\ntraining have gotten a good package, right? So 5 divided by 60 you get\na probability of around 0.08 which is pretty low, right? Okay. So this was all about the different types\nof probability now, let's move on and look at\nour last Topic in probability, which is base theorem. Now guys base. Your room is a very\nimportant concept when it comes to statistics and probability. It is majorly used\nin knife bias algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8250.0,
    "t_end": 8280.0,
    "text": "Your room is a very\nimportant concept when it comes to statistics and probability. It is majorly used\nin knife bias algorithm. Those of you who aren't aware. Now I've bias is a supervised\nlearning classification algorithm and it is mainly used\nin Gmail spam filtering right? A lot of you might have noticed\nthat if you open up Gmail, you'll see that you have\na folder called spam right or that is carried out\nthrough machine learning and And the algorithm use\nthere is knife bias, right? So now let's discuss what\nexactly the Bayes theorem is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8275.0,
    "t_end": 8305.0,
    "text": "or that is carried out\nthrough machine learning and And the algorithm use\nthere is knife bias, right? So now let's discuss what\nexactly the Bayes theorem is and what it denotes\nthe bias theorem is used to show the relation between\none conditional probability and it's inverse. All right. Basically it's nothing\nbut the probability of an event occurring based\non prior knowledge of conditions that might be related\nto the same event. Okay. So mathematically the bell's\ntheorem is represented like this right now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8300.0,
    "t_end": 8330.0,
    "text": "that might be related\nto the same event. Okay. So mathematically the bell's\ntheorem is represented like this right now. Shown in this equation. The left-hand term is referred\nto as the likelihood ratio which measures the probability of occurrence of event\nbe given an event a okay on the left hand side is what is known as\nthe posterior right is referred to as posterior, which means that the probability of occurrence of a given\nan event be right. The second term is referred to as the likelihood Ratio or at\nthis measures the probability",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8325.0,
    "t_end": 8355.0,
    "text": "of occurrence of a given\nan event be right. The second term is referred to as the likelihood Ratio or at\nthis measures the probability of occurrence of B\ngiven an event. A now P of a is also\nknown as the prior which refers to the actual\nprobability distribution of A and P of B is again, the probability of B, right. This is the bias theorem and in order to better\nunderstand the base theorem. Let's look at a small example. Let's say that we have\nthree bowels we have bow is a bow will be and bouncy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8350.0,
    "t_end": 8380.0,
    "text": "Let's look at a small example. Let's say that we have\nthree bowels we have bow is a bow will be and bouncy. Okay barley contains\ntwo blue balls and for red balls bowel B contains eight blue\nballs and for red balls. Wow Zeke. Games one blue ball\nand three red balls now if we draw one ball\nfrom each Bowl, what is the probability\nto draw a blue ball from a bowel a if we know that we drew exactly a total\nof two blue balls, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8375.0,
    "t_end": 8405.0,
    "text": "what is the probability\nto draw a blue ball from a bowel a if we know that we drew exactly a total\nof two blue balls, right? If you didn't\nunderstand the question, please read it I shall pause\nfor a second or two. Right. So I hope all of you\nhave understood the question. Okay. Now what I'm going to do\nis I'm going to draw a blueprint for you and tell you how exactly\nto solve the problem. But I want you all to give\nme the solution to this problem, right? I'll draw a blueprint. I'll tell you\nwhat exactly the steps are but I want you to come\nup with a solution",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8400.0,
    "t_end": 8430.0,
    "text": "But I want you all to give\nme the solution to this problem, right? I'll draw a blueprint. I'll tell you\nwhat exactly the steps are but I want you to come\nup with a solution on your own right the formula\nis also given to you. Everything is given to you. All you have to do is come up\nwith the final answer. Right? Let's look at how you\ncan solve this problem. So first of all, what we will do is\nLet's consider a all right, let a be the event of picking a blue ball\nfrom bag in and let X be the event of picking\nexactly two blue balls, right because these\nare the two events",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8425.0,
    "t_end": 8455.0,
    "text": "X be the event of picking\nexactly two blue balls, right because these\nare the two events that we need to calculate\nthe probability of now there are two probabilities\nthat you need to consider here. One is the event of picking\na blue ball from bag a and the other is the event of\npicking exactly two blue balls. Okay. So these two are represented\nby a and X respectively and so what we want is\nthe probability of occurrence of event a given X, which means that given",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8450.0,
    "t_end": 8480.0,
    "text": "and so what we want is\nthe probability of occurrence of event a given X, which means that given that we're picking\nexactly two blue balls. What is the probability that we are picking\na blue ball from bag? So by the definition\nof conditional probability, this is exactly what\nour equation will look like. Correct. This is basically a occurrence\nof event a given element X and this is\nthe probability of a and x and this is the probability\nof X alone, correct. What we need to do is we need\nto find these two probabilities",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8475.0,
    "t_end": 8505.0,
    "text": "and this is\nthe probability of a and x and this is the probability\nof X alone, correct. What we need to do is we need\nto find these two probabilities which is probability of a\nand X occurring together and probability of X. Okay. This is the entire solution. So how do you find P probability of X this you can do\nin three ways. So first is white ball\nfrom a either white from be or read from see now first is\nto find the probability of x x basically represents the event",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8500.0,
    "t_end": 8530.0,
    "text": "or read from see now first is\nto find the probability of x x basically represents the event of picking exactly\ntwo blue balls. Right. So these are the three ways\nin which it is possible. So you'll pick one blue ball\nfrom bowel a and one from bowel be in the second case. You can pick one from a and another blue ball\nfrom see in the third case. You can pick a blue\nball from Bagby and a blue ball from bagsy. Right? These are the three ways\nin which it is possible.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8525.0,
    "t_end": 8555.0,
    "text": "You can pick a blue\nball from Bagby and a blue ball from bagsy. Right? These are the three ways\nin which it is possible. So you need to find\nthe probability of each of this step do is that you need to find\nthe probability of a and X occurring together. This is the sum\nof terms one and two. Okay, this is because in both\nof these events, you're picking a ball\nfrom bag, correct? So there is find out\nthis probability and let me know your answer\nin the comment section. All right. We'll see if you get\nthe answer right? I gave you the entire\nsolution to this.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8550.0,
    "t_end": 8580.0,
    "text": "me know your answer\nin the comment section. All right. We'll see if you get\nthe answer right? I gave you the entire\nsolution to this. All you have to do is\nsubstitute the value right? If you want a second or two, I'm going to pause on the screen\nso that you can go through this in a more clearer way right? Remember that you need\nto calculate two. He's the first probability that you need to calculate is\nthe event of picking a blue ball from bag a given that you're picking\nexactly two blue balls. Okay, II probability you need\nto calculate is the event",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8575.0,
    "t_end": 8605.0,
    "text": "from bag a given that you're picking\nexactly two blue balls. Okay, II probability you need\nto calculate is the event of picking exactly to bluebirds. All right. These are the two probabilities. You need to calculate so\nremember that and this is the solution. All right, so guys, make sure you\nmention your answers in the comment section for now. Let's move on and Get\nour next topic, which is the\ninferential statistics. So guys, we just completed the\nprobability module right now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8600.0,
    "t_end": 8630.0,
    "text": "Let's move on and Get\nour next topic, which is the\ninferential statistics. So guys, we just completed the\nprobability module right now. We will discuss\ninferential statistics, which is the second\ntype of Statistics. We discussed descriptive\nstatistics earlier. All right. So like I mentioned earlier\ninferential statistics also known as statistical inference\nis a branch of Statistics that deals with forming\ninferences and predictions about a population based\non a sample of data. Taken from the population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8625.0,
    "t_end": 8655.0,
    "text": "that deals with forming\ninferences and predictions about a population based\non a sample of data. Taken from the population. All right, and the question\nyou should ask is how does one form inferences\nor predictions on a sample? The answer is you\nuse Point estimation? Okay. Now you must be wondering what is point estimation\none estimation is concerned with the use of the sample data\nto measure a single value which serves as\nan approximate value or the best estimate of\nan unknown population parameter. That's a little confusing.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8650.0,
    "t_end": 8680.0,
    "text": "which serves as\nan approximate value or the best estimate of\nan unknown population parameter. That's a little confusing. Let me break it down\nto you for Camping in order to calculate the mean\nof a huge population. What we do is we first draw out\nthe sample of the population and then we find the sample mean right the sample mean\nis then used to estimate the population mean this is\nbasically Point estimate, you're estimating the value\nof one of the parameters of the population, right? Basically the main",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8675.0,
    "t_end": 8705.0,
    "text": "you're estimating the value\nof one of the parameters of the population, right? Basically the main you're trying to estimate\nthe value of the mean. This is what point estimation is\nthe two main terms in point estimation. There's something known as as the estimator\nand the something known as the estimate estimator\nis a function of the sample that is used to find\nout the estimate. Alright in this example. It's basically the sample\nmean right so a function that calculates the sample\nmean is known as the estimator and the realized value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8700.0,
    "t_end": 8730.0,
    "text": "It's basically the sample\nmean right so a function that calculates the sample\nmean is known as the estimator and the realized value of the estimator is\nthe estimate right? So I hope Point\nestimation is clear. Now, how do you\nfind the estimates? There are four common ways\nin which you can do this. The first one is\nmethod of Moment yo, what you do is\nyou form an equation in the sample data set and then you analyze\nthe similar equation in the population data set as well like the population mean\npopulation variance and so on.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8725.0,
    "t_end": 8755.0,
    "text": "and then you analyze\nthe similar equation in the population data set as well like the population mean\npopulation variance and so on. So in simple terms, what you're doing is you're\ntaking down some known facts about the population and you're extending\nthose ideas to the sample. Alright, once you do that, you can analyze the sample\nand estimate more essential or more complex\nvalues right next. We have maximum likelihood. This method basically uses\na model to estimate a value. All right. Now a maximum likelihood\nis majorly based on probability.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8750.0,
    "t_end": 8780.0,
    "text": "This method basically uses\na model to estimate a value. All right. Now a maximum likelihood\nis majorly based on probability. So there's a lot of probability\ninvolved in this method next. We have the base estimator\nthis works by minimizing the errors or the average risk. Okay, the base estimator\nhas a lot to do with the Bayes theorem. All right, let's\nnot get into the depth of these estimation methods. Finally. We have the best unbiased\nestimators in this method. There are seven unbiased\nestimators that can be used",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8775.0,
    "t_end": 8805.0,
    "text": "Finally. We have the best unbiased\nestimators in this method. There are seven unbiased\nestimators that can be used to approximate a parameter. Okay. So Guys these were\na couple of methods that are used\nto find the estimate but the most well-known method\nto find the estimate is known as the interval estimation. Okay. This is one of the most important\nestimation methods right? This is where confidence\ninterval also comes into the picture right apart\nfrom interval estimation. We also have something\nknown as margin of error.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8800.0,
    "t_end": 8830.0,
    "text": "This is where confidence\ninterval also comes into the picture right apart\nfrom interval estimation. We also have something\nknown as margin of error. So I'll be discussing\nall of this. In the upcoming slides. So first let's understand. What is interval estimate? Okay, an interval\nor range of values, which are used to estimate a\npopulation parameter is known as an interval estimation, right? That's very understandable. Basically what they're trying to\nsee is you're going to estimate the value of a parameter. Let's say you're trying to find\nthe mean of a population.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8825.0,
    "t_end": 8855.0,
    "text": "Basically what they're trying to\nsee is you're going to estimate the value of a parameter. Let's say you're trying to find\nthe mean of a population. What you're going to do is\nyou're going to build a range and your value will lie in\nthat range or in that interval. Alright, so this way your output\nis going to be more accurate because you've not predicted\na point estimation instead. You have estimated an interval within which your value\nmight occur, right? Okay. Now this image clearly shows how Point estimate and interval\nestimate or different",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8850.0,
    "t_end": 8880.0,
    "text": "within which your value\nmight occur, right? Okay. Now this image clearly shows how Point estimate and interval\nestimate or different so guys interval estimate\nis obviously more accurate because you are not just\nfocusing on a particular value or a particular point in order to predict\nthe probability instead. You're saying that\nthe value might be within this range between\nthe lower confidence limit and the upper confidence limit. All right, this is denotes\nthe range or the interval.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8875.0,
    "t_end": 8905.0,
    "text": "and the upper confidence limit. All right, this is denotes\nthe range or the interval. Okay, if you're still confused\nabout interval estimation, let me give you a small example if I stated that I will take\n30 minutes to reach the theater. This is known\nas Point estimation. Okay, but if I stated that I will take\nbetween 45 minutes to an hour to reach the theater. This is an example\nof into Estimation. All right. I hope it's clear. Now now interval estimation\ngives rise to two important statistical terminologies one\nis known as confidence interval",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8900.0,
    "t_end": 8930.0,
    "text": "I hope it's clear. Now now interval estimation\ngives rise to two important statistical terminologies one\nis known as confidence interval and the other is known\nas margin of error. All right. So there's it's important that you pay attention to both of these terminologies\nconfidence interval is one of the most significant measures that are used to check how essential machine\nlearning model is. All right. So what is confidence interval\nconfidence interval is the measure of your confidence",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8925.0,
    "t_end": 8955.0,
    "text": "So what is confidence interval\nconfidence interval is the measure of your confidence that the interval\nestimated contains the population parameter\nor the population mean or any of those parameters\nright now statisticians use confidence interval\nto describe the amount of uncertainty associated with the sample estimate of\na population parameter now guys, this is a lot of definition. Let me just make you\nunderstand confidence interval with a small example. Okay. Let's say that you perform",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8950.0,
    "t_end": 8980.0,
    "text": "Let me just make you\nunderstand confidence interval with a small example. Okay. Let's say that you perform a survey and you survey\na group of cat owners. The see how many cans\nof cat food they purchase in one year. Okay, you test your statistics at the 99\npercent confidence level and you get\na confidence interval of hundred comma 200 this means that you think that the cat owners by between hundred to two\nhundred cans in a year and also since the confidence\nlevel is 99% shows",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 8975.0,
    "t_end": 9005.0,
    "text": "by between hundred to two\nhundred cans in a year and also since the confidence\nlevel is 99% shows that you're very confident\nthat the results are, correct. Okay. I hope all of you\nare clear with that. Alright, so your confidence\ninterval here will be a hundred and two hundred and your confidence level\nwill be 99% Right? That's the difference\nbetween confidence interval and confidence level So\nwithin your confidence interval your value is going to lie and\nyour confidence level will show how confident you are\nabout your estimation, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9000.0,
    "t_end": 9030.0,
    "text": "and confidence level So\nwithin your confidence interval your value is going to lie and\nyour confidence level will show how confident you are\nabout your estimation, right? I hope that was clear. Let's look at margin of error. No margin of error for a given level of confidence\nis a greatest possible distance between the Point estimate and the value of the parameter that it is estimating\nyou can say that it is a deviation from\nthe actual point estimate right. Now. The margin of error\ncan be calculated using this formula now zc\nher denotes the critical value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9025.0,
    "t_end": 9055.0,
    "text": "that it is a deviation from\nthe actual point estimate right. Now. The margin of error\ncan be calculated using this formula now zc\nher denotes the critical value or the confidence interval and this is X standard\ndeviation divided by root of the sample size. All right, n is basically\nthe sample size now, let's understand how\nyou can estimate the confidence intervals. So guys the level of confidence which is denoted by\nC is the probability that the interval estimate\ncontains a population parameter.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9050.0,
    "t_end": 9080.0,
    "text": "which is denoted by\nC is the probability that the interval estimate\ncontains a population parameter. Let's say that you're trying\nto estimate the mean. All right. So the level of confidence\nis the probability that the interval\nestimate contains the population parameter. So this interval\nbetween minus Z and z or the area beneath this curve\nis nothing but the probability that the interval estimate\ncontains a population parameter. You don't all right. It should basically\ncontain the value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9075.0,
    "t_end": 9105.0,
    "text": "that the interval estimate\ncontains a population parameter. You don't all right. It should basically\ncontain the value that you are predicting right. Now. These are known\nas critical values. This is basically\nyour lower limit and your higher\nlimit confidence level. Also, there's something\nknown as the Z score now. This court can be calculated by\nusing the standard normal table. All right, if you look\nit up anywhere on Google you'll find the z-score table or the standard normal\ntable to understand how this is done. Let's look at a small example.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9100.0,
    "t_end": 9130.0,
    "text": "or the standard normal\ntable to understand how this is done. Let's look at a small example. Okay, let's say\nthat the level of confidence. Vince is 90% This means\nthat you are 90% confident that the interval contains\nthe population mean. Okay, so the remaining 10%\nwhich is out of hundred percent. The remaining 10%\nis equally distributed on these tail regions. Okay, so you have 0.05 here\nand 0.05 over here, right? So on either side of see you will distribute\nthe other leftover percentage",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9125.0,
    "t_end": 9155.0,
    "text": "Okay, so you have 0.05 here\nand 0.05 over here, right? So on either side of see you will distribute\nthe other leftover percentage now these Z scores\nare calculated from the table as I mentioned before. All right one. I'm 6 4 5 is get collated\nfrom the standard normal table. Okay, so guys how you estimate\nthe level of confidence? So to sum it up. Let me tell you the steps that\nare involved in constructing a confidence interval first. You would start by identifying\na sample statistic. Okay. This is the statistic",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9150.0,
    "t_end": 9180.0,
    "text": "a confidence interval first. You would start by identifying\na sample statistic. Okay. This is the statistic that you will use to estimate\na population parameter. This can be anything\nlike the mean of the sample next you\nwill select a confidence level now the confidence level\ndescribes the uncertainty of a Sampling method right after that you'll find\nsomething known as the margin of error right? We discussed margin\nof error earlier. So you find this based\non the equation that I explained\nin the previous slide, then you'll finally specify\nthe confidence interval.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9175.0,
    "t_end": 9205.0,
    "text": "We discussed margin\nof error earlier. So you find this based\non the equation that I explained\nin the previous slide, then you'll finally specify\nthe confidence interval. All right. Now, let's look\nat a problem statement to better understand\nthis concept a random sample of 32 textbook prices is taken\nfrom a local College Bookstore. The mean of the sample is so so and so and the sample\nstandard deviation is This use a 95% confident level and find the margin\nof error for the mean price of all text books\nin the bookstore.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9200.0,
    "t_end": 9230.0,
    "text": "This use a 95% confident level and find the margin\nof error for the mean price of all text books\nin the bookstore. Okay. Now, this is a very\nstraightforward question. If you want you can read\nthe question again. All you have to do is you have\nto just substitute the values into the equation. All right, so guys, we know the formula for margin\nof error you take the Z score from the table. After that we have deviation\nMadrid's 23.4 for right and that's standard deviation\nand n stands for the number",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9225.0,
    "t_end": 9255.0,
    "text": "After that we have deviation\nMadrid's 23.4 for right and that's standard deviation\nand n stands for the number of samples here. The number of samples is\n32 basically 32 textbooks. So approximately your margin\nof error is going to be around 8.1 to this is\na pretty simple question. All right. I hope all of you\nunderstood this now that you know, the idea behind\nconfidence interval. Let's move ahead to one of the most important topics\nin statistical inference, which is hypothesis\ntesting, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9250.0,
    "t_end": 9280.0,
    "text": "Let's move ahead to one of the most important topics\nin statistical inference, which is hypothesis\ntesting, right? So Ugly statisticians\nuse hypothesis testing to formally check whether the hypothesis\nis accepted or rejected. Okay, hypothesis. Testing is an inferential\nstatistical technique used to determine whether there is enough evidence\nin a data sample to infer that a certain condition holds\ntrue for an entire population. So to understand",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9275.0,
    "t_end": 9305.0,
    "text": "that a certain condition holds\ntrue for an entire population. So to understand the characteristics\nof a general population, we take a random sample, and we analyze the properties\nof the sample right we test. Whether or not the identified\nconclusion represents the population accurately and finally we interpret\nthe results now whether or not to accept\nthe hypothesis depends upon the percentage value\nthat we get from the hypothesis. Okay, so to\nbetter understand this, let's look at a small\nexample before that.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9300.0,
    "t_end": 9330.0,
    "text": "upon the percentage value\nthat we get from the hypothesis. Okay, so to\nbetter understand this, let's look at a small\nexample before that. There are a few steps\nthat are followed in hypothesis testing you begin\nby stating the null and the alternative hypothesis. All right. I'll tell you what\nexactly these terms are and then you formulate. Analysis plan right after that\nyou analyze the sample data and finally you can\ninterpret the results right now to understand\nthe entire hypothesis testing. We look at a good example.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9325.0,
    "t_end": 9355.0,
    "text": "right now to understand\nthe entire hypothesis testing. We look at a good example. Okay now consider\nfor boys Nick jean-bob and Harry these boys\nwere caught bunking a class and they were asked\nto stay back at school and clean the classroom\nas a punishment, right? So what John did is he decided that four of them would take\nturns to clean their classrooms. He came up with a plan\nof writing each of their names on chits and putting them in a bowl now every day they had\nto pick up a name from the bowel",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9350.0,
    "t_end": 9380.0,
    "text": "He came up with a plan\nof writing each of their names on chits and putting them in a bowl now every day they had\nto pick up a name from the bowel and that person had to play\nin the clock, right? That sounds pretty fair\nenough now it is been three days and everybody's name has come up\nexcept John's assuming that this event\nis completely random and free of bias. What is a probability of John not cheating\nright or is the probability that he's not actually\ncheating this can Solved by using hypothesis testing.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9375.0,
    "t_end": 9405.0,
    "text": "of John not cheating\nright or is the probability that he's not actually\ncheating this can Solved by using hypothesis testing. Okay. So we'll Begin by calculating\nthe probability of John not being picked for a day. Alright, so we're\ngoing to assume that the event is free of bias. So we need to find\nout the probability of John not cheating right first\nwe will find the probability that John is not picked\nfor a day, right? We get 3 out of 4, which is basically 75%\n75% is fairly high. So if John is not picked\nfor three days in a row",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9400.0,
    "t_end": 9430.0,
    "text": "which is basically 75%\n75% is fairly high. So if John is not picked\nfor three days in a row the Probability will drop down\nto approximately 42% Okay. So three days in a row meaning that is the probability\ndrops down to 42 percent. Now, let's consider a situation where John is not picked\nfor 12 days in a row the probability drops down\nto three point two percent. Okay. That's the probability\nof John cheating becomes fairly high, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9425.0,
    "t_end": 9455.0,
    "text": "the probability drops down\nto three point two percent. Okay. That's the probability\nof John cheating becomes fairly high, right? So in order for statisticians to come\nto a conclusion, they Define what is known\nas a threshold value. Right considering\nthe above situation if the threshold value\nis set to 5 percent. It would indicate that if the probability lies\nbelow 5% then John is cheating his way out of detention. But if the probability is\nabout threshold value then John it just lucky and his name\nisn't getting picked.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9450.0,
    "t_end": 9480.0,
    "text": "But if the probability is\nabout threshold value then John it just lucky and his name\nisn't getting picked. So the probability and hypothesis testing give rise\nto two important components of hypothesis testing, which is null hypothesis\nand alternative hypothesis. Null. Hypothesis is based. Basically approving the Assumption alternate\nhypothesis is when your result disapproves\nthe Assumption right therefore in our example, if the probability\nof an event occurring is less than 5% which it is\nthen the event is biased hence.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9475.0,
    "t_end": 9505.0,
    "text": "when your result disapproves\nthe Assumption right therefore in our example, if the probability\nof an event occurring is less than 5% which it is\nthen the event is biased hence. It proves the\nalternate hypothesis. So guys with this we come\nto the end of this session. Let's go ahead\nand understand what exactly is. Was learning so\nsupervised learning is where you have\nthe input variable X and the output variable Y\nand use an algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9500.0,
    "t_end": 9530.0,
    "text": "Was learning so\nsupervised learning is where you have\nthe input variable X and the output variable Y\nand use an algorithm to learn the map Egg function\nfrom the input to the output as I mentioned earlier with the example\nof face detection. So it is called\nsupervised learning because the process\nof an algorithm learning from the training data\nset can be thought of as a teacher supervising\nthe learning process. So if we have a look\nat the supervised learning steps or What would rather\nsay the workflow? So the model is used\nas you can see here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9525.0,
    "t_end": 9555.0,
    "text": "So if we have a look\nat the supervised learning steps or What would rather\nsay the workflow? So the model is used\nas you can see here. We have the historic data. Then we again we have\nthe random sampling. We split the data\ninto train your asset and the testing data set using\nthe training data set. We with the help\nof machine learning which is supervised\nmachine learning. We create statistical model then after we have a mod\nwhich is being generated with the help\nof the training data set. What we do is use\nthe testing data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9550.0,
    "t_end": 9580.0,
    "text": "after we have a mod\nwhich is being generated with the help\nof the training data set. What we do is use\nthe testing data set for production and testing. What we do is get the output and finally we have\nthe model validation outcome. That was the\ntraining and testing. So if we have a look\nat the prediction part of any particular supervised\nlearning algorithm, so the model is used\nfor operating outcome of a new data set. So whenever performance of the model degraded\nthe model is retrained or if there are\nany performance issues, the model is retained with\nthe help of the new data now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9575.0,
    "t_end": 9605.0,
    "text": "of the model degraded\nthe model is retrained or if there are\nany performance issues, the model is retained with\nthe help of the new data now when we talk about supervisor in there not just one\nbut quite a few algorithms here. So we have linear\nregression logistic regression. This is entry. We have random Forest. We have made by classifiers. So linear regression is used\nto estimate real values. For example, the cost of houses. The number of calls\nthe total sales based on the continuous variables.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9600.0,
    "t_end": 9630.0,
    "text": "For example, the cost of houses. The number of calls\nthe total sales based on the continuous variables. So that is what\nreading regression is. Now when we talk\nabout logistic regression, which is used to estimate\ndiscrete values, for example, which are binary values\nlike 0 and 1 yes, or no true. False based on the given set\nof independent variables. So for example, when you are talking\nabout something like the chances of winning or if you talk about winning which can be\neither true or false if will it rain today\nwith it can be the yes or no,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9625.0,
    "t_end": 9655.0,
    "text": "of winning or if you talk about winning which can be\neither true or false if will it rain today\nwith it can be the yes or no, so it cannot be like when the output\nof a particular algorithm or the particular\nquestion is either. Yes. No or Banner e then only we use a large\nstick regression the next we have decision trees. So now these are used for\nclassification problems it work. X for both\ncategorical and continuous dependent variables and if we talk about random Forest\nSo Random Forest is an M symbol",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9650.0,
    "t_end": 9680.0,
    "text": "dependent variables and if we talk about random Forest\nSo Random Forest is an M symbol of a decision tree, it gives better prediction\naccuracy than decision tree. So that is another type of\nsupervised learning algorithm. And finally we have\nthe need based classifier. So it was a classification technique based\non the Bayes theorem with an assumption of\nIndependence between predictors. A linear regression is one\nof the easiest algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9675.0,
    "t_end": 9705.0,
    "text": "A linear regression is one\nof the easiest algorithm in machine learning. It is a statistical model that attempts to\nshow the relationship between two variables\nwith a linear equation. But before we drill down to linear regression\nalgorithm in depth, I'll give you a quick overview\nof today's agenda. So we'll start a session with a quick overview\nof what is regression as linear regression\nis one of a type of regression algorithm. Once we learn about regression, its use case the various\ntypes of it next.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9700.0,
    "t_end": 9730.0,
    "text": "of regression algorithm. Once we learn about regression, its use case the various\ntypes of it next. We'll learn about\nthe algorithm from scratch. Each where I'll teach you it's mathematical\nimplementation first, then we'll drill down\nto the coding part and Implement linear\nregression using python in today's session will deal with linear regression algorithm\nusing least Square method check its goodness of fit or how close the data is to the fitted regression line\nusing the R square method. And then finally what will do will optimize it\nusing the gradient decent method",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9725.0,
    "t_end": 9755.0,
    "text": "to the fitted regression line\nusing the R square method. And then finally what will do will optimize it\nusing the gradient decent method in the last part\non the coding session. I'll teach you to implement\nlinear regression using Python and Coding session would be divided into two parts\nthe first part would consist of linear regression\nusing python from scratch where you will use\nthe mathematical algorithm that you have learned\nin this session. And in the next part\nof the coding session will be using scikit-learn\nfor direct implementation of linear regression. So let's begin our session\nwith what is regression.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9750.0,
    "t_end": 9780.0,
    "text": "And in the next part\nof the coding session will be using scikit-learn\nfor direct implementation of linear regression. So let's begin our session\nwith what is regression. Well regression analysis is a form of predictive\nmodeling technique which investigates the\nrelationship between a dependent and independent variable\na regression analysis. Vols graphing a line\nover a set of data points that most closely fits\nthe overall shape of the data or regression shows the changes\nin a dependent variable on the y-axis to the changes in the explanation variable\non the x-axis fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9775.0,
    "t_end": 9805.0,
    "text": "or regression shows the changes\nin a dependent variable on the y-axis to the changes in the explanation variable\non the x-axis fine. Now you would ask\nwhat are the uses of regression? Well, there are major three uses\nof regression analysis the first being determining the strength\nof predicates errs, the regression might be used\nto identify the strength of the effect that the independent variables\nhave on the dependent variable or But you can ask question. Like what is the strength\nof relationship between sales and marketing spending or what\nis the relationship between age",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9800.0,
    "t_end": 9830.0,
    "text": "Like what is the strength\nof relationship between sales and marketing spending or what\nis the relationship between age and income second is forecasting an effect in this the regression\ncan be used to forecast effects or impact of changes. That is the regression analysis\nhelp us to understand how much the dependent variable\nchanges with the change and one or more\nindependent variable fine. For example, you can ask\nquestion like how much additional say Lancome\nwill I get for each? Thousand dollars\nspent on marketing. So it is Trend forecasting",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9825.0,
    "t_end": 9855.0,
    "text": "additional say Lancome\nwill I get for each? Thousand dollars\nspent on marketing. So it is Trend forecasting in this the regression\nanalysis predict Trends and future values. The regression analysis can\nbe used to get Point estimates in this you can ask questions. Like what will be\nthe price of Bitcoin and next six months, right? So next topic is linear versus\nlogistic regression by now. I hope that you know,\nwhat a regression is. So let's move on\nand understand its type. So there are various kinds\nof regression like linear regression logistic regression\npolynomial regression.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9850.0,
    "t_end": 9880.0,
    "text": "So let's move on\nand understand its type. So there are various kinds\nof regression like linear regression logistic regression\npolynomial regression. Others only but for this session will be focusing on linear\nand logistic regression. So let's move on and let me tell\nyou what is linear regression. And what is logistic regression then what we'll do\nwe'll compare both of them. All right. So starting with\nlinear regression in simple linear regression, we are interested in things\nlike y equal MX plus C. So what we are trying to find\nis the correlation between X",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9875.0,
    "t_end": 9905.0,
    "text": "we are interested in things\nlike y equal MX plus C. So what we are trying to find\nis the correlation between X and Y variable this means that every value of x has a corresponding\nvalue of y and it if it is continuous. All right, however\nin logistic regression, we are not fitting our data\nto a straight line like linear regression instead\nwhat we are doing. We are mapping Y versus X to a sigmoid function\nin logistic regression. What we find out is is y 1 or 0\nfor this particular value of x",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9900.0,
    "t_end": 9930.0,
    "text": "to a sigmoid function\nin logistic regression. What we find out is is y 1 or 0\nfor this particular value of x so thus we are essentially\ndeciding true or false value for a given value of x fine. So as a core concept\nof linear regression, you can say that the data\nis modeled using a straight. But in the case\nof logistic regression the data is module using\na sigmoid function. The linear regression is used\nwith continuous variables on the other hand\nthe logistic regression. It is used with categorical\nvariable the output or the prediction\nof a linear regression",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9925.0,
    "t_end": 9955.0,
    "text": "The linear regression is used\nwith continuous variables on the other hand\nthe logistic regression. It is used with categorical\nvariable the output or the prediction\nof a linear regression is a value of the variable on the other hand\nthe output of production of a logistic regression\nis the probability of occurrence of the event. Now, how will you\ncheck the accuracy and goodness of fit in case\nof linear regression? We are various methods\nlike measured by loss R square. Are adjusted r squared Etc while in the case\nof logistic regression you have accuracy precision\nrecall F1 score,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9950.0,
    "t_end": 9980.0,
    "text": "while in the case\nof logistic regression you have accuracy precision\nrecall F1 score, which is nothing but\nthe harmonic mean of precision and recall next is Roc curve for determining the probability\nthreshold for classification or the confusion Matrix Etc. There are many all right. So summarizing the difference between linear and\nlogistic regression. You can say that the type of function you\nare mapping to is the main point of difference between linear\nand logistic regression a linear regression model. The Continuous X2 a continuous\nfile on the other hand",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 9975.0,
    "t_end": 10005.0,
    "text": "of difference between linear\nand logistic regression a linear regression model. The Continuous X2 a continuous\nfile on the other hand a logistic regression\nMaps a continuous x to the bindery why so we can use logistic\nregression to make category or true false decisions\nfrom the data find so let's move\non ahead next is linear regression selection criteria, or you can say when will\nyou use linear regression? So the first is classification and regression capabilities\nregression models predict a continuous variable such as\nthe sales made on a day",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10000.0,
    "t_end": 10030.0,
    "text": "and regression capabilities\nregression models predict a continuous variable such as\nthe sales made on a day or predict the temperature of a city T their Reliance\non a polynomial like a straight line\nto fit a data set poses a real challenge when it comes towards building\na classification capability. Let's imagine that you fit\na line with a train points that you have now imagine you\nadd some more data points to it. But in order to fit it,\nwhat do you have to do? You have to change\nyour existing model that is maybe you have\nto change the threshold itself. So this will happen\nwith each new data point you are",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10025.0,
    "t_end": 10055.0,
    "text": "You have to change\nyour existing model that is maybe you have\nto change the threshold itself. So this will happen\nwith each new data point you are to the model hence. The linear regression is not\ngood for classification models. Fine. Next is data quality. Each missing value\nremoves one data point that could optimize the regression and\nsimple linear regression. The outliers can significantly disrupt the outcome\njust for now. You can know that if you\nremove the outliers your model will become very good. All right. So this is about data quality. Next is computational complexity\na linear regression is often",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10050.0,
    "t_end": 10080.0,
    "text": "will become very good. All right. So this is about data quality. Next is computational complexity\na linear regression is often not computationally expensive as\ncompared to the decision tree or the clustering algorithm\nthe order of complexity for n training example\nand X features usually Falls in either Big O of x Or bigger of xn\nnext is comprehensible and transparent the\nlinear regression are easily comprehensible\nand transparent in nature. They can be represented by\na simple mathematical notation to anyone and can be\nunderstood very easily.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10075.0,
    "t_end": 10105.0,
    "text": "easily comprehensible\nand transparent in nature. They can be represented by\na simple mathematical notation to anyone and can be\nunderstood very easily. So these are some\nof the criteria based on which you will select\nthe linear regression algorithm. All right. Next is where is linear\nregression used first is evaluating trans\nand sales estimate. Well linear regression\ncan be used in business to evaluate Trends\nand make estimates. Forecast for example, if a company sales have\nincreased steadily every month for past few years then\nconducting a linear analysis",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10100.0,
    "t_end": 10130.0,
    "text": "if a company sales have\nincreased steadily every month for past few years then\nconducting a linear analysis on the sales data\nwith monthly sales on the y axis and time on the x axis. This will give you a line that predicts the upward Trends\nin the sale after creating the trendline the company\ncould use the slope of the lines to focused\nsale in future months. Next is analyzing. The impact of price changes\nwill linear regression can be used to analyze\nthe effect of pricing on Omer behavior for instance, if a company changes the price on a certain\nproduct several times,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10125.0,
    "t_end": 10155.0,
    "text": "can be used to analyze\nthe effect of pricing on Omer behavior for instance, if a company changes the price on a certain\nproduct several times, then it can record the quantity\nitself for each price level and then perform\na linear regression with sold quantity as a dependent variable and price\nas the independent variable. This would result in a line\nthat depicts the extent to which the customer reduce\ntheir consumption of the product as the prices increasing. So this result would help us\nin future pricing decisions. Next is assessment of risk\nin financial services",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10150.0,
    "t_end": 10180.0,
    "text": "So this result would help us\nin future pricing decisions. Next is assessment of risk\nin financial services and insurance domain. Linear regression can be used\nto analyze the risk, for example health insurance\ncompany might conduct a linear regression algorithm how it can do it can do it\nby plotting the number of claims per customer against its age\nand they might discover that the old customers tend to make more\nhealth insurance claim. Well the result\nof such analysis might guide important business decisions. All right, so by now you\nhave just a rough idea of",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10175.0,
    "t_end": 10205.0,
    "text": "Well the result\nof such analysis might guide important business decisions. All right, so by now you\nhave just a rough idea of what linear regression\nalgorithm as like what it does where it is used\nwhen You should use it early. Now. Let's move on\nand understand the algorithm and depth so suppose\nyou have independent variable on the x-axis and dependent\nvariable on the y-axis. All right suppose. This is the data point\non the x axis. The independent variable\nis increasing on the x-axis. And so does the dependent\nvariable on the y-axis?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10200.0,
    "t_end": 10230.0,
    "text": "This is the data point\non the x axis. The independent variable\nis increasing on the x-axis. And so does the dependent\nvariable on the y-axis? So what kind of linear\nregression line you would get you would get a positive\nlinear regression line. All right as the slope would\nbe positive next is suppose. You have an independent\nvariable on the X axis which is increasing and on the other hand the\ndependent variable on the y-axis that is decreasing. So what kind of line\nwill you get in that case? You will get\na negative regression line. In this case as the slope\nof the line is negative",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10225.0,
    "t_end": 10255.0,
    "text": "So what kind of line\nwill you get in that case? You will get\na negative regression line. In this case as the slope\nof the line is negative and this particular line that is line of y equal MX plus C is a line\nof linear regression which shows the relationship\nbetween independent variable and dependent variable and this line is only known\nas line of linear regression. Okay. So let's add\nsome data points, too. Our graph so these\nare some observation or data points on our graph. So let's plot some more. Okay. Now all our data points\nare plotted now our task is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10250.0,
    "t_end": 10280.0,
    "text": "or data points on our graph. So let's plot some more. Okay. Now all our data points\nare plotted now our task is to create a regression line\nor the best fit line. All right now once our regression\nline is drawn now, it's the task\nof production now suppose. This is our estimated value\nor the predicted value and this is our actual value. Okay. So what we have to do our main\ngoal is to reduce this error that is to reduce the distance between the Estimated\nor the predicted value and the actual value the best\nfit line would be the one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10275.0,
    "t_end": 10305.0,
    "text": "that is to reduce the distance between the Estimated\nor the predicted value and the actual value the best\nfit line would be the one which had the least error or the least difference\nin estimated value and the actual value. All right, and other words we\nhave to minimize the error. This was a brief understanding of linear regression\nalgorithm soon. We'll jump towards\nmathematical implementation. But for then let me tell you\nthis suppose you draw a graph with speed on the x-axis and distance covered on the y axis with\nthe time domain in constant.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10300.0,
    "t_end": 10330.0,
    "text": "But for then let me tell you\nthis suppose you draw a graph with speed on the x-axis and distance covered on the y axis with\nthe time domain in constant. If you plot a graph\nbetween the speed travel by the vehicle and the distance traveled\nin a fixed unit of time, then you will get\na positive relationship. All right. So suppose the equation\nof a line is y equal MX plus C. Then in this case Y is\nthe distance traveled in a fixed duration of time x is the speed of vehicle m\nis the positive slope of the line and see is\nthe y-intercept of the line. All right suppose\nthe distance remaining constant.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10325.0,
    "t_end": 10355.0,
    "text": "is the speed of vehicle m\nis the positive slope of the line and see is\nthe y-intercept of the line. All right suppose\nthe distance remaining constant. You have to plot a graph\nbetween the speed of the vehicle and the time taken\nto travel a fixed distance. Then in that case\nyou will get a line with a negative relationship. All right, the slope of the line\nis negative here the equation of line changes to y\nequal minus of MX plus C where Y is the time\ntaken to travel a fixed distance X is the speed of vehicle m is\nthe negative slope of the line and see is\nthe y-intercept of the line.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10350.0,
    "t_end": 10380.0,
    "text": "where Y is the time\ntaken to travel a fixed distance X is the speed of vehicle m is\nthe negative slope of the line and see is\nthe y-intercept of the line. All right. Now, let's get back to our independent\nand dependent variable. So in that term,\nwhy is our dependent variable and X that is\nour independent variable now, let's move on. And see them at the magical\nimplementation of the things. Alright, so we have x equal 1 2 3 4 5 let's plot\nthem on the x-axis. So 0 1 2 3 4 5 6 align\nand we have y as 3 4 2 4 5.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10375.0,
    "t_end": 10405.0,
    "text": "equal 1 2 3 4 5 let's plot\nthem on the x-axis. So 0 1 2 3 4 5 6 align\nand we have y as 3 4 2 4 5. All right. So let's plot 1 2 3 4 5 on the y-axis now, let's plot our coordinates 1\nby 1 so x equal 1 and y equal 3, so we have here x equal 1 and y equal 3 So this is the point\n1 comma 3 so similarly we have 1 3 2 4 3 2 4 4 & 5 5. Alright, so moving on ahead.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10400.0,
    "t_end": 10430.0,
    "text": "3 So this is the point\n1 comma 3 so similarly we have 1 3 2 4 3 2 4 4 & 5 5. Alright, so moving on ahead. Let's calculate the mean of X\nand Y and plot it on the graph. All right, so mean of X is 1 plus 2 plus 3 plus 4\nplus 5 divided by 5. That is 3. All right, similarly mean\nof Y is 3 plus 4 plus 2 plus 4 plus 5 that is 18. So we 10 divided by 5. That is nothing but 3.6. Alright, so next\nwhat we'll do we'll plot. I mean that is 3 comma\n3 .6 on the graph.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10425.0,
    "t_end": 10455.0,
    "text": "That is nothing but 3.6. Alright, so next\nwhat we'll do we'll plot. I mean that is 3 comma\n3 .6 on the graph. Okay. So there's a point 3 comma 3 .6 see our goal is to find\nor predict the best fit line using the least Square\nMethod All right. So in order to find that we first need to find\nthe equation of line, so let's find the equation\nof our regression line. Alright, so let's suppose\nthis is our regression line y equal MX plus C. Now. We have an equation of line. So all we need to do\nis find the value of M",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10450.0,
    "t_end": 10480.0,
    "text": "Alright, so let's suppose\nthis is our regression line y equal MX plus C. Now. We have an equation of line. So all we need to do\nis find the value of M and C. I wear m equals\nsummation of x minus X bar X Y minus y bar\nupon the summation of x minus X bar whole Square\ndon't get confused. Let me resolve it for you. All right. So moving on ahead\nas a part of formula. What we are going to do\nwill calculate x minus X bar. So we have X as 1 minus X bar\nas 3 so 1 minus 3 that is minus 2 next.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10475.0,
    "t_end": 10505.0,
    "text": "So we have X as 1 minus X bar\nas 3 so 1 minus 3 that is minus 2 next. We have x equal\nto minus its mean 3 that is minus 1\nsimilarly we 3 - 3 0 4 minus 3 1 5 - 3 2. All right, so x minus X bar. It's nothing but the distance\nof all the point through the line y equal 3 and what does this y minus y bar implies\nit implies the distance of all the point from the line",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10500.0,
    "t_end": 10530.0,
    "text": "and what does this y minus y bar implies\nit implies the distance of all the point from the line x equal 3 .6 fine. So let's calculate the value\nof y minus y bar. So starting with y equal 3 - value of y bar\nthat is 3.6. So it is three minus three. .6. How much - of 0.6 next is 4 minus 3.6\nthat is 0.4 next to minus 3.6 that is - of 1.6. Next is 4 minus 3.6\nthat is 0.4 again,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10525.0,
    "t_end": 10555.0,
    "text": "of 0.6 next is 4 minus 3.6\nthat is 0.4 next to minus 3.6 that is - of 1.6. Next is 4 minus 3.6\nthat is 0.4 again, 5 minus 3.6 that is 1.4. Alright, so now we are done\nwith Y minus y bar fine now next we will calculate x\nminus X bar whole Square. So let's calculate x\nminus X bar whole Square so it is - 2 whole square that is\n4 minus 1 whole square. That is 1 0 squared is\n0 1 Square 1 2 square for fine. So now in our table we have x\nminus X bar y minus y bar",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10550.0,
    "t_end": 10580.0,
    "text": "2 whole square that is\n4 minus 1 whole square. That is 1 0 squared is\n0 1 Square 1 2 square for fine. So now in our table we have x\nminus X bar y minus y bar and x minus X bar whole Square. Now what we need. We need the product of x\nminus X bar X Y minus y bar. Alright, so let's see\nthe product of x minus X bar X Y minus y bar that is minus\nof 2 x minus of 0.6. That is 1.2 minus\nof 1 x 0 point 4. That is minus. - of zero point 4 0 x\nminus of 1.6.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10575.0,
    "t_end": 10605.0,
    "text": "That is 1.2 minus\nof 1 x 0 point 4. That is minus. - of zero point 4 0 x\nminus of 1.6. That is 0 1 multiplied\nby zero point four that is 0.4. And next 2 multiplied\nby 1 point for that is 2.8. All right. Now almost all the parts\nof our formula is done. So now what we need\nto do is get the summation of last two columns. All right, so the summation of x\nminus X bar whole square is 10 and the summation of x minus X bar X Y minus y bar is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10600.0,
    "t_end": 10630.0,
    "text": "All right, so the summation of x\nminus X bar whole square is 10 and the summation of x minus X bar X Y minus y bar is for So the value of M\nwill be equal to 4 by 10 fine. So let's put this value of m equals zero point 4\nand our line y equal MX plus C. So let's file all the points\ninto the equation and find the value of C. So we have y as 3.6 remember\nthe mean by m as 0.4 which we calculated just\nnow X as the mean value of x",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10625.0,
    "t_end": 10655.0,
    "text": "So we have y as 3.6 remember\nthe mean by m as 0.4 which we calculated just\nnow X as the mean value of x that is 3 and we have the equation as\n3 point 6 equals 0 .4 Applied by 3 plus C. Alright that is 3.6 equal\n1 Point 2 plus C. So what is the value of C\nthat is 3.6 minus 1.2. That is 2.4. All right. So what we had we had m equals\nzero point four C as 2.4. And then finally when we calculate the equation\nof the regression line,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10650.0,
    "t_end": 10680.0,
    "text": "So what we had we had m equals\nzero point four C as 2.4. And then finally when we calculate the equation\nof the regression line, what we get is y equal\nzero point four times of X plus two point four. So this is the regression line. All right, so there is how you are plotting\nyour points this Actual point. All right now for given m equals\nzero point four and SQL 2.4. Let's predict the value of y\nfor x equal 1 2 3 4 & 5. So when x equal\n1 the predicted value of y will be zero point four x",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10675.0,
    "t_end": 10705.0,
    "text": "Let's predict the value of y\nfor x equal 1 2 3 4 & 5. So when x equal\n1 the predicted value of y will be zero point four x one plus two point\nfour that is 2.8. Similarly when x equal\nto predicted value of y will be zero point 4 x 2 + 2 point 4 that equals\nto 3 point 2 similarly x equal 3 y will be 3. .6. X equals 4 y will be 4 point 0 x equal 5 y will be\nfour point four. So let's plot them on the graph",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10700.0,
    "t_end": 10730.0,
    "text": "X equals 4 y will be 4 point 0 x equal 5 y will be\nfour point four. So let's plot them on the graph and the line passing through\nall these predicting point and cutting y-axis at 2.4\nas the line of regression. Now your task is to calculate\nthe distance between the actual and the predicted value and your job is\nto reduce the distance. All right, or in other words, you have to reduce the error\nbetween the actual and the predicted value the line with the least error will be\nthe line of linear regression. Chicken or regression line and it will also be\nthe best fit line.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10725.0,
    "t_end": 10755.0,
    "text": "with the least error will be\nthe line of linear regression. Chicken or regression line and it will also be\nthe best fit line. All right. So this is how things\nwork in computer. So what it do it performs\nn number of iteration for different values of M\nfor different values of M. It will calculate\nthe equation of line where y equals MX plus C. Right? So as the value\nof M changes the line is changing so iteration\nwill start from one. All right, and it will perform\na number of iteration. So after every iteration what it will do it\nwill calculate the predicted.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10750.0,
    "t_end": 10780.0,
    "text": "is changing so iteration\nwill start from one. All right, and it will perform\na number of iteration. So after every iteration what it will do it\nwill calculate the predicted. Value according to the line\nand compare the distance of actual value\nto the predicted value and the value of M for which the distance\nbetween the actual and the predicted value is\nminimum will be selected as the best fit line. All right. Now that we have calculated\nthe best fit line now, it's time to check the goodness\nof fit or to check how good a model is performing. So in order to do that,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10775.0,
    "t_end": 10805.0,
    "text": "it's time to check the goodness\nof fit or to check how good a model is performing. So in order to do that, we have a method\ncalled R square method. So what is this R square? Well r-squared value is\na statistical measure of how close the data are to the fitted regression\nline in general. It is considered that a high r-squared\nvalue model is a good model, but you can also have\na lower squared value for a good model as well or a higher squared\nvalue for a model that does not fit at all. I like it is also known as\ncoefficient of determination or the coefficient\nof multiple determination.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10800.0,
    "t_end": 10830.0,
    "text": "that does not fit at all. I like it is also known as\ncoefficient of determination or the coefficient\nof multiple determination. Let's move on and see\nhow a square is calculated. So these are our actual values\nplotted on the graph. We had calculated\nthe predicted values of Y as 2.8 3.2 3.6 4.0 4.4. Remember when we calculated\nthe predicted values of Y for the equation Y\npredicted equals 0 1 4 x of X plus two point\nfour for every x equal 1 2 3 4 & 5 from there. We got the Ed values\nof Phi all right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10825.0,
    "t_end": 10855.0,
    "text": "of X plus two point\nfour for every x equal 1 2 3 4 & 5 from there. We got the Ed values\nof Phi all right. So let's plot it on the graph. So these are point\nand the line passing through these points are nothing\nbut the regression line. All right. Now what you need to do is you have to check and compare\nthe distance of actual - mean versus the distance\nof predicted - mean alike. So basically what you are doing\nyou are calculating the distance of actual value to the mean\nto distance of predicted value to the mean I like",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10850.0,
    "t_end": 10880.0,
    "text": "So basically what you are doing\nyou are calculating the distance of actual value to the mean\nto distance of predicted value to the mean I like so there is nothing but a square in mathematically\nyou can represent our school. Whereas summation of Y\npredicted values minus y bar whole Square divided\nby summation of Y minus y bar whole Square where Y is the actual value\ny p is the predicted value and Y Bar is the mean value of y\nthat is nothing but 3.6. Remember, this is our formula. So next what we'll do\nwe'll calculate y minus. Y1.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10875.0,
    "t_end": 10905.0,
    "text": "Remember, this is our formula. So next what we'll do\nwe'll calculate y minus. Y1. So we have y is\n3y bar as 3 point 6, so we'll calculate\nit as 3 minus 3.6 that is nothing but minus of 0.6\nsimilarly for y equal 4 and Y Bar equal 3.6. We have y minus y bar as\nzero point 4 then 2 minus 3.6. It is 1 point 6 4 minus\n3.6 again zero point four and five minus 3.6 it is 1.4. So we got the value\nof y minus y bar.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10900.0,
    "t_end": 10930.0,
    "text": "It is 1 point 6 4 minus\n3.6 again zero point four and five minus 3.6 it is 1.4. So we got the value\nof y minus y bar. Now what we have to do we\nhave to take it Square. So we have minus 0.6 Square\nas 0.36 0.4 Square as 0.16 - of 1.6 Square as 2.56 0.4 Square\nas 0.16 and 1.4 squared is 1.96 now is a part\nof formula what we need. We need our YP\nminus y BAR value.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10925.0,
    "t_end": 10955.0,
    "text": "is 1.96 now is a part\nof formula what we need. We need our YP\nminus y BAR value. So these are VIP values and we\nhave to subtract it from the No, why so 2 .8 minus 3.6\nthat is minus 0.8. Similarly. We will get 3.2 minus 3.6\nthat is 0.4 and 3.6 minus 3.6. That is 0 for 1 0 minus\n3.6 that is 0.4. Then 4 .4 minus 3.6 that is 0.8. So we calculated the value\nof YP minus y bar now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10950.0,
    "t_end": 10980.0,
    "text": "Then 4 .4 minus 3.6 that is 0.8. So we calculated the value\nof YP minus y bar now, it's our turn to calculate\nthe value of y b minus y bar whole Square next. We have - of 0.8 Square as 0.64 - of Point\nfour square as 0.160 Square 0 0 point 4 Square as again 0.16\nand 0.8 Square as 0.64. All right. Now as a part of formula what it suggests it suggests\nme to take the summation of Y P",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 10975.0,
    "t_end": 11005.0,
    "text": "All right. Now as a part of formula what it suggests it suggests\nme to take the summation of Y P minus y bar whole square and summation of Y minus\ny bar whole Square. All right. Let's see. So in submitting y\nminus y bar whole Square what you get is five point two\nand summation of Y P minus y bar whole Square you\nget one point six. So the value of R square\ncan be calculated as 1 point 6 upon 5.2 fine. So the result which will get\nis approximately equal to 0.3. Well, this is not a good fit.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11000.0,
    "t_end": 11030.0,
    "text": "1 point 6 upon 5.2 fine. So the result which will get\nis approximately equal to 0.3. Well, this is not a good fit. All right, so it suggests that the data points are far\naway from the regression line. Alright, so this is how your graph will look\nlike when R square is 0.3 when you increase the value\nof R square to 0.7. So you'll see that the actual value would like\ncloser to the regression line when it reaches to 0.9 it comes. More clothes and when the value\nof approximately equals to 1 then the actual values lies\non the regression line itself,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11025.0,
    "t_end": 11055.0,
    "text": "More clothes and when the value\nof approximately equals to 1 then the actual values lies\non the regression line itself, for example, in this case. If you get a very low value\nof R square suppose 0.02. So in that case what will see that the actual values\nare very far away from the regression line\nor you can say that there are too\nmany outliers in your data. You cannot focus\nand thing from the data. All right. So this was all about the\ncalculation of our Square now, you might get a question\nlike are low values of Square always bad.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11050.0,
    "t_end": 11080.0,
    "text": "So this was all about the\ncalculation of our Square now, you might get a question\nlike are low values of Square always bad. Well in some field it\nis entirely expected that I ask where value will be low. For example any field that attempts to predict human\nbehavior such as psychology typically has r-squared values\nlower than around 50% through which you can conclude that humans are simply harder to predict the under\nphysical process furthermore. If you ask what value is low, but you have statistically\nsignificant predictors, then you can still\ndraw important conclusion",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11075.0,
    "t_end": 11105.0,
    "text": "to predict the under\nphysical process furthermore. If you ask what value is low, but you have statistically\nsignificant predictors, then you can still\ndraw important conclusion about how changes in the\npredicator values associated. Created with the changes\nin the response value regardless of the r-squared the significant coefficient\nstill represent the mean change in the response for one unit\nof change in the predicator while holding other predicated\nin the model constant. Obviously this type of information can be\nextremely valuable. All right. All right. So this was all about\nthe theoretical concept now, let's move on to the coding part",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11100.0,
    "t_end": 11130.0,
    "text": "of information can be\nextremely valuable. All right. All right. So this was all about\nthe theoretical concept now, let's move on to the coding part and understand the\ncode in depth. So for implementing\nlinear regression using python, I will be using Anaconda with jupyter notebook\ninstalled on it. So I like there's\na jupyter notebook and we are using\npython 3.0 on it. Alright, so we are going\nto use a data set consisting of head size and human brain\nof different people. All right. So let's import our data set\npercent matplotlib and line.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11125.0,
    "t_end": 11155.0,
    "text": "of head size and human brain\nof different people. All right. So let's import our data set\npercent matplotlib and line. We are importing numpy as NP pandas as speedy and\nmatplotlib and from matplotlib. We are importing pipe lot\nof that as PLT. Alright next we will import\nour data had brain dot CSV and store it\nin the database table. Let's execute the Run button\nand see the armor. But so this task\nsymbol it symbolizes that it still executing. So there's a output\nour data set consists",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11150.0,
    "t_end": 11180.0,
    "text": "But so this task\nsymbol it symbolizes that it still executing. So there's a output\nour data set consists of two thirty seven rows\nand 4 columns. We have columns as\ngender age range head size in centimeter Cube and brain weights\nand Graham fine. So there's our sample data set. This is how it looks it consists\nof all these data set. So now that we\nhave imported our data, so as you can see they are\n237 values in the training set so we can find a linear. Relationship between the head\nsize and the Brain weights.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11175.0,
    "t_end": 11205.0,
    "text": "so as you can see they are\n237 values in the training set so we can find a linear. Relationship between the head\nsize and the Brain weights. So now what we'll do\nwe'll collect X & Y the X would consist\nof the head size values and the Y would consist\nof brain with values. So collecting X and Y.\nLet's execute the Run. Done next what we'll do we\nneed to find the values of b 1 or B not or you can say m and C. So we'll need the mean of X\nand Y values first of all what we'll do we'll calculate\nthe mean of X and Y so mean x",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11200.0,
    "t_end": 11230.0,
    "text": "or B not or you can say m and C. So we'll need the mean of X\nand Y values first of all what we'll do we'll calculate\nthe mean of X and Y so mean x equal NP dot Min X. So mean is a predefined function\nof Numb by similarly mean underscore y equal\nNP dot mean of Y, so what it will return if you'll return\nthe mean values of Y next we'll check\nthe total number of values. So m equals. Well length of X. Alright, then we'll use the formula\nto calculate the values of b 1 and B naught or MNC. All right, let's execute\nthe Run button and see",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11225.0,
    "t_end": 11255.0,
    "text": "then we'll use the formula\nto calculate the values of b 1 and B naught or MNC. All right, let's execute\nthe Run button and see what is the result. So as you can see\nhere on the screen, we have got d 1 as 0 point 2 6 3 and be not as three twenty\nfive point five seven. Alright, so now\nthat we have a coefficient. So comparing it with\nthe equation y equal MX plus C. You can say\nthat brain weight equals zero point 2 6 3 X Head size\nplus three twenty five point five seven so you can say",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11250.0,
    "t_end": 11280.0,
    "text": "zero point 2 6 3 X Head size\nplus three twenty five point five seven so you can say that the value of M\nhere is zero point 2 6 3 and the value of C. Here is three twenty\nfive point five seven. All right, so there's\nour linear model now, let's plot it\nand see graphically. Let's execute it. So this is how our plot looks\nlike this model is not so bad. But we need to find out\nhow good our model has. So in order to find\nit the many methods like root mean Square method\nthe coefficient of determination",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11275.0,
    "t_end": 11305.0,
    "text": "But we need to find out\nhow good our model has. So in order to find\nit the many methods like root mean Square method\nthe coefficient of determination or the a square method. So in this tutorial, I have told you\nabout our score method. So let's focus on that and see\nhow good our model is. So let's calculate\nthe R square value. All right here SS underscore T\nis the total sum of square SS. I is the total sum of square\nof residuals and R square as the formula is\n1 minus total sum",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11300.0,
    "t_end": 11330.0,
    "text": "I is the total sum of square\nof residuals and R square as the formula is\n1 minus total sum of squares upon total sum\nof square of the residuals. All right next\nwhen you execute it, you will get the value\nof R square as 0.63 which is pretty very good. Now that you have implemented\nsimple linear regression model using least Square method, let's move on and see how will you implement the model\nusing machine learning library called scikit-learn. All right. So this scikit-learn\nis a simple machine. Owning library in Python welding\nmachine learning model are",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11325.0,
    "t_end": 11355.0,
    "text": "called scikit-learn. All right. So this scikit-learn\nis a simple machine. Owning library in Python welding\nmachine learning model are very easy using scikit-learn. So suppose there's\na python code. So using the scikit-learn\nlibraries your code shortens to this length like so let's execute the Run button and see you\nwill get the same our to score. So today we'll be discussing\nlogistic regression. So let's move forward and understand the what and by\nof logistic regression.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11350.0,
    "t_end": 11380.0,
    "text": "So today we'll be discussing\nlogistic regression. So let's move forward and understand the what and by\nof logistic regression. Now this algorithm\nis most widely used when the dependent variable or you can see the output is\nin the binary format. And so here you need\nto predict the outcome of a categorical\ndependent variable. So the outcome should be\nalways discreet or categorical in nature Now by discrete. I mean the value\nshould be binary or you can say you just have\ntwo values it can either be 0 or 1 you can either be yes or a no either be true\nor false or high or low.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11375.0,
    "t_end": 11405.0,
    "text": "or you can say you just have\ntwo values it can either be 0 or 1 you can either be yes or a no either be true\nor false or high or low. So only these can be\nthe outcomes so the value which you need to protect\nshould be discrete or you can say\ncategorical in nature. Whereas in linear regression. We have the value of by\nor you can say the value. Two predictors in a Range that is how there's a difference\nbetween linear regression and logistic regression. We must be having question. Why not linear regression now\nguys in linear regression the value of buyer or the value which you need\nto predict is in a range,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11400.0,
    "t_end": 11430.0,
    "text": "We must be having question. Why not linear regression now\nguys in linear regression the value of buyer or the value which you need\nto predict is in a range, but in our case as\nin the logistic regression, we just have two values\nit can be either 0 or it can be one. It should not entertain\nthe values which is below zero or above one. But in linear regression, we have the value of y\nin the range so here in order to implement logic regression. We need to clip this This part\nso we don't need the value that is below zero\nor we don't need the value which is above 1 so since the value of y will be\nbetween only 0 and 1",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11425.0,
    "t_end": 11455.0,
    "text": "We need to clip this This part\nso we don't need the value that is below zero\nor we don't need the value which is above 1 so since the value of y will be\nbetween only 0 and 1 that is the main rule\nof logistic regression. The linear line has to be\nclipped at zero and one now. Once we clip this graph it\nwould look somewhat like this. So here you are\ngetting the curve which is nothing but\nthree different straight lines. So here we need to make\na new way to solve this problem. So this has to be\nformulated into equation and hence we come up\nwith logistic regression. So here the outcome\nis either 0 or 1. Which is the main rule\nof logistic regression.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11450.0,
    "t_end": 11480.0,
    "text": "and hence we come up\nwith logistic regression. So here the outcome\nis either 0 or 1. Which is the main rule\nof logistic regression. So with this our resulting curve\ncannot be formulated. So hence our main aim\nto bring the values to 0 and 1 is fulfilled. So that is how we came up with\nlarge stick regression now here once it gets formulated\ninto an equation. It looks somewhat like this. So guys, this is\nnothing but an S curve or you can say the sigmoid curve\na sigmoid function curve. So this sigmoid function\nbasically converts any value from minus infinity to Infinity\npure discrete values,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11475.0,
    "t_end": 11505.0,
    "text": "So this sigmoid function\nbasically converts any value from minus infinity to Infinity\npure discrete values, which a Logitech regression\nwants or you can say the Values which are in binary\nformat either 0 or 1. So if you see here\nthe values and either 0 or 1 and this is nothing\nbut just a transition of it, but guys there's\na catch over here. So let's say I have\na data point that is 0.8. Now, how can you decide whether your value is 0 or 1 now here you\nhave the concept of threshold which basically\ndivides your line.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11500.0,
    "t_end": 11530.0,
    "text": "whether your value is 0 or 1 now here you\nhave the concept of threshold which basically\ndivides your line. So here threshold value basically indicates the\nprobability of either winning or losing so here by winning. I mean the value is equals to 1. Am I losing I mean\nthe values equal to 0 but how does it do that? Let's have a data point\nwhich is over here. Let's say my cursor is at 0.8. So here I check whether this value is less\nthan the threshold value or not. Let's say if it is more\nthan the threshold value. It should give me the result\nas 1 if it is less than that,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11525.0,
    "t_end": 11555.0,
    "text": "whether this value is less\nthan the threshold value or not. Let's say if it is more\nthan the threshold value. It should give me the result\nas 1 if it is less than that, then should give me\nthe result is zero. So here my threshold\nvalue is 0.5. I need to Define that\nif my value let's is 0.8. It is a more than 0.5. Then the value should\nbe rounded of to 1. Let's see if it is\nless than 0.5. Let's I have a value 0.2 then\nshould reduce it to zero. So here you can use the concept of threshold value\nto find output. So here it should be discreet. It should be either 0\nor it should be one.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11550.0,
    "t_end": 11580.0,
    "text": "So here you can use the concept of threshold value\nto find output. So here it should be discreet. It should be either 0\nor it should be one. So I hope you caught this curve\nof logistic regression. So guys, this is\nthe sigmoid S curve. So to make this curve\nwe need to make an equation. So let me address\nthat part as well. So let's see how an equation\nis formed to imitate this functionality so over here, we have an equation\nof a straight line. It is y is equal to MX plus C. So in this case, I just have only one independent\nvariable but let's say if we have many\nindependent variable then",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11575.0,
    "t_end": 11605.0,
    "text": "It is y is equal to MX plus C. So in this case, I just have only one independent\nvariable but let's say if we have many\nindependent variable then the equation becomes m 1 x\n1 plus m 2 x 2 plus m 3 x 3 and so on till M NX n now, let us put in B and X. So here the equation\nbecomes Y is equal to b 1 x 1 plus beta 2 x 2 plus b 3 x 3 and so on\ntill be nxn plus C. So guys the equation of the straight line has a range\nfrom minus infinity to Infinity. But in our case or you can say\nlargest equation the value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11600.0,
    "t_end": 11630.0,
    "text": "of the straight line has a range\nfrom minus infinity to Infinity. But in our case or you can say\nlargest equation the value which we need to predict\nor you can say the Y value it can have the range\nonly from 0 to 1. So in that case we need\nto transform this equation. So to do that what we had done we have just divide\nthe equation by 1 minus y so now Y is equal to 0 so 0 over 1 minus 0\nwhich is equal to 1 so 0 over 1 is again 0 and if you take Y is equals\nto 1 then 1 over 1 minus 1 which is 0",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11625.0,
    "t_end": 11655.0,
    "text": "so 0 over 1 is again 0 and if you take Y is equals\nto 1 then 1 over 1 minus 1 which is 0 so 1 over 0 is infinity. So here my range is now\nbetween You know to Infinity, but again, we want the range\nfrom minus infinity to Infinity. So for that what we'll do we'll have\nthe log of this equation. So let's go ahead\nand have the logarithmic of this equation. So here we have this transform\nit further to get the range between minus infinity\nto Infinity so over here we have log of Y over 1 minus 1 and this is your final\nlogistic regression equation. So guys, don't worry.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11650.0,
    "t_end": 11680.0,
    "text": "here we have log of Y over 1 minus 1 and this is your final\nlogistic regression equation. So guys, don't worry. You don't have to write\nthis formula or memorize this formula in Python. You just need to\ncall this function which is logistic regression and everything will be be\nautomatically for you. So I don't want to scare\nyou with the maths in the formulas behind it, which is always good to know\nhow this formula was generated. So I hope you guys are clear with how logistic regression\ncomes into the picture next. Let us see what are\nthe major differences between linear regression was\na logistic regression the first",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11675.0,
    "t_end": 11705.0,
    "text": "with how logistic regression\ncomes into the picture next. Let us see what are\nthe major differences between linear regression was\na logistic regression the first of all in linear regression, we have the value of y as a continuous variable\nor the variable between need to predict\nare continuous in nature. Whereas in logistic regression. We have the categorical variable\nso here the value which you need to predict\nshould be Creating nature. It should be either 0 or 1 or should have\njust two values to it. For example, whether it is raining\nor it is not raining is it humid outside\nor it is not humid outside. Now, does it going to snow\nand it's not going to snow?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11700.0,
    "t_end": 11730.0,
    "text": "whether it is raining\nor it is not raining is it humid outside\nor it is not humid outside. Now, does it going to snow\nand it's not going to snow? So these are the few example, we need to predict where the values are discrete\nor you can just predict whether this is\nhappening or not. Next linear equation solves\nyour regression problems. So here you have a concept\nof independent variable and the dependent variable. So here you can calculate\nthe value of y which you need to predict\nusing the A of X so here your y variable\nor you can see the value that you need to\npredict are in a range. But whereas in\nlogistic regression you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11725.0,
    "t_end": 11755.0,
    "text": "here your y variable\nor you can see the value that you need to\npredict are in a range. But whereas in\nlogistic regression you have discrete values. So logistic regression basically\nsolves a classification problem so it can basically classify it\nand it can just give you result whether this event\nis happening or not. So I hope it is pretty much Clear till now\nnext in linear equation. The graph that you have seen is a straight line graph\nso over here, you can calculate the value\nof y with respect to the value of x where as in logistic\nregression because of that. The got was a Escobar you\ncan see the sigmoid curve.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11750.0,
    "t_end": 11780.0,
    "text": "you can calculate the value\nof y with respect to the value of x where as in logistic\nregression because of that. The got was a Escobar you\ncan see the sigmoid curve. So using the sigmoid function\nYou can predict your y-values moving the I let\nus see the various use cases where in logistic regression\nis implemented in real life. So the very first is\nweather prediction now largest aggression helps\nyou to predict your weather. For example, it\nis used to predict whether it is raining\nor not whether it is sunny. Is it cloudy or not? So all these things\ncan be predicted using logistic regression.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11775.0,
    "t_end": 11805.0,
    "text": "whether it is raining\nor not whether it is sunny. Is it cloudy or not? So all these things\ncan be predicted using logistic regression. Where as you need\nto keep in mind that both linear regression. And logistic regression can be\nused in predicting the weather. So in that case linear equation\nhelps you to predict what will be\nthe temperature tomorrow whereas logistic regression\nwill only tell you which is going to rain or not\nor whether it's cloudy or not, which is going to snow or not. So these values are discrete. Whereas if you apply\nlinear regression you the predicting things like what\nis the temperature tomorrow or what is the temperature\nday after tomorrow",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11800.0,
    "t_end": 11830.0,
    "text": "Whereas if you apply\nlinear regression you the predicting things like what\nis the temperature tomorrow or what is the temperature\nday after tomorrow and all those thing? So these are\nthe slight differences between linear regression and logistic regression\nthe moving ahead. We have classification problem. Sighs on performs\nmulti-class classification. So here it can help you tell\nwhether it's a bird. It's not a bird. Then you classify\ndifferent kind of mammals. Let's say whether it's a dog\nor it's not a dog similarly. You can check it for reptile whether it's a reptile\nor not a reptile. So in logistic regression, it can perform\nmulti-class classification.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11825.0,
    "t_end": 11855.0,
    "text": "You can check it for reptile whether it's a reptile\nor not a reptile. So in logistic regression, it can perform\nmulti-class classification. So this point\nI've already discussed that it is used\nin classification problems next. It also helps you to determine\nthe illness as well. So let me take an example. Let's say a patient goes for\na routine check up in hospital. So what doctor will do it, it will perform various tests\non the patient and will check whether the patient is\nactually l or not. So what will be the features so doctor can check\nthe sugar level the blood pressure then what\nis the age of the patient?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11850.0,
    "t_end": 11880.0,
    "text": "So what will be the features so doctor can check\nthe sugar level the blood pressure then what\nis the age of the patient? Is it very small or is\nit old person then? What is the previous medical\nhistory of the patient and all of these features\nwill be recorded by the doctor and finally doctor checks\nthe patient data and Data - the outcome of an illness\nand the severity of illness. So using all the data\na doctor can identify with A patient is ill or not. So these are\nthe various use cases in which you can use\nlogistic regression now, I guess enough of theory part.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11875.0,
    "t_end": 11905.0,
    "text": "with A patient is ill or not. So these are\nthe various use cases in which you can use\nlogistic regression now, I guess enough of theory part. So let's move ahead and see some\nof the Practical implementation of logistic regression\nso over here, I be implementing two projects when I have the data set of Titanic so over here\nwill predict what factors made people more likely to survive\nthe sinking of the Titanic ship and my second project\nwill see the data analysis on the SUV cars so over here we\nhave the data of the SUV cars who can purchase it. And what factors made people\nmore interested in buying SUV?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11900.0,
    "t_end": 11930.0,
    "text": "on the SUV cars so over here we\nhave the data of the SUV cars who can purchase it. And what factors made people\nmore interested in buying SUV? So these will be\nthe major questions as to why you should Implement logistic regression and\nwhat output will you get by it? So let's start by\nthe very first project that is Titanic data analysis. So some of you might know that there was a ship\ncalled as Titanic with basically hit an iceberg and it sunk to the bottom\nof the ocean and it was a big disaster at that time because it was the first\nvoyage of the ship and it was supposed to be really\nreally strongly built and one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11925.0,
    "t_end": 11955.0,
    "text": "a big disaster at that time because it was the first\nvoyage of the ship and it was supposed to be really\nreally strongly built and one of the best ships of that time. So it was a big Disaster of that time and of course there\nis a movie about this as well. So many of you\nmight have washed it. So what we have we have data\nof the passengers those who survived and those who did not survive\nin this particular tragedy. So what you have to do you\nhave to look at this data and analyze which factors\nwould have been contributed the most to the chances of a person survival\non the ship or not. So using the logistic\nregression, we can predict",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11950.0,
    "t_end": 11980.0,
    "text": "the most to the chances of a person survival\non the ship or not. So using the logistic\nregression, we can predict whether the person survived or the person died\nnow apart from this. We also have a look\nwith the various features along with that. So first, let us explore\nThe data set so over here. We have the index value\nthen the First Column is passenger ID. Then my next column is survived. So over here, we have two values\na 0 and a 1 so 0 stands for did not survive\nand one stands for survive. So this column is categorical where the values\nare discrete next.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 11975.0,
    "t_end": 12005.0,
    "text": "for did not survive\nand one stands for survive. So this column is categorical where the values\nare discrete next. We have passenger class\nso over here, we have three values 1 2 and 3. So this basically tells you that whether a passengers travelling\nin the first class second class or third class, then we have the name of the We have the six or you can see\nthe gender of the passenger where the passenger\nis a male or female. Then we have the age\nwe had sip SP. So this basically means\nthe number of siblings or the spouses aboard\nthe Titanic so over here,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12000.0,
    "t_end": 12030.0,
    "text": "Then we have the age\nwe had sip SP. So this basically means\nthe number of siblings or the spouses aboard\nthe Titanic so over here, we have values such as 1\n0 and so on then we have Parts apart is basically\nthe number of parents or children aboard\nthe Titanic so over here, we also have some values then we have the ticket number. We have the fair. We have the table number\nand we have the embarked column. So in my inbox column, we have three values\nwe have SC and Q. So as basically stands for Southampton C\nstands for Cherbourg",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12025.0,
    "t_end": 12055.0,
    "text": "we have three values\nwe have SC and Q. So as basically stands for Southampton C\nstands for Cherbourg and Q stands for Cubans down. So these are the features that will be applying\nour model on so here we'll perform various steps and then we'll be implementing\nlogistic regression. So now these are\nthe various steps which are required\nto implement any algorithm. So now in our case\nwe are implementing logistic regression soft. Very first step is\nto collect your data or to import the libraries that are used for\ncollecting your data. And then taking it forward then\nmy second step is to analyze",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12050.0,
    "t_end": 12080.0,
    "text": "Very first step is\nto collect your data or to import the libraries that are used for\ncollecting your data. And then taking it forward then\nmy second step is to analyze your data so over here I can go\nto the various fields and then I can analyze the data. I can check that the females or children survive\nbetter than the males or did the rich\npassenger survived more than the poor passenger\nor did the money matter as in who paid mode to get\ninto the ship with the evacuated first? And what about the workers\ndoes the worker survived or what is the survival rate if you were the worker\nin the ship and not just",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12075.0,
    "t_end": 12105.0,
    "text": "And what about the workers\ndoes the worker survived or what is the survival rate if you were the worker\nin the ship and not just a traveling passenger? So all of these are\nvery very and questions and you would be going\nthrough all of them one by one. So in this stage, you need to analyze our data and explore your data as much\nas you can then my third step is to Wrangle your data now data wrangling basically means\ncleaning your data so over here, you can simply remove\nthe unnecessary items or if you have a null values\nin the data set. You can just clear that data and\nthen you can take it forward.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12100.0,
    "t_end": 12130.0,
    "text": "if you have a null values\nin the data set. You can just clear that data and\nthen you can take it forward. So in this step you\ncan build your model using the train data set and then you can test it using a test so over here you\nwill be performing a split which basically Get\nyour data set into training and testing data set and find\nyou will check the accuracy. So as to ensure how much accurate\nyour values are. So I hope you guys got\nthese five steps that you're going to implement\nin logistic regression. So now let's go into all\nthese steps in detail. So number one. We have to collect your data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12125.0,
    "t_end": 12155.0,
    "text": "that you're going to implement\nin logistic regression. So now let's go into all\nthese steps in detail. So number one. We have to collect your data or you can say\nimport the libraries. So it may show you\nthe implementation part as well. So I just open\nmy jupyter notebook and I just Implement all\nof these steps side by side. So guys this is\nmy jupyter notebook. So first, let me just rename\njupyter notebook to let's say Titanic data analysis. Now a full step was\nto import all the libraries and collect the data. So let me just import\nall the library's first.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12150.0,
    "t_end": 12180.0,
    "text": "Now a full step was\nto import all the libraries and collect the data. So let me just import\nall the library's first. So first of all,\nI'll import pandas. So pandas is used\nfor data analysis. So I'll say import pandas as PD\nthen I will be importing numpy. So I'll say import numpy as NP\nso number is a library in Python which basically stands\nfor numerical Python and it is widely used to perform\nany scientific computation. Next. We will be importing Seaborn. So c 1 is a library for statistical plotting so\nSay import Seaborn as SNS.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12175.0,
    "t_end": 12205.0,
    "text": "and it is widely used to perform\nany scientific computation. Next. We will be importing Seaborn. So c 1 is a library for statistical plotting so\nSay import Seaborn as SNS. I'll also import matplotlib. So matplotlib library\nis again for plotting. So I'll say import\nmatplotlib dot Pi plot as PLT now to run this library\nin jupyter Notebook all I have to write in his percentage\nmatplotlib in line. Next I will be importing\none module as well. So as to calculate the basic\nmathematical functions, so I'll say import maths.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12200.0,
    "t_end": 12230.0,
    "text": "Next I will be importing\none module as well. So as to calculate the basic\nmathematical functions, so I'll say import maths. So these are the libraries that I will be needing\nin this Titanic data analysis. So now let me just\nimport my data set. So I'll take a variable. Let's say Titanic data\nand using the pandas. I will just read my CSV\nor you can see the data set. I like the name of my data set\nthat is Titanic dot CSV. Now. I have already showed you\nthe data set so over here. Let me just bring\nthe top 10 rows. So for that I will just say",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12225.0,
    "t_end": 12255.0,
    "text": "I have already showed you\nthe data set so over here. Let me just bring\nthe top 10 rows. So for that I will just say I take the variable\nTitanic data dot head and I'll say the top ten rules. So now I'll just run this so to run this style is have\nto press shift + enter or else you can just directly\nclick on this cell so over here. I have the index. We have the passenger ID,\nwhich is nothing. But again the index which is starting from 1 then\nwe have the survived column which has a category. Call values or you can say\nthe discrete values, which is in the form of 0 or 1. Then we have\nthe passenger class.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12250.0,
    "t_end": 12280.0,
    "text": "Call values or you can say\nthe discrete values, which is in the form of 0 or 1. Then we have\nthe passenger class. We have the name of\nthe passenger sex age and so on. So this is the data set that I will be going forward with next let us print\nthe number of passengers which are there in this original\ndata frame for that. I'll just simply type in print. I'll say a number of passengers. And using the length function, I can calculate\nthe total length. So I'll say length and inside this I'll be\npassing this variable",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12275.0,
    "t_end": 12305.0,
    "text": "And using the length function, I can calculate\nthe total length. So I'll say length and inside this I'll be\npassing this variable because Titanic data,\nso I'll just copy it from here. I'll just paste it dot index and next set me\njust bring this one. So here the number of passengers which are there in the original data set\nwe have is 891 so around this number would traveling in\nthe Titanic ship so over here, my first step is done where you have just collected\ndata imported all the libraries and find out the total\nnumber of passengers, which are Titanic so\nnow let me just go back",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12300.0,
    "t_end": 12330.0,
    "text": "where you have just collected\ndata imported all the libraries and find out the total\nnumber of passengers, which are Titanic so\nnow let me just go back to presentation and let's see. What is my next step. So we're done with\nthe collecting data. Next step is to analyze\nyour data so over here will be creating different plots\nto check the relationship between variables as in how one variable\nis affecting the other so you can simply explore\nyour data set by making use of various columns and then you can plot\na graph between them. So you can either plot\na correlation graph. You can plot\na distribution curve. It's up to you guys.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12325.0,
    "t_end": 12355.0,
    "text": "and then you can plot\na graph between them. So you can either plot\na correlation graph. You can plot\na distribution curve. It's up to you guys. So let me just go back to my jupyter notebook and let\nme analyze some of the data. Over here. My second part is\nto analyze data. So I just put this in headed\nto now to put this in here to I just have to go\non code click on mark down and I just run this so first let us plot account plot where you can pay\nbetween the passengers who survived and\nwho did not survive. So for that I will be using\nthe Seabourn Library so over here I have imported\nSeaborn as SNS so I don't have\nto write the whole name.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12350.0,
    "t_end": 12380.0,
    "text": "So for that I will be using\nthe Seabourn Library so over here I have imported\nSeaborn as SNS so I don't have\nto write the whole name. I'll simply say\nSNS dot count plot. I say axis with the survive\nand the data that I'll be using\nis the Titanic data or you can say the name\nof variable in which you have store your data set. So now let me just run this so who were here as you can see\nI have survived column on my x axis and on the y axis. I have the count. So zero basically stands\nfor did not survive and one stands\nfor the passengers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12375.0,
    "t_end": 12405.0,
    "text": "axis and on the y axis. I have the count. So zero basically stands\nfor did not survive and one stands\nfor the passengers who did survive so over here, you can see that around 550\nof the passengers who did not survive and they\nwere around 350 passengers who only survive so here\nyou can basically conclude. There are very less survivors\nthan on survivors. So this was the very first plot\nnow there is not another plot to compare the sex as to whether\nout of all the passengers who survived and\nwho did not survive. How many were men and\nhow many were female so to do that?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12400.0,
    "t_end": 12430.0,
    "text": "to compare the sex as to whether\nout of all the passengers who survived and\nwho did not survive. How many were men and\nhow many were female so to do that? I'll simply say\nSNS dot count plot. I add the Hue as six\nso I want to know how many females and\nhow many male survive then I'll be\nspecifying the data. So I'm using Titanic data\nset and let me just run this you have done a mistake over here so over here you can see I have survived\ncolumn on the x-axis and I have the count\non the why now. So have you color stands\nfor your male passengers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12425.0,
    "t_end": 12455.0,
    "text": "can see I have survived\ncolumn on the x-axis and I have the count\non the why now. So have you color stands\nfor your male passengers and orange stands\nfor your female? So as you can see\nhere the passengers who did not survive that has a value\n0 so we can see that. Majority of males did not\nsurvive and if we see the people who survived here, we can see the majority\nof female survive. So this basically concludes\nthe gender of the survival rate. So it appears on average\nwomen were more than three times more likely\nto survive than men next.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12450.0,
    "t_end": 12480.0,
    "text": "So this basically concludes\nthe gender of the survival rate. So it appears on average\nwomen were more than three times more likely\nto survive than men next. Let us plot another plot where we have the Hue as\nthe passenger class so over here we can see which class at\nthe passenger was traveling in whether it was traveling\nin class 1 2 or 3. So for that I just\narrived the same command. I will say as soon as.com plot. I gave my x-axis as a family. I'll change my Hue\nto passenger class. So my variable\nnamed as PE class.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12475.0,
    "t_end": 12505.0,
    "text": "I'll change my Hue\nto passenger class. So my variable\nnamed as PE class. And the data said that I'll be using\nthis Titanic data. So this is my result so over here you can see I have\nblue for first-class orange for second class and green\nfor the third class. So here the passengers who did not survive a majorly\nof the third class or you can say the lowest class or the cheapest class to get\ninto the dynamic and the people who did survive majorly belong\nto the higher classes. So here 1 & 2 has more eyes\nthan the passenger who were traveling\nin the third class.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12500.0,
    "t_end": 12530.0,
    "text": "who did survive majorly belong\nto the higher classes. So here 1 & 2 has more eyes\nthan the passenger who were traveling\nin the third class. So here we have computed\nthat the passengers who did not survive\na majorly of third. Or you can see the lowest class and the passengers\nwho were traveling in first and second class\nwould tend to survive mode next. I just got a graph for\nthe age distribution over here. I can simply use my data. So we'll be using\npandas library for this. I will declare an array\nand I'll pass in the column. That is H. So I plot and I\nwant a histogram.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12525.0,
    "t_end": 12555.0,
    "text": "I will declare an array\nand I'll pass in the column. That is H. So I plot and I\nwant a histogram. So I'll see plot da test. So you can notice over here that we have more\nof young passengers, or you can see the children\nbetween the ages 0 to 10 and then we have\nthe average people and if you go ahead Lester\nwould be the population. So this is the analysis\non the age column. So we saw that we have more young passengers and\nmore video courage passengers which are traveling\nin the Titanic. So next let me plot\na graph of fare as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12550.0,
    "t_end": 12580.0,
    "text": "So we saw that we have more young passengers and\nmore video courage passengers which are traveling\nin the Titanic. So next let me plot\na graph of fare as well. So I'll say Titanic data. I say fair and again, I've got a histogram\nso I'll say hissed. So here you can see\nthe fair size is between zero to hundred now. Let me add the bin size. So as to make it\nmore clear over here, I'll say Ben is equals to let's say 20 and I'll increase\nthe figure size as well. So I'll say fixed size.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12575.0,
    "t_end": 12605.0,
    "text": "I'll say Ben is equals to let's say 20 and I'll increase\nthe figure size as well. So I'll say fixed size. Let's say I'll give\nthe dimensions as 10 by 5. So it is bins. So this is more clear now next. It is analyzed\nthe other columns as well. So I'll just type\nin Titanic data and I want the information as\nto what all columns are left. So here we have passenger ID, which I guess it's\nof no use then we have see how many passengers survived\nand how many did not we also do the analysis\non the gender basis.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12600.0,
    "t_end": 12630.0,
    "text": "which I guess it's\nof no use then we have see how many passengers survived\nand how many did not we also do the analysis\non the gender basis. We saw with a female\ntend to survive more or the maintain to survive more\nthen we saw the passenger class where the passenger is traveling\nin the first class second class or third class. Then we have the name. So in name,\nwe cannot do any analysis. We saw the sex we saw the ages. Well, then we have sea bass P. So this stands for the number\nof siblings or the spouse is which Are aboard the Titanic so\nlet us do this as well. So I'll say SNS dot count plot.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12625.0,
    "t_end": 12655.0,
    "text": "So this stands for the number\nof siblings or the spouse is which Are aboard the Titanic so\nlet us do this as well. So I'll say SNS dot count plot. I mentioned X SC SP. And I will be using\nthe Titanic data so you can see the plot over here so over here\nyou can conclude that. It has the maximum value\non zero so we can conclude that neither children\nnor a spouse was on board the Titanic now\nsecond most highest value is 1 and then we have various values\nfor 2 3 4 and so on next",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12650.0,
    "t_end": 12680.0,
    "text": "on board the Titanic now\nsecond most highest value is 1 and then we have various values\nfor 2 3 4 and so on next if I go above the store\nthis column as well. Similarly can do four parts. So next we have part so you can see the number\nof parents or children which are both the Titanic\nso similarly can do. Israel then we have\nthe ticket number. So I don't think so. Any analysis is\nrequired for Ticket. Then we have fears of a we\nhave already discussed as in the people would tend\nto travel in the first class. You will pay the highest view\nthen we have the cable number and we have embarked.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12675.0,
    "t_end": 12705.0,
    "text": "in the people would tend\nto travel in the first class. You will pay the highest view\nthen we have the cable number and we have embarked. So these are the columns that will be doing\ndata wrangling on so we have analyzed the data and we have seen\nquite a few graphs in which we can conclude which\nvariable is better than another or what is the relationship\nthe whole third step is my data wrangling\nso data wrangling basically means Cleaning your data. So if you have a large data set, you might be having\nsome null values or you can say n values. So it's very important that you remove all\nthe unnecessary items",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12700.0,
    "t_end": 12730.0,
    "text": "you might be having\nsome null values or you can say n values. So it's very important that you remove all\nthe unnecessary items that are present\nin your data set. So removing this directly\naffects your accuracy. So I just go ahead\nand clean my data by removing all the Nan values\nand unnecessary columns, which has a null value\nin the data set the next time you're\nperforming data wrangling. Supposed to fall I'll check whether my dataset\nis null or not. So I'll say Titanic data,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12725.0,
    "t_end": 12755.0,
    "text": "Supposed to fall I'll check whether my dataset\nis null or not. So I'll say Titanic data, which is the name of my data set\nand I'll say is null. So this will basically tell\nme what all values are null and will return me\na Boolean result. So this basically\nchecks the missing data and your result will be\nin Boolean format as in the result will be true\nor false so Falls mean if it is not null\nand true means if it is null, so let me just run this. Over here you can see\nthe values as false or true. So Falls is where the value is\nnot null and true is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12750.0,
    "t_end": 12780.0,
    "text": "Over here you can see\nthe values as false or true. So Falls is where the value is\nnot null and true is where the value is none. So over here you can see\nin the cabin column. We have the very first value which is null so we have to do\nsomething on this so you can see that we have a large data set. So the counting does not stop and we can actually\nsee the some of it. We can actually print\nthe number of passengers who have the Nan value\nin each column. So I say Titanic\nunderscore data is null and I want the sum of it.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12775.0,
    "t_end": 12805.0,
    "text": "who have the Nan value\nin each column. So I say Titanic\nunderscore data is null and I want the sum of it. They've got some so this is\nbasically print the number of passengers who have the n\nn values in each column so we can see that we have missing values\nin each column that is 177. Then we have the maximum value\nin the cave in column and we have very Less\nin the Embark column. That is 2 so here if you don't want\nto see this numbers, you can also plot a heat map and then you can visually\nanalyze it so let me just do that as well. So I'll say SNSD heat map.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12800.0,
    "t_end": 12830.0,
    "text": "you can also plot a heat map and then you can visually\nanalyze it so let me just do that as well. So I'll say SNSD heat map. and say why tick labels\nFalse child has run this as we have already seen that there were three columns in which missing data\nvalue was present. So this might be age so over\nhere almost 20% of each column has a missing value then\nwe have the caping columns. So this is quite a large value and then we have two values\nfor embark column as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12825.0,
    "t_end": 12855.0,
    "text": "has a missing value then\nwe have the caping columns. So this is quite a large value and then we have two values\nfor embark column as well. Add a see map for color coding. So I'll say see map. So if I do this so the graph becomes\nmore attractive so over here yellow stands for Drew or you\ncan say the values are null. So here we have computed that we have the missing value\nof H. We have a lot of missing values\nin the cabin column and we have very less value, which is not even visible\nin the Embark column as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12850.0,
    "t_end": 12880.0,
    "text": "that we have the missing value\nof H. We have a lot of missing values\nin the cabin column and we have very less value, which is not even visible\nin the Embark column as well. So to remove\nthese missing values, you can either replace\nthe values and you can put in some dummy values to it or you\ncan simply drop the column. So here let us suppose\npick the age column. So first, let me\njust plot a box plot and they will analyze\nwith having a column as age so I'll say SNS dot box plot. I'll say x is equals\nto passenger class. So it's PE class.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12875.0,
    "t_end": 12905.0,
    "text": "so I'll say SNS dot box plot. I'll say x is equals\nto passenger class. So it's PE class. I'll say Y is equal\nto H and the data set that I'll be using\nis Titanic side. So I'll say the data\nis goes to Titanic data. You can see the edge in first class and second class\ntends to be more older rather than we have it\nin the third place. Well that depends\nOn the experience how much you earn on might be\nthere any number of reasons? So here we concluded that passengers who were traveling in class\none and class two a tend to be older than what we have\nin the class 3 so we have found",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12900.0,
    "t_end": 12930.0,
    "text": "So here we concluded that passengers who were traveling in class\none and class two a tend to be older than what we have\nin the class 3 so we have found that we have some\nmissing values in EM. Now one way is to either just\ndrop the column or you can just simply fill\nin some values to them. So this method is called\nas imputation now to perform data wrangling or cleaning it is for spring\nthe head of the data set. So I'll say Titanic not head\nso it's Titanic. For data, let's say I\njust want the five rows. So here we have survived\nwhich is again categorical.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12925.0,
    "t_end": 12955.0,
    "text": "So I'll say Titanic not head\nso it's Titanic. For data, let's say I\njust want the five rows. So here we have survived\nwhich is again categorical. So in this particular column, I can apply\nlogic to progression. So this can be my y value\nor the value that you need to predict. Then we have\nthe passenger class. We have the name then we\nhave ticket number Fair given so over here. We have seen that in keeping. We have a lot of null values\nor you can say that any invalid which is quite visible as well. So first of all, we'll just drop this column\nfor dropping it. I'll just say\nTitanic underscore data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12950.0,
    "t_end": 12980.0,
    "text": "So first of all, we'll just drop this column\nfor dropping it. I'll just say\nTitanic underscore data. And I'll simply type\nin drop and the column which I need to drop so I\nhave to drop the cable column. I mention the access equals\nto 1 and I'll say in place also to true. So now again, I just print the head\nand a to see whether this column has been removed\nfrom the data set or not. So I'll say Titanic dot head. So as you can see here, we don't have\ngiven column anymore. Now, you can also\ndrop the na values.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 12975.0,
    "t_end": 13005.0,
    "text": "So as you can see here, we don't have\ngiven column anymore. Now, you can also\ndrop the na values. So I'll say Titanic data\ndot drop all the any values or you can say Nan which is not a number and I will\nsay in place is equal to True. Let's Titanic. So over here, let me again plot the heat map\nand let's say what the values which will be for showing\na lot of null values. Has it been removed or not. So I'll say SNSD heat map. I'll pass in the data set. I'll check it is null I say why\ndick labels is equal to false.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13000.0,
    "t_end": 13030.0,
    "text": "Has it been removed or not. So I'll say SNSD heat map. I'll pass in the data set. I'll check it is null I say why\ndick labels is equal to false. And I don't want color coding. So again I say false. So this will basically\nhelp me to check whether my values\nhas been removed from the data set or not. So as you can see here,\nI don't have any null values. So it's entirely black now. You can actually know\nthe some as well. So I'll just go above So\nI'll just copy this part",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13025.0,
    "t_end": 13055.0,
    "text": "You can actually know\nthe some as well. So I'll just go above So\nI'll just copy this part and I just use the sum function\nto calculate the sum. So here the tells me that data set is green as\nin the data set does not contain any null value or any n value. So now we have R Angela data. You can see cleaner data. So here we have done just\none step in data wrangling that is just removing\none column out of it. Now you can do a lot\nof things you can actually fill in the values\nwith some other values or you can just\ncalculate the mean",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13050.0,
    "t_end": 13080.0,
    "text": "Now you can do a lot\nof things you can actually fill in the values\nwith some other values or you can just\ncalculate the mean and then you can just fit\nin the null values. But now if I see my data set, so I'll say\nTitanic data dot head. But now if I see you over here I\nhave a lot of string values. So this has to be converted\nto a categorical variables in order to implement\nlogistic regression. So what we will do\nwe will convert this to categorical variable into some dummy variables and\nthis can be done using pandas because logistic regression\njust take two values.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13075.0,
    "t_end": 13105.0,
    "text": "into some dummy variables and\nthis can be done using pandas because logistic regression\njust take two values. So whenever you apply machine\nlearning you need to make sure that there are\nno string values present because it won't be taking\nthese as your input variables. So using string you don't have\nto predict anything but in my case I have the survived\ncolumns 2210 how many? People tend to survive and how men did not so 0 stands\nfor did not survive and one stands for survive. So now let me just\nconvert these variables into dummy variables. So I'll just use pandas\nand I say PD not get dummies.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13100.0,
    "t_end": 13130.0,
    "text": "So now let me just\nconvert these variables into dummy variables. So I'll just use pandas\nand I say PD not get dummies. You can simply press\ntab to autocomplete and say Titanic data\nand I'll pass the sex so you can just simply click\non shift + tab to get more information on this. So here we have\nthe type data frame and we have the passenger ID\nsurvived and passenger class. So if Run this you'll see that 0 basically stands\nfor not a female and once and for it is a female similarly for\nmale zero Stanford's not made",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13125.0,
    "t_end": 13155.0,
    "text": "So if Run this you'll see that 0 basically stands\nfor not a female and once and for it is a female similarly for\nmale zero Stanford's not made and one Stanford main now, we don't require\nboth these columns because one column\nitself is enough to tell us whether it's male\nor you can say female or not. So let's say if I want\nto keep only mail I will say if the value of mail is 1 so it is definitely a maid\nand is not a female. So that is how you don't need\nboth of these values. So for that I just\nremove the First Column, let's say a female so\nI'll say drop first.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13150.0,
    "t_end": 13180.0,
    "text": "So that is how you don't need\nboth of these values. So for that I just\nremove the First Column, let's say a female so\nI'll say drop first. Andrew it has given\nme just one column which is male and has\na value 0 and 1. Let me just set this as\na variable hsx so over here I can say sex dot head. I'll just want to see\nthe first pie Bros. Sorry, it's Dot. So this is how my data\nlooks like now here. We have done it for sex. Then we have\nthe numerical values in age.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13175.0,
    "t_end": 13205.0,
    "text": "So this is how my data\nlooks like now here. We have done it for sex. Then we have\nthe numerical values in age. We have the numerical\nvalues in spouses. Then we have the ticket number. We have the pair and we\nhave embarked as well. So in Embark,\nthe values are in SC and Q. So here also we can apply\nthis get dummy function. So let's say I\nwill take a variable. Let's say Embark. I'll use the pandas Library. I need the column name\nthat is embarked.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13200.0,
    "t_end": 13230.0,
    "text": "I need the column name\nthat is embarked. Let me just print\nthe head of it. So I'll say Embark\ndot head so over here. We have c q and s now here also\nwe can drop the First Column because these two\nvalues are enough with the passenger\nis either traveling for Q that is toonstone S4 sound time and if both the values\nare 0 then definitely the passenger is from Cherbourg. That is the third value so you can again drop the first\nvalue so I'll say drop.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13225.0,
    "t_end": 13255.0,
    "text": "the passenger is from Cherbourg. That is the third value so you can again drop the first\nvalue so I'll say drop. Let me just run this so this is how my output looks\nlike now similarly. You can do it for\npassenger class as well. So here also we have\nthree classes one two, and three so I'll just\ncopy the whole statement. So let's say I want\nthe variable name. Let's say PCL. I'll pass in the column name that is PE class and I'll just\ndrop the First Column.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13250.0,
    "t_end": 13280.0,
    "text": "I'll pass in the column name that is PE class and I'll just\ndrop the First Column. So here also the values\nwill be 1 2 or 3 and I'll just remove\nthe First Column. So here we just left\nwith two and three so if both the values are 0 then\ndefinitely the passengers traveling the first class now, we have made the values\nas categorical now, my next step would be\nto concatenate all these new rows into a data set. We can see Titanic data using\nthe pandas will just concatenate all these columns. So I'll say p Dot.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13275.0,
    "t_end": 13305.0,
    "text": "We can see Titanic data using\nthe pandas will just concatenate all these columns. So I'll say p Dot. One cat and then say\nwe have to concatenate sex. We have to concatenate\nEmbark and PCL and then I will mention\nthe access to one. I'll just run this can you to print the head so\nover here you can see that these columns\nhave been added over here. So we have the mail column\nwith basically tells where the person is male or it's a female then\nwe have the Embark which is basically q",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13300.0,
    "t_end": 13330.0,
    "text": "So we have the mail column\nwith basically tells where the person is male or it's a female then\nwe have the Embark which is basically q and s so if it's traveling from Queenstown value\nwould be one else it would be 0 and If both\nof these values are zeroed, it is definitely\ntraveling from Cherbourg. Then we have the passenger\nclass as 2 and 3. So the value of both these is 0 then passengers\ntravelling in class one. So I hope you got this\ntill now now these are the irrelevant columns that we have done over here so we can just drop\nthese columns will drop in PE class the embarked column\nand the sex column.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13325.0,
    "t_end": 13355.0,
    "text": "the irrelevant columns that we have done over here so we can just drop\nthese columns will drop in PE class the embarked column\nand the sex column. So I'll just type in Titanic data dot drop\nand mention the columns that I want to drop. So I say And even lead\nthe passenger ID because it's nothing\nbut just the index value which is starting from one. So I'll drop this as well then\nI don't want name as well. So I'll delete name as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13350.0,
    "t_end": 13380.0,
    "text": "which is starting from one. So I'll drop this as well then\nI don't want name as well. So I'll delete name as well. Then what else we can drop we\ncan drop the ticket as well. And then I'll just\nmention the axis L say in place is equal to True. Okay, so the my column\nname starts uppercase. So these has been dropped now, let me just bring\nmy data set again. So this is\nmy final leadership guys. We have the survived column which has the value zero and one\nthen we have the passenger class",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13375.0,
    "t_end": 13405.0,
    "text": "So this is\nmy final leadership guys. We have the survived column which has the value zero and one\nthen we have the passenger class or we forgot to drop\nthis as well. So no worries. I'll drop this again. So now let me just run this. So over here we\nhave the survive. We have the H we\nhave the same SP. We have the parts. We have Fair mail and these\nwe have just converted. So here we have just\nperformed data angling for you can see clean the data and then we have just\nconverted the values of gender",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13400.0,
    "t_end": 13430.0,
    "text": "We have Fair mail and these\nwe have just converted. So here we have just\nperformed data angling for you can see clean the data and then we have just\nconverted the values of gender to male then embarked to qns and the passenger Class 2 2 & 3. So this was all\nabout my data wrangling or just cleaning the data then\nmy next up is training and testing your data. So here we will split\nthe data set into train subset and test steps. And then what we'll do\nwe'll build a model on the train data and then predict the output\non your test data set. So let me just go\nback to Jupiter and it is implement\nthis as well over here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13425.0,
    "t_end": 13455.0,
    "text": "and then predict the output\non your test data set. So let me just go\nback to Jupiter and it is implement\nthis as well over here. I need to train my data set. So I'll just put this\nindeed heading 3. So over you need to Define\nyour dependent variable and independent variable. So here my Y is the output\nfor you can say the value that I need to predict\nso over here, I will write Titanic data. I'll take the column\nwhich is survive. So basically I have\nto predict this column whether the passenger\nsurvived or not.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13450.0,
    "t_end": 13480.0,
    "text": "I'll take the column\nwhich is survive. So basically I have\nto predict this column whether the passenger\nsurvived or not. And as you can see we have\nthe discrete outcome, which is in the form of 0\nand 1 and rest all the things we can take it as a features or you\ncan say independent variable. So I'll say Titanic data. Not a drop, so we just simply\ndrop the survive and all the other columns\nwill be my independent variable. So everything else are\nthe features which leads to the survival rate. So once we have defined\nthe independent variable",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13475.0,
    "t_end": 13505.0,
    "text": "So everything else are\nthe features which leads to the survival rate. So once we have defined\nthe independent variable and the dependent variable\nnext step is to split your data into training\nand testing subset. So for that we will\nbe using SK loan. I just type in from sklearn\ndot cross validation. import train display Now here if you just click\non shift and tab, you can go to the documentation and you can just see\nthe examples over here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13500.0,
    "t_end": 13530.0,
    "text": "if you just click\non shift and tab, you can go to the documentation and you can just see\nthe examples over here. And she can blast open it and then I just go\nto examples and see how you can split your data. So over here you have\nextra next test why drain why test and then using\nthe string test platelet and just passing your independent variable\nand dependent variable and just Define a size\nand a random straight to it. So, let me just copy this\nand I'll just paste over here. Over here, we'll train test. Then we have the dependent\nvariable train and test",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13525.0,
    "t_end": 13555.0,
    "text": "So, let me just copy this\nand I'll just paste over here. Over here, we'll train test. Then we have the dependent\nvariable train and test and using the split function\nwill pass in the independent and dependent variable\nand then we'll set a split size. So let's say I'll put it up 0.3. So this basically means that your data set\nis divided in 0.3 that is in 70/30 ratio. And then I can add\nany random straight to it. So let's say I'm applying\none this is not necessary. If you want the same result\nas that of mine, you can add the random stream. So this would basically\ntake exactly the same sample",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13550.0,
    "t_end": 13580.0,
    "text": "So let's say I'm applying\none this is not necessary. If you want the same result\nas that of mine, you can add the random stream. So this would basically\ntake exactly the same sample every Next I have to train\nand predict by creating a model. So here logistic\nregression will graph from the linear regression. So next I'll just type in from SK loan dot linear model\nimport logistic regression. Next I'll just create the instance of this\nlogistic regression model. So I'll say log model is equals\nto largest aggression now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13575.0,
    "t_end": 13605.0,
    "text": "the instance of this\nlogistic regression model. So I'll say log model is equals\nto largest aggression now. I just need to fit my model. So I'll say log model dot fit and I'll just pass\nin my ex train. And why it rain? It gives me all the details\nof logistic regression. So here it gives me the class\nmade dual fit intercept and all those things then\nwhat I need to do, I need to make prediction. So I will take a variable\ninsect addictions and I'll pass",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13600.0,
    "t_end": 13630.0,
    "text": "and all those things then\nwhat I need to do, I need to make prediction. So I will take a variable\ninsect addictions and I'll pass on the model to it. So I'll say\nlog model dot protect and I'll pass in the value\nthat is X test. So here we have just\ncreated a model fit that model and then we\nhad made predictions. So now to evaluate how my model\nhas been performing. So you can simply\ncalculate the accuracy or you can also calculate\na classification report. So don't worry guys. I'll be showing both\nof these methods. So I'll say from sklearn dot matrix\ninput classification report.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13625.0,
    "t_end": 13655.0,
    "text": "So don't worry guys. I'll be showing both\nof these methods. So I'll say from sklearn dot matrix\ninput classification report. Are you start fishing report? And inside this I'll be passing\nin why test and the predictions? So guys this is\nmy classification report. So over here,\nI have the Precision. I have the recall. We have the advanced code\nand then we have support. So here we have the value\nof decision as 75 72 and 73,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13650.0,
    "t_end": 13680.0,
    "text": "We have the advanced code\nand then we have support. So here we have the value\nof decision as 75 72 and 73, which is not that bad now in order to calculate\nthe accuracy as well. You can also use the concept\nof confusion Matrix. So if you want to print\nthe confusion Matrix, I will simply say from sklearn dot matrix import\nconfusion Matrix first of all, and then we'll just\nprint this So how am I function\nhas been imported successfully so is a confusion Matrix. And I'll again passing\nthe same variables",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13675.0,
    "t_end": 13705.0,
    "text": "how am I function\nhas been imported successfully so is a confusion Matrix. And I'll again passing\nthe same variables which is why\ntest and predictions. So I hope you guys already know\nthe concept of confusion Matrix. So can you guys give me\na quick confirmation as to whether you guys remember this confusion\nMatrix concept or not? So if not, I can just quickly\nsummarize this as well. Okay charged with you say so yes. Okay. So what is not clear with this? So I'll just tell\nyou in a brief what confusion Matrix is all about?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13700.0,
    "t_end": 13730.0,
    "text": "So what is not clear with this? So I'll just tell\nyou in a brief what confusion Matrix is all about? So confusion Matrix is nothing\nbut a 2 by 2 Matrix which has a four outcomes\nthis basic tells us that how accurate\nyour values are. So here we have\nthe column as predicted. No predicted Y and we\nhave actual know an actual. Yes. So this is the concept\nof confusion Matrix. So here let me just fade\nin these values which we have just calculated. So here we have 105.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13725.0,
    "t_end": 13755.0,
    "text": "So here let me just fade\nin these values which we have just calculated. So here we have 105. 105 2125 and 63 So\nas you can see here, we have got four outcomes now 105 is the value\nwhere a model has predicted. No, and in reality. It was also a no so where we have predicted know\nan actual know similarly. We have 63 as a predicted. Yes. So here the model predicted. Yes, and actually\nalso it was yes. So in order to\ncalculate the accuracy,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13750.0,
    "t_end": 13780.0,
    "text": "We have 63 as a predicted. Yes. So here the model predicted. Yes, and actually\nalso it was yes. So in order to\ncalculate the accuracy, you just need to add the sum of these two values and divide\nthe whole by the some. So here these two values\ntells me where the order has. We predicted the correct output. So this value is also\ncalled as true- This is called\nas false positive. This is called as true positive and this is called\nas false negative. Now in order to\ncalculate the accuracy. You don't have\nto do it manually. So in Python, you can just import\naccuracy score function",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13775.0,
    "t_end": 13805.0,
    "text": "Now in order to\ncalculate the accuracy. You don't have\nto do it manually. So in Python, you can just import\naccuracy score function and you can get\nthe results from that. So I'll just do that as well. So I'll say from sklearn\ndot-matrix import accuracy score and I'll simply\nprint the accuracy. I'm passing the same variables. That is why I test\nand predictions so over here. It tells me the accuracy as 78\nwhich is quite good so over here if you want to do it manually we\nhave 2 plus these two numbers, which is 105 263.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13800.0,
    "t_end": 13830.0,
    "text": "It tells me the accuracy as 78\nwhich is quite good so over here if you want to do it manually we\nhave 2 plus these two numbers, which is 105 263. So this comes out to almost 168\nand then you have to divide by the sum of all\nthe phone numbers. So 105 plus 63 plus 21 plus 25, so this gives me\na result of to 1/4. So now if you divide these two number you'll get\nthe same accuracy that is 98% or you can say .78. So that is how you\ncan calculate the accuracy. So now let me just go back\nto my presentation and let's see",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13825.0,
    "t_end": 13855.0,
    "text": "So that is how you\ncan calculate the accuracy. So now let me just go back\nto my presentation and let's see what all we have\ncovered till now. So here we have First Data data\ninto train and test subset then we have build a model\non the train data and then predicted the output\non the test data set and then my fifth step\nis to check the accuracy. So here we have calculator accuracy to almost\nseventy eight percent, which is quite good. You cannot say\nthat accuracy is bad. So here tells me\nhow accurate your results. So him accuracy skoda finds that enhanced got\na good accuracy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13850.0,
    "t_end": 13880.0,
    "text": "So here tells me\nhow accurate your results. So him accuracy skoda finds that enhanced got\na good accuracy. So now moving ahead. Let us see the second project\nthat is SUV data analysis. So in this a car company has\nreleased new SUV in the market and using the previous data\nabout the sales of their SUV. They want to predict\nthe category of people who might be interested\nin buying this. So using the\nlogistic regression, you need to find what factors\nmade people more interested in buying this SUV. So for this let us hear data set\nwhere I have user ID I have",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13875.0,
    "t_end": 13905.0,
    "text": "you need to find what factors\nmade people more interested in buying this SUV. So for this let us hear data set\nwhere I have user ID I have Of gender as male\nand female then we have the age. We have the estimated salary and then we have\nthe purchased column. So this is my discreet column or you can see\nthe categorical column. So here we just have the value that is 0 and 1 and this column\nwe need to predict whether a person can actually\npurchase a SUV or Not. So based on these factors,\nwe will be deciding whether a person can\nactually purchase SUV or not.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13900.0,
    "t_end": 13930.0,
    "text": "whether a person can actually\npurchase a SUV or Not. So based on these factors,\nwe will be deciding whether a person can\nactually purchase SUV or not. So we know the salary\nof a person we know the age and using these we can predict whether person can\nactually purchase SUV on Let me just go to my jupyter. Notebook and has implemented\na logistic regression. So guys, I will not be going\nthrough all the details of data cleaning and analyzing\nthe part start part. I'll just leave it on you. So just go ahead\nand practice as much as you can. Alright, so the second project\nis SUV predictions.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13925.0,
    "t_end": 13955.0,
    "text": "Alright, so the second project\nis SUV predictions. Alright, so first of all, I have to import\nall the libraries so I say import numpy\nSNP and similarly. I'll do the rest of it. Alright, so now let\nme just bring the head of this data set. So this give already seen\nthat we have columns as user ID. We have gender. We have the age. We have the salary\nand then we have to calculate",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13950.0,
    "t_end": 13980.0,
    "text": "So this give already seen\nthat we have columns as user ID. We have gender. We have the age. We have the salary\nand then we have to calculate whether person can actually\npurchase a SUV or not. So now let us just simply go on\nto the algorithm part. So we'll directly start off\nwith the logistic regression how you can train a model so\nfor doing all those things we first need to Define\nan independent variable and a dependent variable. So in this case, I want my ex at is\nan independent variable is a data set. I lock so here I will specify\nsighing all the rows. So cool and basically stands\nfor that and in the columns,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 13975.0,
    "t_end": 14005.0,
    "text": "I want my ex at is\nan independent variable is a data set. I lock so here I will specify\nsighing all the rows. So cool and basically stands\nfor that and in the columns, I want only two and\nthree dot values. So here we should fetch\nme all the rows and only the second\nand third column which is age and estimated salary. So these are the factors which will be used to predict\nthe dependent variable that is purchase. So here my dependent\nvariable is purchase any dependent variable is\nof age and salary. So I'll say later said dot I log I'll have all the rows\nand add just one for column.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14000.0,
    "t_end": 14030.0,
    "text": "any dependent variable is\nof age and salary. So I'll say later said dot I log I'll have all the rows\nand add just one for column. That is my position. Is column values. All right, so I just forgot when one square\nbracket over here. Alright so over here. I have defined my independent\nvariable and dependent variable. So here my independent variable\nis age and salary and dependent variable\nis the column purchase. Now, you must be wondering\nwhat is this? I lock function. So I look function is basically\nan index of a panda's data frame",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14025.0,
    "t_end": 14055.0,
    "text": "Now, you must be wondering\nwhat is this? I lock function. So I look function is basically\nan index of a panda's data frame and it is used\nfor integer based indexing or you can also say\nselection by index now, let me just bring\nthese independent variables and dependent variable. So if I bring the independent\nvariable I have aged as well as a salary next. Let me print the dependent\nvariable as well. So over here you can see I\njust have the values in 0 and 1 so 0 stands\nfor did not purchase next. Let me just divide my data set\ninto training and test subset.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14050.0,
    "t_end": 14080.0,
    "text": "and 1 so 0 stands\nfor did not purchase next. Let me just divide my data set\ninto training and test subset. So I'll simply write in from SK loaned cross plate\ndot cross validation. import rain test next I\njust press shift and tab and over here. I will go to the examples\nand just copy the same line. So I'll just copy this. I'll move the points now. I want to text size\nto be let's see 25, so I have divided the trained\nand tested in 75/25 ratio.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14075.0,
    "t_end": 14105.0,
    "text": "I'll move the points now. I want to text size\nto be let's see 25, so I have divided the trained\nand tested in 75/25 ratio. Now, let's say I'll take\nthe random set of 0 So Random State basically\nensures the same result or you can say the same samples\ntaken whenever you run the code. So let me just run this now. You can also scale\nyour input values for better performing and this can be done\nusing standard scale. Oh, so let me do that as well. So I'll say\nfrom sklearn pre-processing. Import standard scalar now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14100.0,
    "t_end": 14130.0,
    "text": "So I'll say\nfrom sklearn pre-processing. Import standard scalar now. Why do we scale it now? If you see a data set we\nare dealing with large numbers. Well, although we are using\na very small data set. So whenever you're working\nin a prod environment, you'll be working\nwith large data set we will be using thousands and hundred thousands of do\npeople's so they're scaling down will definitely\naffect the performance by a large extent. So here let me just show you how you can scale down\nthese input values and then the pre-processing contains all\nyour methods & functionality,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14125.0,
    "t_end": 14155.0,
    "text": "So here let me just show you how you can scale down\nthese input values and then the pre-processing contains all\nyour methods & functionality, which is required\nto transform your data. So now let us scale down for tests as well as\ntheir training data set. So else First Make\nan instance of it. So I'll say standard scalar then I'll have Xtreme sasc dot\nfit fit underscore transform. I'll pass in my Xtreme variable.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14150.0,
    "t_end": 14180.0,
    "text": "I'll pass in my Xtreme variable. And similarly I can do\nit for test wherein I'll pass the X test. All right. Now my next step is\nto import logistic regression. So I'll simply apply\nlogistically creation by first importing it so I'll say from sklearn sklearn the linear model import\nlogistic regression over here. I'll be using classifier. So is a classifier DOT is equals to largest aggression\nso over here,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14175.0,
    "t_end": 14205.0,
    "text": "the linear model import\nlogistic regression over here. I'll be using classifier. So is a classifier DOT is equals to largest aggression\nso over here, I just make an instance of it. So I'll say logistic\nregression and over here. I just pass in the random state, which is 0 No,\nI simply fit the model. And I simply pass in\nX train and white rain. So here it tells\nme all the details of logistic regression. Then I have to\npredict the value. So I'll say why I prayed\nit's equals to classifier.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14200.0,
    "t_end": 14230.0,
    "text": "of logistic regression. Then I have to\npredict the value. So I'll say why I prayed\nit's equals to classifier. Then predict function\nand then I just pass in X test. So now we have\ncreated the model. We have scale down\nour input values. Then we have applied\nlogistic regression. We have predicted the values and now we want\nto know the accuracy. So now the accuracy first we\nneed to import accuracy scores. So I'll say from\nsklearn dot-matrix import actually see school",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14225.0,
    "t_end": 14255.0,
    "text": "So now the accuracy first we\nneed to import accuracy scores. So I'll say from\nsklearn dot-matrix import actually see school and using this function we\ncan calculate the accuracy or you can manually do that by creating\na confusion Matrix. So I'll just pass. my lightest and my y\npredicted All right. So over here I get\nthe accuracy is 89% So we want to know\nthe accuracy in percentage. So I just have to multiply it\nby a hundred and if I run this so it gives me 89% So I hope you guys are clear with whatever I\nhave taught you today.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14250.0,
    "t_end": 14280.0,
    "text": "So I just have to multiply it\nby a hundred and if I run this so it gives me 89% So I hope you guys are clear with whatever I\nhave taught you today. So here I have taken\nmy independent variables as age and salary and then\nwe have calculated that how many people\ncan purchase the SUV and then we have calculated\nour model by checking the accuracy so over here\nwe get the accuracy is 89 which is great. Alright guys that is\nit for today. So I'll Discuss what we have covered\nin today's training. First of all, we had a quick introduction\nto what is regression and where their aggression\nis actually use then we have understood\nthe types of regression",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14275.0,
    "t_end": 14305.0,
    "text": "we had a quick introduction\nto what is regression and where their aggression\nis actually use then we have understood\nthe types of regression and then got into the details of what and why\nof logistic regression of compared linear was\nin logistic regression. If you've also seen\nthe various use cases where you can Implement\nlogistic regression in real life and then we have picked\nup two projects that is Titanic data analysis and SUV prediction so\nover here we have seen how you can collect your data\nanalyze your data then perform. Modeling on that date\nthat train the data test the data and then finally\nhave calculated the accuracy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14300.0,
    "t_end": 14330.0,
    "text": "how you can collect your data\nanalyze your data then perform. Modeling on that date\nthat train the data test the data and then finally\nhave calculated the accuracy. So in your SUV prediction, you can actually\nanalyze clean your data and you can do a lot of things so you can just go ahead\npick up any data set and explore it as\nmuch as you can. What is classification. I hope every one of you\nmust have used Gmail. So how do you think the male\nis getting classified as a Spam",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14325.0,
    "t_end": 14355.0,
    "text": "I hope every one of you\nmust have used Gmail. So how do you think the male\nis getting classified as a Spam or not spam mail? Well, there's But\nclassification So What It Is Well\nclassification is the process of dividing the data set\ninto different categories or groups by adding label. In other way, you can say\nthat it is a technique of categorizing the observation\ninto different category. So basically what you\nare doing is you are taking the data analyzing it and on the basis\nof some condition you finely divided\ninto various categories. Now, why do we classify it?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14350.0,
    "t_end": 14380.0,
    "text": "the data analyzing it and on the basis\nof some condition you finely divided\ninto various categories. Now, why do we classify it? Well, we classify it\nto perform predictive analysis on it like when you get the mail the machine\npredicts it Be a Spam or not spam mail and on the basis\nof that prediction it add the irrelevant or spam mail to the respective folder\nin general this classification. Algorithm handled questions. Like is this data belongs\nto a category or B category? Like is this a male or is this\na female something like that?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14375.0,
    "t_end": 14405.0,
    "text": "Like is this data belongs\nto a category or B category? Like is this a male or is this\na female something like that? I getting it? Okay fine. Now the question arises\nwhere will you use it? Well, you can use this\nof protection order to check whether the transaction\nis genuine or not suppose. I am using a credit. Here in India now due to some reason I had\nto fly to Dubai now. If I'm using the credit\ncard over there, I will get a notification alert\nregarding my transaction. They would ask me to confirm\nabout the transaction.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14400.0,
    "t_end": 14430.0,
    "text": "I will get a notification alert\nregarding my transaction. They would ask me to confirm\nabout the transaction. So this is also kind\nof predictive analysis as the machine predicts that something fishy is in the transaction\nas very for our ago. I made the transaction using\nthe same credit card and India and 24 hour later. The same credit card is being\nused for the payment in Dubai. So the machine texts that\nsomething fishy is going on in the transaction. So in order to confirm it it\nsends you a notification alert. All right. Well, this is one of\nthe use case of classification",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14425.0,
    "t_end": 14455.0,
    "text": "in the transaction. So in order to confirm it it\nsends you a notification alert. All right. Well, this is one of\nthe use case of classification you can even use it\nto classify different items like fruits on the base\nof its taste color size or weight a machine\nwell trained using the classification algorithm\ncan easily predict the class or the type of fruit whenever\nnew data is given to it. Not just the fruit. It can be any item. It can be a car. It can be a house. It can be a signboard. Or anything. Have you noticed that while you visit some sites",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14450.0,
    "t_end": 14480.0,
    "text": "It can be a house. It can be a signboard. Or anything. Have you noticed that while you visit some sites or you try to login\ninto some you get a picture capture for that right where you have to identify whether the given image is of\na car or its of a pole or not? You have to select it\nfor example that 10 images and you're selecting\nthree Mages out of it. So in a way you are\ntraining the machine, right you're telling that these three are\nthe picture of a car and rest are not so who knows you are training\nat for something big right? So moving on ahead.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14475.0,
    "t_end": 14505.0,
    "text": "and rest are not so who knows you are training\nat for something big right? So moving on ahead. Let's discuss the types\nof education online. Well, there are\nseveral different ways to perform the same tasks\nlike in order to predict whether a given person is a male or a female the machine\nhad to be trained first. All right, but there are multiple ways\nto train the machine and you can choose any one of them just\nfor Predictive Analytics. There are many\ndifferent techniques, but the most common of them\nall is the decision tree, which we'll cover in depth\nin today's session.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14500.0,
    "t_end": 14530.0,
    "text": "There are many\ndifferent techniques, but the most common of them\nall is the decision tree, which we'll cover in depth\nin today's session. So it's a part\nof classification algorithm. We have decision tree\nrandom Forest name buys. K-nearest neighbor Lodge is Regression linear regression\nsupport Vector machines and so on there are many. Alright, so let me give\nyou an idea about few of them starting\nwith decision tree. Well decision tree is\na graphical representation of all the possible solution to a decision the decisions which are made they\ncan be explained very easily. For example here is a task,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14525.0,
    "t_end": 14555.0,
    "text": "to a decision the decisions which are made they\ncan be explained very easily. For example here is a task, which says that should I go\nto a restaurant or should I buy a hamburger\nyou are confused on that. So for the artboard you\nwill do you will create a dish entry for it starting with the root node\nwill be first of all, you will check\nwhether you are hungry or not. All right, if you're not hungry then\njust go back to sleep. Right? If you are hungry and you have $25 then you\nwill decide to go to restaurant and if you're hungry\nand you don't have $25,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14550.0,
    "t_end": 14580.0,
    "text": "and you have $25 then you\nwill decide to go to restaurant and if you're hungry\nand you don't have $25, then you will just\ngo and buy a hamburger. That's it. All right. So there's about decision tree\nnow moving on ahead. Let's see. What is a random Forest. Well random Forest build\nmultiple decision trees and merges them together\nto get a more accurate and stable production. All right, most of the time\nrandom Forest is trained with a bagging method. The bragging method\nis based on the idea",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14575.0,
    "t_end": 14605.0,
    "text": "All right, most of the time\nrandom Forest is trained with a bagging method. The bragging method\nis based on the idea that the combination of learning module increases\nthe overall result. If you are combining the\nlearning from different models and then clubbing it together what it will do it will Increase\nthe overall result fine. Just one more thing. If the size of your\ndata set is huge. Then in that case one single\ndecision tree would lead to our Offutt model same way like a single person\nmight have its own perspective on the complete population as\na population is very huge.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14600.0,
    "t_end": 14630.0,
    "text": "like a single person\nmight have its own perspective on the complete population as\na population is very huge. Right? However, if we implement\nthe voting system and ask different individual\nto interpret the data, then we would be able\nto cover the pattern in a much meticulous way\neven from the diagram. You can see that in section A we have Howard large\ntraining data set what we do. We first divide\nour training data set into n sub-samples on it and we create a decision tree\nfor each cell sample. Now in the B part\nwhat we do we take the vote",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14625.0,
    "t_end": 14655.0,
    "text": "into n sub-samples on it and we create a decision tree\nfor each cell sample. Now in the B part\nwhat we do we take the vote out of every decision made\nby every decision tree. And finally we Club\nthe vote to get the random Forest dition fine. Let's move on ahead. Next. We have neighbor Buys. So name bias is\na classification technique, which is based on Bayes theorem. It assumes that it's of any particular feature in\na class is completely unrelated to the presence of any other feature\nnamed buys is simple",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14650.0,
    "t_end": 14680.0,
    "text": "of any particular feature in\na class is completely unrelated to the presence of any other feature\nnamed buys is simple and easy to implement algorithm\nand due to a Simplicity this algorithm might out perform\nmore complex model when the size of the data set\nis not large enough. All right, a classical use case of Navy bias is\na document classification. And that what you\ndo you determine whether a given text corresponds to one or more categories\nin the Texas case, the features used might be\nthe presence or absence. Absence of any keyword.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14675.0,
    "t_end": 14705.0,
    "text": "to one or more categories\nin the Texas case, the features used might be\nthe presence or absence. Absence of any keyword. So this was about Nev\nfrom the diagram. You can see\nthat using neighbor buys. We have to decide whether we have\na disease or not. First what we do we\ncheck the probability of having a disease and not having the disease\nright probability of having a disease is 0.1 while on the other hand\nprobability of not having a disease is 0.9. Okay first, let's see when we have disease\nand we go to the doctor.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14700.0,
    "t_end": 14730.0,
    "text": "a disease is 0.9. Okay first, let's see when we have disease\nand we go to the doctor. All right, so when we\nvisited the doctor and the test is positive\nAdjective so probability of having a positive test when you're having a disease\nis 0.8 0 and probability of a negative test when you already have\na disease that is 0.20. This is also a false negative\nstatement as the test is detecting negative, but you still have\nthe disease, right? So it's a false\nnegative statement. Now, let's move ahead",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14725.0,
    "t_end": 14755.0,
    "text": "is detecting negative, but you still have\nthe disease, right? So it's a false\nnegative statement. Now, let's move ahead when you don't have\nthe disease at all. So probability of not having\na disease is 0.9. And when you visit the doctor\nand the doctor is like, yes, you have the disease. But you already know\nthat you don't have the disease. So it's a false\npositive statement. So probability of having\na disease when you actually know there is no disease\nis 0.1 and probability of not having a disease when you actually know\nthere is no disease. So and the probability\nof it is around 0.90 fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14750.0,
    "t_end": 14780.0,
    "text": "of not having a disease when you actually know\nthere is no disease. So and the probability\nof it is around 0.90 fine. It is same as probability\nof not having a disease even the test is showing\nthe same results a true positive statement. So it is 0.9. All right. So let's move on ahead and\ndiscuss about kn n algorithm. So this KNN algorithm\nor the k-nearest neighbor, it stores all\nthe available cases and classifies new cases based\non the similarity measure the K",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14775.0,
    "t_end": 14805.0,
    "text": "it stores all\nthe available cases and classifies new cases based\non the similarity measure the K in the KNN algorithm as\nthe nearest neighbor, we wish to take vote\nfrom for example, if k equal 1 then the object\nis simply assigned to the class of that single nearest neighbor\nfrom the diagram. You can see the difference\nin the image when k equal 1 k equal 3\nand k equal 5, right? Well the And systems are now able to use\nthe k-nearest neighbor for visual pattern\nrecognization to scan",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14800.0,
    "t_end": 14830.0,
    "text": "Well the And systems are now able to use\nthe k-nearest neighbor for visual pattern\nrecognization to scan and detect hidden packages\nin the bottom bin of a shopping cart\nat the checkout if an object is detected which matches exactly\nto the object listed in the database. Then the price of the spotted\nproduct could even automatically be added\nto the customers Bill while this automated\nbilling practice is not used extensively at this time, but the technology\nhas been developed and is available for use if you want you can\njust use It and yeah,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14825.0,
    "t_end": 14855.0,
    "text": "but the technology\nhas been developed and is available for use if you want you can\njust use It and yeah, one more thing k-nearest\nneighbor is also used in retail to detect patterns in the credit card users many\nnew transaction scrutinizing software application use Cayenne algorithms to\nanalyze register data and spot unusual pattern that indicates\nsuspicious activity. For example,\nif register data indicates that a lot\nof customers information is being entered manually rather\nthan through automated scanning and swapping then in that case.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14850.0,
    "t_end": 14880.0,
    "text": "that a lot\nof customers information is being entered manually rather\nthan through automated scanning and swapping then in that case. This could indicate that the employees\nwere using the register. In fact stealing customers\npersonal information or if I register data indicates that a particular good\nis being returned or exchanged multiple times. This could indicate that employees are misusing\nthe return policy or trying to make money from\ndoing the fake returns, right? So this was about KNN algorithm. So starting with\nwhat is decision tree,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14875.0,
    "t_end": 14905.0,
    "text": "or trying to make money from\ndoing the fake returns, right? So this was about KNN algorithm. So starting with\nwhat is decision tree, but first, let me tell\nyou why did we choose the Gentry to start with? Well, these decision tree\nare really very easy to read and understand it belongs\nto one of The few models that interpretable where you can understand exactly\nwhy the classifier has made that particular decision right? Let me tell you a fact\nthat for a given data set. You cannot say that this algorithm performs\nbetter than that. It's like you cannot say\nthat decision trees",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14900.0,
    "t_end": 14930.0,
    "text": "Let me tell you a fact\nthat for a given data set. You cannot say that this algorithm performs\nbetter than that. It's like you cannot say\nthat decision trees better than a buys or name biases performing better\nthan decision tree. It depends on the data set, right you have to apply\nhit and trial method with all the algorithms one by one and then compare\nthe result the model which gives the best\nresult as the Order which you can use\nat for better accuracy for your data set. All right, so let's start\nwith what is decision tree. Well a decision tree is\na graphical representation of all the possible solution",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14925.0,
    "t_end": 14955.0,
    "text": "All right, so let's start\nwith what is decision tree. Well a decision tree is\na graphical representation of all the possible solution to our decision based\non certain conditions. Now, you might be wondering\nwhy this thing is called as decision tree. Well, it is called so because it starts with the root and then branches off\nto a number of solution just like a tree right even\nthe tree starts from a roux and it starts\ngrowing its branches. As once it gets bigger and bigger similarly\nin a decision tree. It has a roux which keeps on growing with\nincreasing number of decision",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14950.0,
    "t_end": 14980.0,
    "text": "As once it gets bigger and bigger similarly\nin a decision tree. It has a roux which keeps on growing with\nincreasing number of decision and the conditions now, let me tell you\na real life scenario. I won't say that all of you, but most of you\nmust have used it. Remember whenever you dial\nthe toll-free number of your credit card company, it redirects you to his intelligent\ncomputerised assistant where it asks\nyou questions like, press one for English\nor press 2 for Henry, press 3 for this press\n4 for that right now once you select one now again, It redirects you\nto a certain set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 14975.0,
    "t_end": 15005.0,
    "text": "press 3 for this press\n4 for that right now once you select one now again, It redirects you\nto a certain set of questions like press\n1 for this press 1 for that and similarly, right? So this keeps on repeating until you finally get\nto the right person, right? You might think that you are caught\nin a voicemail hell but what the company\nwas actually doing it was just using a decision tree\nto get you to the right person. I lied. I'd like you to focus\non this particular image for a moment on\nthis particular slide. You can see I image\nwhere the task is.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15000.0,
    "t_end": 15030.0,
    "text": "I'd like you to focus\non this particular image for a moment on\nthis particular slide. You can see I image\nwhere the task is. Should I accept\na new job offer or not? Alright, so you have\nto decide that for That what you did you created\na decision tree starting with the base condition\nor the root node. Was that the basic salary or the minimum salary\nshould be $50,000 if it is not $50,000. Then you are not at all\naccepting the offer. All right. So if your salary is\ngreater than $50,000, then you will further check whether the commute is\nmore than one hour or not. If it is more than one are you\nwill just decline the offer",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15025.0,
    "t_end": 15055.0,
    "text": "So if your salary is\ngreater than $50,000, then you will further check whether the commute is\nmore than one hour or not. If it is more than one are you\nwill just decline the offer if it is less than one hour, then you are getting closer\nto accepting the job offer then further what you will do. You will check\nwhether the company is offering. Free coffee or not, right if the company\nis not offering the free coffee, then you will just\ndecline the offer and have fit as offering\nthe free coffee. And yeah, you will happily\naccept the offer right? This is just an example\nof a decision tree.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15050.0,
    "t_end": 15080.0,
    "text": "And yeah, you will happily\naccept the offer right? This is just an example\nof a decision tree. Now, let's move ahead\nand understand a decision tree. Well, here is a sample data set that I will be using\nit to explain you about the decision tree. All right in this data set\neach row is an example. And the first two columns\nprovide features or attributes that describes the data and the last column\ngives the label or the class we want to predict and if you like you\ncan just modify this data by adding additional features",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15075.0,
    "t_end": 15105.0,
    "text": "and the last column\ngives the label or the class we want to predict and if you like you\ncan just modify this data by adding additional features and more example and our program will work\nin exactly the same way fine. Now this data set\nis pretty straightforward except for one thing. I hope you have noticed that\nit is not perfectly separable. Let me tell you something\nmore about that as in the second and fifth examples\nthey have the same features. But different labels\nboth have yellow as a Colour and diameter as three, but the labels are mango\nand lemon right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15100.0,
    "t_end": 15130.0,
    "text": "But different labels\nboth have yellow as a Colour and diameter as three, but the labels are mango\nand lemon right? Let's move on and see how our decision tree\nhandles this case. All right, in order to build\na tree will use a decision tree algorithm called card\nthis card algorithm stands for classification and regression tree\nalgorithm online. Let's see a preview\nof how it works. All right to begin\nwith We'll add a root node for the tree and all\nthe nodes receive a list of rows as a input and the route will receive\nthe entire training data set now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15125.0,
    "t_end": 15155.0,
    "text": "All right to begin\nwith We'll add a root node for the tree and all\nthe nodes receive a list of rows as a input and the route will receive\nthe entire training data set now each node will ask\ntrue and false question about one other feature. And in response\nto that question will split or partition the data set\ninto two different subsets these subsets then become\ninput to child node. We are to the tree and the goal of the question\nis to finally unmix the labels as we proceed down or in\nother words to produce the purest possible distribution\nof the labels at each node.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15150.0,
    "t_end": 15180.0,
    "text": "and the goal of the question\nis to finally unmix the labels as we proceed down or in\nother words to produce the purest possible distribution\nof the labels at each node. For example, the input\nof this node contains only. One single type\nof label so we could say that it's perfectly unmixed. There is no uncertainty\nabout the type of label as it consists\nof only grapes right on the other hand the labels\nin this node are still mixed up. So we would ask another question\nto further drill it down, right but before that we need to\nunderstand which question to ask",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15175.0,
    "t_end": 15205.0,
    "text": "So we would ask another question\nto further drill it down, right but before that we need to\nunderstand which question to ask and when and to do that we need to conduct by how much question\nhelps to unmix the label and we can quantify\nthe amount of Uncertainty at a single node using\na metric called gini impurity and we can quantify how much a question reduces that uncertainty using a concept\ncalled information game will use these to select the best\nquestion to ask at each point. And then what we'll do\nwe'll iterate the steps",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15200.0,
    "t_end": 15230.0,
    "text": "these to select the best\nquestion to ask at each point. And then what we'll do\nwe'll iterate the steps will recursively build the tree on each of the new node\nwill continue dividing the data until there are\nno further question to ask and finally we\nreach to our Leaf. Alright, alright,\nso this was about decision tree. So in order to create\na diversion First of all what you have to do\nyou have to identify different set of questions that you can ask to a tree\nlike is this color green and what will be these question\nthis question will be decided by your data set like as\nthis colored green",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15225.0,
    "t_end": 15255.0,
    "text": "that you can ask to a tree\nlike is this color green and what will be these question\nthis question will be decided by your data set like as\nthis colored green as the diameter greater\nthan equal to 3 is the color yellow right questions resembles\nto your data set remember that? All right. So if my color is green, then what it will do it\nwill divide into two part first. The Green Mango will be\nin the true while on the false. We have lemon\nand the map all right. And if the color is green or the diameter is greater\nthan equal to 3 or the color is yellow.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15250.0,
    "t_end": 15280.0,
    "text": "And if the color is green or the diameter is greater\nthan equal to 3 or the color is yellow. Now let's move on and understand about\ndecision tree terminologies. Alright, so starting with root node root node\nis a base node of a tree the entire tree starts\nfrom a root node. In other words. It is the first node\nof a tree it represents the entire population or sample and this entire population\nis further segregated or divided into two\nor more homogeneous set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15275.0,
    "t_end": 15305.0,
    "text": "the entire population or sample and this entire population\nis further segregated or divided into two\nor more homogeneous set. Fine. Next is the leaf node. Well, Leaf node is the one when you reach\nat the end of the tree, right that is you\ncannot further segregated down to any other level. That is the leaf node. Next is splitting splitting\nis dividing your root node or node into different sub part\non the basis of some condition. All right, then comes\nthe branch or the sub tree.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15300.0,
    "t_end": 15330.0,
    "text": "or node into different sub part\non the basis of some condition. All right, then comes\nthe branch or the sub tree. Well, this Branch\nor subtree gets formed when you split the tree suppose\nwhen you split a root node, it gets divided\ninto two branches or two subtrees right next. The concept of pruning. Well, you can say\nthat pruning is just opposite of splitting what we\nare doing here. We are just removing\nthe sub node of a decision tree will see more about pruning\nlater in this session. All right, let's move on ahead.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15325.0,
    "t_end": 15355.0,
    "text": "We are just removing\nthe sub node of a decision tree will see more about pruning\nlater in this session. All right, let's move on ahead. Next is parent or child node. Well, first of all root node\nis always the parent node and all other nodes associated with that\nis known as child node. Well, you can understand it\nin a way that all the top node belongs to a parent node\nand all the bottom node which are derived from\na Top node zhi node the node producing a further note is\na child node and the node which is producing. It is a parent node\nsimple concept, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15350.0,
    "t_end": 15380.0,
    "text": "producing a further note is\na child node and the node which is producing. It is a parent node\nsimple concept, right? Let's use the cartel Gotham\nand design a tree manually. So first of all, what you do you decide\nwhich question to ask and when so\nhow will you do that? So let's first of all visualize\nthe decision tree. So there's the decision tree\nwhich will be creating manually or like first of all, let's have a look\nat the Data set you have Outlook temperature\nhumidity and windy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15375.0,
    "t_end": 15405.0,
    "text": "or like first of all, let's have a look\nat the Data set you have Outlook temperature\nhumidity and windy as you have different attributes\non the basis of that you have to predict that\nwhether you can play or not. So which one among them should\nyou pick first answer determine the best attribute that\nclassifies the training data? All right. So how will you choose\nthe best attribute or how does a tree decide where to split or how the tree\nwill decide its root node? Well before we move on and split a tree there\nare some terminologies that you should know. All right first\nbeing the gini index.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15400.0,
    "t_end": 15430.0,
    "text": "Well before we move on and split a tree there\nare some terminologies that you should know. All right first\nbeing the gini index. X so what is this gini Index? This gini index is the measure\nof impurity or Purity used in building a decision\nTree in cartel Gotham. All right. Next is Information Gain\nthis Information Gain is the decrease in entropy after data set is split\non the basis of an attribute constructing a decision tree is\nall about finding an attribute that Returns the highest\nInformation Gain. All right, so you\nwill be selecting the node",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15425.0,
    "t_end": 15455.0,
    "text": "constructing a decision tree is\nall about finding an attribute that Returns the highest\nInformation Gain. All right, so you\nwill be selecting the node that would give you\nthe highest Information Gain. Alright next is\nreduction in variance. Reduction in variance is\nan algorithm which is used for continuous Target variable\nor regression problems. The split with lower variance\nis selected as a criteria to let the population see\nin general term. What do you mean by variance? Variance is how much\nyour data is wearing? Right? So if your data is\nless impure or is more pure than in that case\nthe variation would be less",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15450.0,
    "t_end": 15480.0,
    "text": "Variance is how much\nyour data is wearing? Right? So if your data is\nless impure or is more pure than in that case\nthe variation would be less as all the data\nalmost similar, right? So there's also a way\nof setting a tree the split with lower variance is selected as the criteria\nto split the population. All right. Next is the chi Square t Square. It is an algorithm which is used to find out\nthese statistical significance between the differences\nbetween sub nodes and the parent nodes fine. Let's move ahead now\nthe main question is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15475.0,
    "t_end": 15505.0,
    "text": "and the parent nodes fine. Let's move ahead now\nthe main question is how will you decide\nthe best attribute for now just understand that you need to calculate\nsomething known as information game the attribute with the highest Information\nGain is considered the best. Yeah. I know your next question\nmight be like what? This information, but before we move on and see what exactly Information Gain\nIs let me first introduce you to a term called entropy because this term",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15500.0,
    "t_end": 15530.0,
    "text": "what exactly Information Gain\nIs let me first introduce you to a term called entropy because this term will be used in calculating\nthe Information Gain. Well entropy is just a metric which measures the impurity\nof something or in other words. You can say that as\nthe first step to do before you solve the problem\nof a decision tree as I mentioned is\nsomething about impurity. So let's move on and understand\nwhat is impurity suppose. You are a basket full of apples and another Bowl Which\nis full of same label, which says Apple now if you are asked\nto pick one item",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15525.0,
    "t_end": 15555.0,
    "text": "You are a basket full of apples and another Bowl Which\nis full of same label, which says Apple now if you are asked\nto pick one item from each basket and ball, then the probability\nof getting the apple and it's correct label is 1 so\nin this case, you can say that impurities zero. All right. Now what if there are\nfour different fruits in the basket and four different\nlabels in the ball, then the probability\nof matching the fruit to a label is obviously not one. It's something less than that. Well, it could be possible that I picked banana\nfrom the basket",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15550.0,
    "t_end": 15580.0,
    "text": "to a label is obviously not one. It's something less than that. Well, it could be possible that I picked banana\nfrom the basket and when I randomly\npicked Level from the ball. It says a cherry\nany random permutation and combination can be possible. So in this case, I'd say\nthat impurities is nonzero. I hope the concept\nof impurities here. So coming back to entropy as I said entropy is\nthe measure of impurity from the graph on your left. You can see that as the probability\nis zero or one that is either they\nare highly impure or they are highly pure\nthan in that case the value",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15575.0,
    "t_end": 15605.0,
    "text": "You can see that as the probability\nis zero or one that is either they\nare highly impure or they are highly pure\nthan in that case the value of entropy is zero. And when the probability is\n0.5 then the value of entropy. Is maximum. Well, what is impurity\nimpurities the degree of Randomness how random data is so if the data is completely pure in that case\nthe randomness equals zero or if the data is completely empty\nor even in that case the value of impurity\nwill be zero question. Like why is it that the value\nof entropy is maximum",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15600.0,
    "t_end": 15630.0,
    "text": "if the data is completely empty\nor even in that case the value of impurity\nwill be zero question. Like why is it that the value\nof entropy is maximum at 0.5 might arise\nin a mine, right? So let me discuss about that. Let me derive it mathematically as you can see here on the slide\nthe mathematical formula of entropy is - of probability of yes, let's move on and see what this graph has to say\nmathematically suppose s is our total sample space\nand it's divided into two parts. Yes, and no like\nin our data set the result for playing was divided\ninto two parts.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15625.0,
    "t_end": 15655.0,
    "text": "our total sample space\nand it's divided into two parts. Yes, and no like\nin our data set the result for playing was divided\ninto two parts. Yes or no, which we have to predict\neither we have to play or not. Right? So for that particular case, you can Define the formula\nof entropy as entropy of total sample\nspace equals negative of probability of e is multiplied by\nlog of probability. We of yes, whether base 2 minus probability\nof no X log of probability of no with base to where s is\nyour total sample space",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15650.0,
    "t_end": 15680.0,
    "text": "whether base 2 minus probability\nof no X log of probability of no with base to where s is\nyour total sample space and P of v s is\nthe probability of e s-- and p-- of know is\nthe probability of no. Well, if the number\nof BS equal number of know that is probability\nof s equals 0.5 right since you have equal number\nof BS and know so in that case the value of entropy will be one just\nput the value over there. All right. Let me just move to Next slide\nI'll show you this. Alright next is\nif it contains all Yes,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15675.0,
    "t_end": 15705.0,
    "text": "All right. Let me just move to Next slide\nI'll show you this. Alright next is\nif it contains all Yes, or all know that is probability\nof a sample space is either 1 or 0 then in that case entropy\nwill be equal to 0 Let's see the\nmathematically one by one. So let's start\nwith the first condition where the probability was 0.5. So this is our formula\nfor entropy, right? So there's our first case right\nwhich will discuss the art when the probability\nof vs equal probability of node that is in our data set we have\nRule number of yes, and no.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15700.0,
    "t_end": 15730.0,
    "text": "So there's our first case right\nwhich will discuss the art when the probability\nof vs equal probability of node that is in our data set we have\nRule number of yes, and no. All right. So probability of yes\nequal probability of no and that equals\n0.5 or in other words, you can say that yes plus no equal\nto Total sample space. All right, since\nthe probability is 0.5. So when you put the values in the formula you get\nsomething like this and when you calculate it, you will get the entropy of\nthe total sample space as one.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15725.0,
    "t_end": 15755.0,
    "text": "in the formula you get\nsomething like this and when you calculate it, you will get the entropy of\nthe total sample space as one. All right. Let's see for the next case. What is the next case\neither you have totally us or you have to No, so if you have total, yes, let's see the formula\nwhen we have total. Yes. So you have all yes\nand 0 no fine. So probability of e s equal one. And yes as the total\nsample space obviously. So in the formula\nwhen you put that thing up here, you get entropy of sample space equal negative X\nof 1 multiplied by log of 1",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15750.0,
    "t_end": 15780.0,
    "text": "So in the formula\nwhen you put that thing up here, you get entropy of sample space equal negative X\nof 1 multiplied by log of 1 as the value of log 1 equals 0. So the total thing will result\nto 0 similarly is the case with no even in that case\nyou will get the entropy of total sample. Case as 0 so this was\nall about entropy. All right. Next is what is\nInformation Gain? Well Information Gain what it does is it measures\nthe reduction in entropy. It decides which attribute should be selected\nas the decision node.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15775.0,
    "t_end": 15805.0,
    "text": "Well Information Gain what it does is it measures\nthe reduction in entropy. It decides which attribute should be selected\nas the decision node. If s is our total collection than Information Gain\nequals entropy, which we calculated\njust now that - weighted average multiplied\nby entropy of each feature. Don't worry. We'll just see how it to calculate\nit with an example. All right. So let's manually build\na decision tree for our data set. So there's our data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15800.0,
    "t_end": 15830.0,
    "text": "So let's manually build\na decision tree for our data set. So there's our data set which consists of\n14 different instances out of which we have nine. Yes and five know I like\nso we have the formula for entropy just put\nover that since 9 years. So total probability\nof e s equals 9 by 14 and total probability\nof no equals Phi by 14 and when you put up the value and calculate the result\nyou will get the value. Oh of entropy as 0.94. All right. So this was your first step",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15825.0,
    "t_end": 15855.0,
    "text": "and calculate the result\nyou will get the value. Oh of entropy as 0.94. All right. So this was your first step that is compute the entropy\nfor the entire data set. All right. Now you have to select that out of Outlook\ntemperature humidity and windy, which of the node should you\nselect as the root node big question, right? How will you decide that? This particular node should\nbe chosen at the base note and on the basis of that only I will be creating\nthe entire tree. I will select that. Let's see so you have to do it one by one you have\nto calculate the entropy and Information Gain for all",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15850.0,
    "t_end": 15880.0,
    "text": "Let's see so you have to do it one by one you have\nto calculate the entropy and Information Gain for all of the Front note so\nstarting with Outlook. So Outlook has three different parameters\nSunny overcast and rainy. So first of all select\nhow many number of years and no are there in the case\nof Sunny like when it is sunny how many number of years and how many number\nof nodes are there? So in total we have to yes and three Nos and case\nof sunny in case of overcast. We have all yes. So if it is overcast then\nwill surely go to play.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15875.0,
    "t_end": 15905.0,
    "text": "and three Nos and case\nof sunny in case of overcast. We have all yes. So if it is overcast then\nwill surely go to play. It's like that. Alright and next it is rainy\nthen total number of vs equal. Three and total number\nof no equals 2 fine next what we do we\ncalculate the entropy for each feature for here. We are calculating the entropy\nwhen Outlook equals Sunny. First of all, we are assuming\nthat Outlook is our root node and for that we are calculating\nthe information gain for it. Alright. So in order to calculate\nthe Information Gain remember",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15900.0,
    "t_end": 15930.0,
    "text": "we are assuming\nthat Outlook is our root node and for that we are calculating\nthe information gain for it. Alright. So in order to calculate\nthe Information Gain remember the formula it was entropy\nof the total sample space - weighted average X entropy\nof each feature. All right. So what we are doing here, we are calculating\nthe entropy of out. Look when it was sunny. So total number of yes, when it was sunny was\nto and total number of know that was three fine. So let's put up in the formula since the probability\nof yes is 2 by 5 and the probability\nof no is 3 by 5.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15925.0,
    "t_end": 15955.0,
    "text": "So let's put up in the formula since the probability\nof yes is 2 by 5 and the probability\nof no is 3 by 5. So you will get\nsomething like this. Alright, so you are\ngetting the entropy of sunny as zero point\nnine seven one fine. Next we will calculate\nthe entropy for overcast when it was overcast. Remember it was all yes, right. So the probability of yes is equal 1\nand when you put over that you will get the value\nof entropy as 0 fine and when it was rainy rainy\nhas 3s and to nose.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15950.0,
    "t_end": 15980.0,
    "text": "that you will get the value\nof entropy as 0 fine and when it was rainy rainy\nhas 3s and to nose. So probability of e s\nin case of Sonny's 3 by 5 and probability of know\nin case of Sonny's 2 by 5. And when you add the value\nof probability of vs and probability of no\nto the formula, you get the entropy of sunny as\nzero point nine seven one point. Now, you have to calculate how much information you\nare getting from Outlook that equals weighted average. All right. So what was this? To diverge total number of years\nand total number of no fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 15975.0,
    "t_end": 16005.0,
    "text": "All right. So what was this? To diverge total number of years\nand total number of no fine. So information from Outlook\nequals 5 by 14 from where does this 5 came over? We are calculating the total number of sample space\nwithin that particular Outlook when it was sunny, right? So in case of Sunny there\nwas two years and three NOS. All right. So weighted average for Sonny\nwould be equal to 5 by 14. All right, since the formula was five\nby 14 x entropy of each feature. All right, so as calculated the entropy He\nfor Sonny is zero point nine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16000.0,
    "t_end": 16030.0,
    "text": "since the formula was five\nby 14 x entropy of each feature. All right, so as calculated the entropy He\nfor Sonny is zero point nine. Seven one, right? So what we'll do we'll multiply\n5 by 14 with 0.97 one. Right? Well, this was\nthe calculation for information when Outlook equal sunny, but Outlook even equals overcast\nand rainy for in that case. What we'll do again similarly\nwill calculate for everything for overcast and sunny for overcast weighted averages",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16025.0,
    "t_end": 16055.0,
    "text": "What we'll do again similarly\nwill calculate for everything for overcast and sunny for overcast weighted averages for by 14 multiplied\nby its entropy. That is 0 and for Sonny\nit is same Phi by 14. Yes, and to Knows X its entropy that is zero point\nnine seven one. And finally we'll take the sum\nof all of them which equals to 0.693 right next. We will calculate\nthe information gained this what we did earlier was\ninformation taken from Outlook. Now, we are calculating. What is the information?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16050.0,
    "t_end": 16080.0,
    "text": "We will calculate\nthe information gained this what we did earlier was\ninformation taken from Outlook. Now, we are calculating. What is the information? We are gaining\nfrom Outlook right. Now this Information Gain that equals to Total entropy\nminus the information that is taken from Outlook. All right, so So\ntotal entropy we had 0.94 - information we took\nfrom Outlook as 0.693. So the value of information\ngained from Outlook results to zero point two four seven. All right. So next what we have to do.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16075.0,
    "t_end": 16105.0,
    "text": "So the value of information\ngained from Outlook results to zero point two four seven. All right. So next what we have to do. Let's assume that\nWendy is our root node. So Wendy consists of\ntwo parameters false and true. Let's see how many years and how many nodes are there\nin case of true and false. So when Wendy has\nFalls as its parameter, then in that case it has\nsix years and to knows. And when it as true\nas its parameter, it has 3 S and 3 nodes. All right. So let's move ahead and similarly calculate\nthe information taken from Wendy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16100.0,
    "t_end": 16130.0,
    "text": "it has 3 S and 3 nodes. All right. So let's move ahead and similarly calculate\nthe information taken from Wendy and finally calculate the\ninformation gained from Wendy. Alright, so first of all, what we'll do we'll\ncalculate the entropy of each feature starting\nwith windy equal true. So in case of true we\nhad equal number of yes and equal number\nof no will remember the graph when we had the probability as 0.5 as total number of years\nequal total number of know. For that case\nthe entropy equals 1 so we can directly\nwrite entropy of room",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16125.0,
    "t_end": 16155.0,
    "text": "0.5 as total number of years\nequal total number of know. For that case\nthe entropy equals 1 so we can directly\nwrite entropy of room when it's windy is one as we had already proved it when probability equals 0.5\nthe entropy is the maximum that equals to 1. All right. Next is entropy of false\nwhen it is windy. All right, so similarly just\nput the probability of yes and no in the formula\nand then calculate the result since you have six years\nand two nodes. So in total, you'll get the probability\nof e S6 by 8 and probability",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16150.0,
    "t_end": 16180.0,
    "text": "since you have six years\nand two nodes. So in total, you'll get the probability\nof e S6 by 8 and probability of know Two by eight. All right, so when you\nwill calculate it, you will get the entropy of false as zero point\neight one one. Alright, now, let's calculate\nthe information from windy. So total information\ncollected from Windy equals information taken when Wendy equal true\nplus information taken when when D equals false. So we'll calculate the weighted\naverage for each one of them and then we'll sum it up to finally get the total\ninformation taken from windy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16175.0,
    "t_end": 16205.0,
    "text": "So we'll calculate the weighted\naverage for each one of them and then we'll sum it up to finally get the total\ninformation taken from windy. So in this case, it equals to 8 by 14 multiplied\nby 0.8 1 1 + 6 y 14 x 1 what is this? 8 it is total number of yes, and no in case when when D\nequals false, right? So when it was false,\nso total number of BS that equals to 6 and total more\nof know that equal to 2 that some herbs to 8. All right. So that is why the weighted\naverage results to Aid by 14 similarly information taken",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16200.0,
    "t_end": 16230.0,
    "text": "that some herbs to 8. All right. So that is why the weighted\naverage results to Aid by 14 similarly information taken when windy equals true equals\nto 3 plus 3 that is 3 S and 3 no equal 6 divided by\ntotal number of sample space. That is 14 x That\nis entropy of true. All right, so it is a by 14 multiplied by 0.8 1 1\nplus 6 by 14 x one which results to 0.89 to this is information taken from Windy. All right. Now how much information\nyou are gaining from Wendy.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16225.0,
    "t_end": 16255.0,
    "text": "which results to 0.89 to this is information taken from Windy. All right. Now how much information\nyou are gaining from Wendy. So for that what you will do so\ntotal information gained from Windy that equals\nto Total entropy - information taken from Windy. All right, that is 0.94 - 0.89 to that equals\nto zero point zero four eight. And so 0.048 is the information\ngained from Windy. All right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16250.0,
    "t_end": 16280.0,
    "text": "All right. Similarly we calculated\nfor the rest to all right. So for Outlook\nas you can see, the information was 0.693. And it's Information Gain\nwas zero point two four seven in case of temperature. The information was around zero point nine one one\nand the Information Gain that was equal to 0.02\n9 in case of humidity. The information gained was 0.15\nto and in the case of windy. The information\ngained was 0.048.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16275.0,
    "t_end": 16305.0,
    "text": "The information gained was 0.15\nto and in the case of windy. The information\ngained was 0.048. So what we'll do we'll\nselect the attribute. With a maximum fine. Now, we are selected\nOutlook as our root node, and it is further subdivided into three different parts\nSunny overcast and rain, so in case of overcast\nwe have seen that it consists of all. Yes, so we can consider\nit as a leaf node, but in case of sunny and rainy, it's doubtful as it\nconsists of both. Yes and both know",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16300.0,
    "t_end": 16330.0,
    "text": "but in case of sunny and rainy, it's doubtful as it\nconsists of both. Yes and both know so you need to recalculate\nthe things right again for this node. You have to\nrecalculate the things. All right, you have to again\nselect the attribute. Is having the maximum\nInformation Gain. All right, so there's how your complete tree\nwill look like. All right. So, let's see when you can play\nso you can play when Outlook is overcast. All right, in that case. You can always play\nif the Outlook is sunny. You will further drill down\nto check the humidity condition.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16325.0,
    "t_end": 16355.0,
    "text": "You can always play\nif the Outlook is sunny. You will further drill down\nto check the humidity condition. All right, if the\nhumidity is normal, then you will play if the humidity is high\nthen you won't play right when the Outlook predicts that it's rainy then\nfurther you will check whether it's windy or not. If it is a week went then\nyou will go and offer. Say but if it has strong wind,\nthen you won't play right? So this is how your entire\ndecision tree would look like at the end. Now comes the concept\nof pruning say is that what should I do to play?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16350.0,
    "t_end": 16380.0,
    "text": "Now comes the concept\nof pruning say is that what should I do to play? Well you have to do\npruning pruning will decide how you will play. What is this pruning? Well, this pruning is nothing\nbut cutting down the nodes and order to get\nthe optimal solution. All right. So what pruning does it\nreduces the complexity? All right as are you\ncan see on the screen that it showing only\nthe result for you. That is it showing all\nthe result which says that you can play. All right before we drill down\nto a practical session",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16375.0,
    "t_end": 16405.0,
    "text": "That is it showing all\nthe result which says that you can play. All right before we drill down\nto a practical session a common question\nmight come in your mind. You might think that our tree base model better\nthan cleaner model, right? You can think like if I\ncan use a logistic regression for classification problem and linear regression\nfor regression problem. Then why there is\na need to use the tree. Well many of us have this In\nin their mind and well, there's a valid question too.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16400.0,
    "t_end": 16430.0,
    "text": "Then why there is\na need to use the tree. Well many of us have this In\nin their mind and well, there's a valid question too. Well, actually as\nI said earlier, you can use any algorithm. It depends on\nthe type of problem. You're solving let's look\nat some key factor, which will help you to decide\nwhich algorithm to use and when so the first point being if the relationship between\ndependent and independent variable as well approximated by a linear model then linear regression will outperform\ntree base model second case if there is a high\nnon-linearity and complex",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16425.0,
    "t_end": 16455.0,
    "text": "by a linear model then linear regression will outperform\ntree base model second case if there is a high\nnon-linearity and complex relationship between Lent and independent variables\nat remodel will outperform a classical regression\nmodel in third case. If you need to build a model which is easy to explain\nto people a decision tree model will always do better\nthan a linear model as the decision tree models are simpler to interpret\nthen linear regression. All right. Now, let's move on ahead and see how you can write it as\nGentry classifier from scratch",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16450.0,
    "t_end": 16480.0,
    "text": "are simpler to interpret\nthen linear regression. All right. Now, let's move on ahead and see how you can write it as\nGentry classifier from scratch and python using\nthe card algorithm. All right for this. I will be using jupyter notebook\nwith python 3.0. Oh install on it. Alright, so let's\nopen the Anaconda and the jupyter notebook. Whereas that so this is a inner Corner Navigator\nand I will directly jump over to jupyter notebook and hit\nthe launch button. I guess everyone\nknows that jupyter. Notebook is a web-based\ninteractive Computing notebook environment where you\ncan run your python codes.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16475.0,
    "t_end": 16505.0,
    "text": "I guess everyone\nknows that jupyter. Notebook is a web-based\ninteractive Computing notebook environment where you\ncan run your python codes. So my jupyter notebook. It opens on my Local\nHost double 8 9 1 so I will be using\nthis jupyter notebook in order to write\nmy decision tree classifier using python for this\ndecision tree classifier. I have already written. Set of codes. Let me explain you\njust one by one. So we'll start with initializing\nour training data set. So there's our sample data set for which each row\nis an example. The last column is a label and the first two columns\nare the features.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16500.0,
    "t_end": 16530.0,
    "text": "So there's our sample data set for which each row\nis an example. The last column is a label and the first two columns\nare the features. If you want you can add some\nmore features an example for your practice\ninteresting fact is that this data set\nis designed in a way that the second and fifth\nexample have almost the same features, but they have different labels. All right. So let's move on and see\nhow the tree handles this case as you can see here both. Both of them the second and the fifth column\nhave the same features. What did different\nis just their label? Right? So let's move ahead. So this is our training data\nset next what we are doing we",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16525.0,
    "t_end": 16555.0,
    "text": "and the fifth column\nhave the same features. What did different\nis just their label? Right? So let's move ahead. So this is our training data\nset next what we are doing we are adding some column labels. So they are used only\nto print the trees fine. So what we'll do we'll add\nheader to the columns like the First Column is\nof color second is of diameter and third is a label column. Alright, next Road\nwill do will Define a function as unique values\nin which will pass the rows and the columns. So this function\nwhat it will do. We find the unique values\nfor a column in the data set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16550.0,
    "t_end": 16580.0,
    "text": "a function as unique values\nin which will pass the rows and the columns. So this function\nwhat it will do. We find the unique values\nfor a column in the data set. So this is an example for that. So what we are doing here, we are passing\ntraining data Hazard row and column number as 0 so what we are doing we are finding\nunique values in terms of color. And in this since the row is training data\nand the column is 1 so what you are doing here, so we are finding\nthe unique values in terms of diameter fine. So this is just an example next what we'll do we'll Define\na function as class count and we'll pass zeros into it.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16575.0,
    "t_end": 16605.0,
    "text": "So this is just an example next what we'll do we'll Define\na function as class count and we'll pass zeros into it. So what it does it counts\nthe number of each type of Example within data set. So in this function what we are basically doing\nwe are counting the number of each type for example in the data set or\nwhat we are doing. We are counting the unique\nvalues for the label in the data set as a sample. You can see here. We can pass that entire\ntraining data set to this particular function\nas class underscore count what it will do it will find\nall the different types of label within the training data set as you can see here the unique\nlabel consists of mango grape",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16600.0,
    "t_end": 16630.0,
    "text": "what it will do it will find\nall the different types of label within the training data set as you can see here the unique\nlabel consists of mango grape and lemon so next what we'll do\nwe'll Define a function is numeric and we'll pass\na value into it. So what it Do it. We'll just test if the value is numeric\nor not and it will return if the value is\nan integer or a float. For example, you\ncan see is numeric. We are passing 7\nso it is an integer so it will return in value and if we are passing red it's\nnot a numeric value, right? So moving on ahead where you define a class\nnamed as question.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16625.0,
    "t_end": 16655.0,
    "text": "so it will return in value and if we are passing red it's\nnot a numeric value, right? So moving on ahead where you define a class\nnamed as question. So what this question does this question is used\nto partition the data set. This class voted does it\njust records a column number? For example 0 for color a light\nand a column value for example, green Next what we are doing\nwe are defining a match method which is used to compare\nthe feature value in the example. The feature values\nstored in the question. Let's see how first of all\nwhat you are doing. We're defining an init\nfunction and inside that we are passing\nthe self column",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16650.0,
    "t_end": 16680.0,
    "text": "The feature values\nstored in the question. Let's see how first of all\nwhat you are doing. We're defining an init\nfunction and inside that we are passing\nthe self column and the value as parameter. So next what we do\nwe Define a function as match what it does is it\ncompares the feature value in an example to the feature\nvalue in this question when next we'll Define\na function as re PR, which is just a helper method\nto print the question in a readable format. Next what we are doing we are\ndefining a function partition. Well, this function\nis used to partition the data set each row\nin the data set it checks",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16675.0,
    "t_end": 16705.0,
    "text": "Next what we are doing we are\ndefining a function partition. Well, this function\nis used to partition the data set each row\nin the data set it checks if it matched\nthe question or not if it does so it adds it\nto the true rose or if not, then it adds to the false Rose. All right, for example, as you can see, it's partition\nthe training data set based on whether the rows\nare ready or not here. We are calling\nthe function question and we are passing a value\nof zero and read to it. So what did we do? It will assign all the red rose\nto True underscore Rose. And everything else\nwill be assigned to false underscore rose fine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16700.0,
    "t_end": 16730.0,
    "text": "It will assign all the red rose\nto True underscore Rose. And everything else\nwill be assigned to false underscore rose fine. Next what we'll do we'll Define\na gini impurity function and inside that will pass\nthe list of rows. So what it will do it will just\ncalculate the dream Purity for the list of rows. Next what we are doing\nevery defining a function as Information Gain. So what this Information Gain\nfunction does it calculates The Information Gain\nusing the uncertainty of the starting node - the weighted impurity\nof the child node.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16725.0,
    "t_end": 16755.0,
    "text": "The Information Gain\nusing the uncertainty of the starting node - the weighted impurity\nof the child node. The next function\nis find the best plate. Well, this function is used\nto find the best question to ask by iterating over\nevery feature of value and then calculating\nthe information game. For the detail explanation\non the code. You can find the code\nin the description given below. All right next we'll define\na class as leave for classifying the data. It holds a dictionary of glass\nlike mango for how many times it appears in the row\nfrom the training data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16750.0,
    "t_end": 16780.0,
    "text": "for classifying the data. It holds a dictionary of glass\nlike mango for how many times it appears in the row\nfrom the training data that reaches the sleeve. Alright next is\nthe decision node. So this decision node,\nit will ask a question. This holds a reference\nto the question and the two child nodes\non the base of that you are deciding which node\nto add further to which branch. Alright so next video. We're defining a function\nof Beltre and inside that we are passing\nour number of rows. So this is the function\nthat is used to build the tree. So initially what we did we\nDefine all the various function",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16775.0,
    "t_end": 16805.0,
    "text": "that we are passing\nour number of rows. So this is the function\nthat is used to build the tree. So initially what we did we\nDefine all the various function that we'll be using\nin order to build a tree. So let's start by partitioning the data set\nfor each unique attribute, then we'll calculate\nthe information gain and then return the question that produces the highest gain and on the basis of that\nwill split the tree. So what we are doing here, we are partitioning\nthe data set calculating the Information Gain. And then what this is returning\nit is returning the question that is producing\nthe highest gain.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16800.0,
    "t_end": 16830.0,
    "text": "we are partitioning\nthe data set calculating the Information Gain. And then what this is returning\nit is returning the question that is producing\nthe highest gain. All right. Now if gain equals\n0 return Leaf Rose, so what it will do. So if we are getting\nno for the gain that is gain equals\n0 then in that case since no further question\ncould be asked so what it will do it\nwill return a leaf fine now true or underscore Rose or false underscore Rose\nequal partition with rose and the question. So if we are reaching\ntell this position,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16825.0,
    "t_end": 16855.0,
    "text": "or false underscore Rose\nequal partition with rose and the question. So if we are reaching\ntell this position, then you have already\nfound a Value which will be used\nto partition the data set then what you will do you\nwill recursively build the true branch and similarly recursively\nbuild the false Branch. So return Division\nand Discord node and side that will be passing question\ntrue branch and false Branch. So what it will do it\nwill return a question node. This question node this\nrecalls the best feature or the value to ask\nat this point fine. Now that we have\nBuilder tree next",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16850.0,
    "t_end": 16880.0,
    "text": "This question node this\nrecalls the best feature or the value to ask\nat this point fine. Now that we have\nBuilder tree next what we'll do we'll Define\na print underscore tree function which will be used\nto print the tree fine. So finally what we are doing\nin this particular function that we are printing our tree\nnext is the classify function which will use it to decide whether to follow the true\nBranch or the false branch and then compared to the feature values stored\nin the node to the example. We are considering\nand last what we'll do we'll finally print\nthe production at the leaf. So let's execute\nit and see okay,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16875.0,
    "t_end": 16905.0,
    "text": "to the feature values stored\nin the node to the example. We are considering\nand last what we'll do we'll finally print\nthe production at the leaf. So let's execute\nit and see okay, so there's our testing data. Online so we printed\na leaf as well. Now that we have trained\nour algorithm is our training data set\nnow it's time to test it. So there's our testing data set. So let's finally execute\nit and see what is the result. So this is the result you\nwill get so first question, which is asked by the algorithm\nis is diameter greater",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16900.0,
    "t_end": 16930.0,
    "text": "So let's finally execute\nit and see what is the result. So this is the result you\nwill get so first question, which is asked by the algorithm\nis is diameter greater than equal to 3, if it is true, then it will further ask\nif the color is yellow again, if it is true, then it will predict mango\nas one and lemon with one. And in case it is false, then it will just\npredict the mango. Now. This was the true part. Now next coming\nto diameter is not greater than or equal to 3 then\nin that case it's false. And what did we do? It'll just predict\nthe grape vine.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16925.0,
    "t_end": 16955.0,
    "text": "Now next coming\nto diameter is not greater than or equal to 3 then\nin that case it's false. And what did we do? It'll just predict\nthe grape vine. Okay. So this was all\nabout the coding part now, let's conclude this session. But before concluding let me\njust show you one more thing. Now. There's a scikit-learn\nalgorithm cheat sheet, which explains you which algorithm you should use\nand when all right, let's build in\na decision tree format. At let's see how it is Big. So first condition it will check whether you have\n50 samples or not. If your samples\nare greater than 50, then we'll move ahead\nif it is less than 50,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16950.0,
    "t_end": 16980.0,
    "text": "So first condition it will check whether you have\n50 samples or not. If your samples\nare greater than 50, then we'll move ahead\nif it is less than 50, then you need\nto collect more data if your sample\nis greater than 50, then you have to decide whether you want to predict\na category or not. If you want to\npredict a category, then further you will see that whether you\nhave labeled data or not. If you have label data, then that would be a classification\nalgorithm problem. If you don't have\nthe label data, then it would be\na clustering problem. Now if you don't want\nto The category then what you want to protect\npredict a quantity.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 16975.0,
    "t_end": 17005.0,
    "text": "then it would be\na clustering problem. Now if you don't want\nto The category then what you want to protect\npredict a quantity. Well, if you want\nto predict a quantity, then in that case, it would be\na regression problem. If you don't want to predict a quantity and you want\nto keep looking further, then in that case, you should go for dimensionality\nreduction problems and still if you don't want to look and the predicting structure\nis not working. Then you have\ntough luck for that. I hope this doesn't recession\nclarifies all your doubt over decision tree algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17000.0,
    "t_end": 17030.0,
    "text": "I hope this doesn't recession\nclarifies all your doubt over decision tree algorithm. Now, we'll try to find out\nthe answer to this particular question as to why we\nneed random Forest fine. So like human beings learn\nfrom the past experiences. So unlike human beings\na computer does not have experiences then how does\nmachine takes decisions? Where does it learn from? Well a computer system actually learns from the data which\nrepresents some past experiences",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17025.0,
    "t_end": 17055.0,
    "text": "Where does it learn from? Well a computer system actually learns from the data which\nrepresents some past experiences of an application domain. So now let's see, how random Forest It's\nin building up in learning model with a very simple use case\nof credit risk detection. Now needless to say that credit card companies have a very nested\ninterest in identifying Financial transactions that are illegitimate\nand criminal in nature. And also I would like\nto mention this point",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17050.0,
    "t_end": 17080.0,
    "text": "Financial transactions that are illegitimate\nand criminal in nature. And also I would like\nto mention this point that according to\nthe Federal Reserve payments study Americans used\ncredit cards to pay for twenty six point\ntwo million purchases in 2012 and The estimated loss\ndue to unauthorized transactions that here was u.s. 6 point 1 billion dollars now in the banking industry\nmeasuring risk is very critical because the stakes are too high.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17075.0,
    "t_end": 17105.0,
    "text": "in the banking industry\nmeasuring risk is very critical because the stakes are too high. So the overall goal is\nactually to figure out who all can be fraudulent before too much Financial\ndamage has been done. So for this a credit card\ncompany receives thousands of applications for new cards and each application\ncontains information. Mission about an\napplicant, right? So so here as you can see\nthat from all those applications",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17100.0,
    "t_end": 17130.0,
    "text": "So so here as you can see\nthat from all those applications what we can actually\nfigure out is that predictor variables. Like what is the marital\nstatus of the person? What is the gender\nof the person? What is the age of the person\nand the status which is actually whether it is a default pair\nor non-default pair. So default payments are\nbasically when payments are not made in time and according to the agreement\nsigned by the cardholder. So now that account is actually\nset to be in the default.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17125.0,
    "t_end": 17155.0,
    "text": "So default payments are\nbasically when payments are not made in time and according to the agreement\nsigned by the cardholder. So now that account is actually\nset to be in the default. So you can easily\nfigure out the history of the particular card holder\nfrom this then we can also look at the time of payment whether he has been\na regular pair or non regular one. What is the source of income\nfor that particular person and so and so forth. So to minimize loss\nthe back actually needs certain decision rule to predict",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17150.0,
    "t_end": 17180.0,
    "text": "So to minimize loss\nthe back actually needs certain decision rule to predict whether to approve Particular no one of\nthat particular person or not. Now here is where the random Forest\nactually comes into the picture. All right. Now, let's see how random\nForest can actually help us in this particular scenario. Now, we have taken randomly two parameters out of all\nthe predictive variables that we saw previously now, we have taken two\npredictor variables here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17175.0,
    "t_end": 17205.0,
    "text": "two parameters out of all\nthe predictive variables that we saw previously now, we have taken two\npredictor variables here. The first one is the income and the second one\nis the H right and Hurley parallel it to decision trees\nhave been implemented upon those predicted variables\nand let's first assume the case of the income variable right? So here we have divided\nour income into three categories the first one being the person\nearning over $35,000 second",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17200.0,
    "t_end": 17230.0,
    "text": "So here we have divided\nour income into three categories the first one being the person\nearning over $35,000 second from 15 to 35 thousand dollars\nthe third one running in the range of 0 to\n15 thousand dollars. Now if a person\nis earning over $35,000, which is a pretty Good\nincome pretty decent. So now we'll check out\nfor the credit history. And here the probability is that if a person is earning\na good amount then there is very low risk that he won't be able to pay\nback already earning good.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17225.0,
    "t_end": 17255.0,
    "text": "that if a person is earning\na good amount then there is very low risk that he won't be able to pay\nback already earning good. So the probability is that his application\nof loan will get approved. Right? So there is actually low risk\nor moderate risk, but there's no real issue\nof higher risk as such. We can approve\nthe applicants request here. Now, let's move on and watch out\nfor the second category where the person\nis actually earning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17250.0,
    "t_end": 17280.0,
    "text": "We can approve\nthe applicants request here. Now, let's move on and watch out\nfor the second category where the person\nis actually earning from 15 to 35 thousand dollars\nright now here the person may or may not pay back. So in such scenarios will look\nfor the credit history as to what has been\nhis previous history. Now if his previous\nhistory has been bad like he has been a default ER\nin the previous transactions will definitely not Consider\napproving his request and he will be",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17275.0,
    "t_end": 17305.0,
    "text": "like he has been a default ER\nin the previous transactions will definitely not Consider\napproving his request and he will be at the high risk in which\nis not good for the bank. If the previous history of that particular\napplicant is really good. Then we will just to clarify a doubt will consider\nanother parameter as well that will be on depth. I have his already\nin really high dip then the risks again increases\nand there are chances that he might not pay\nrepay in the future.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17300.0,
    "t_end": 17330.0,
    "text": "the risks again increases\nand there are chances that he might not pay\nrepay in the future. So here Will. Not accept the request\nof the person having high dipped if the person is\nin the low depth and he has been a good pair\nin his past history. Then there are chances that he might be back\nand we can consider approving the request\nof this particular applicant. Alex look at the third category, which is a person earning\nfrom 0 to 15 thousand dollars.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17325.0,
    "t_end": 17355.0,
    "text": "Alex look at the third category, which is a person earning\nfrom 0 to 15 thousand dollars. Now, this is something\nwhich actually raises I broke and this person\nwill actually lie in the category of high risk. All right. So the probability is that his application of loan\nwould probably get rejected now, we'll get one final outcome from\nthis income parameter, right? Now let us look\nat our second variable that is H which will lead\ninto the second decision tree.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17350.0,
    "t_end": 17380.0,
    "text": "we'll get one final outcome from\nthis income parameter, right? Now let us look\nat our second variable that is H which will lead\ninto the second decision tree. Now. Let us say\nif the person is Young, right? So now we will look forward to\nif it is a student now if it is a student then\nthe chances are high that he won't be\nable to repay back because he has\nno earning Source, right? So here the risks are too high\nand probability is that his application\nof loan will get rejected fine. Now if the person is Young",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17375.0,
    "t_end": 17405.0,
    "text": "So here the risks are too high\nand probability is that his application\nof loan will get rejected fine. Now if the person is Young and his Not the student\nthen we'll probably go on and look for another variable. That is pan balance. Now. Let's look if the bank balance\nis less than 5 lakhs. So again the risk arises\nand the probabilities that his application\nof loan will get rejected. Now if the person\nis Young is not a student and his bank balance so of greater than 5 lakhs\nis got a pretty good",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17400.0,
    "t_end": 17430.0,
    "text": "Now if the person\nis Young is not a student and his bank balance so of greater than 5 lakhs\nis got a pretty good and stable and balanced\nthen the probability is that he is sort of application will get approved of Now\nlet us take another scenario if he's a senior, right? So if he is a senior\nwill probably go and check out for this credit history. How well has he been\nin his previous transactions? What kind of a person he is like whether he's a defaulter\nor is Ananda falter. Now if he is a very\nfair kind of person",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17425.0,
    "t_end": 17455.0,
    "text": "What kind of a person he is like whether he's a defaulter\nor is Ananda falter. Now if he is a very\nfair kind of person in his previous transactions\nthen again the risk arises and the probability\nof his application getting rejected actually\nincreases right now if he has An excellent person as per his transactions\nin the previous history. So now again here\nthere is least risk and the probabilities that his application\nof loan will get approved. So now here these two variables\nincome and age have led",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17450.0,
    "t_end": 17480.0,
    "text": "and the probabilities that his application\nof loan will get approved. So now here these two variables\nincome and age have led to two different decision trees. Right and these two different\ndecision trees actually led to two different results. Now what random forest does is\nit will actually compile these two different results\nfrom these two different. Gentry's and then finally, it will lead\nto a final outcome. That is how random\nForest actually works. Right? So that is actually the motive\nof the random Forest.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17475.0,
    "t_end": 17505.0,
    "text": "it will lead\nto a final outcome. That is how random\nForest actually works. Right? So that is actually the motive\nof the random Forest. Now let us move forward and see\nwhat is random Forest right? You can get an idea of the mechanism from the name\nitself random forests. So a collection\nof trees is a fortress that's why I called\nfor is probably and here also the trees are actually\nbecause being trained on subsets which are being\nselected at random. And therefore they are called\nrandom forests So Random forests",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17500.0,
    "t_end": 17530.0,
    "text": "also the trees are actually\nbecause being trained on subsets which are being\nselected at random. And therefore they are called\nrandom forests So Random forests is a collection or an insane. Humble of decision trees right\nhere decision trees actually built using the whole data\nset considering all features, but actually in random Forest\nonly a fraction of the number of rows is selected and that too at random and a particular\nnumber of features, which are actually selected\nat random are trained",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17525.0,
    "t_end": 17555.0,
    "text": "of rows is selected and that too at random and a particular\nnumber of features, which are actually selected\nat random are trained upon and that is how the decision trees\nare built upon. Right? So similarly number\nof decision trees will be grown and each decision tree will Salt\ninto a certain final outcome and random Forest\nwill do nothing but actually just\ncompiled the results of all those decision trees\nto bring up the final result. As you can see\nin this particular figure that a particular instance\nactually has resulted",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17550.0,
    "t_end": 17580.0,
    "text": "of all those decision trees\nto bring up the final result. As you can see\nin this particular figure that a particular instance\nactually has resulted into three different\ndecision trees, right? So not tree one results into\na final outcome called Class A and tree to results into class B. Similarly tree\nthree results into class P So Random Forest will compile the results\nof all these Decision trees and it will go by the call\nof the majority voting now since head to decision trees\nhave actually voted into the favor of the Class B\nthat is decision tree 2 and 3.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17575.0,
    "t_end": 17605.0,
    "text": "and it will go by the call\nof the majority voting now since head to decision trees\nhave actually voted into the favor of the Class B\nthat is decision tree 2 and 3. Therefore the final outcome will\nbe in the favor of the Class B. And that is how random\nForest actually works upon. Now one really beautiful thing about\nthis particular algorithm is that it is one\nof the versatile algorithms which is capable of Performing\nboth regression as well as Now, let's try to understand\nrandom Forest further",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17600.0,
    "t_end": 17630.0,
    "text": "which is capable of Performing\nboth regression as well as Now, let's try to understand\nrandom Forest further with a very beautiful example\nor this is my favorite one. So let's say you want to decide if you want to watch edge\nof tomorrow or not, right? So in this particular scenario, you will have two different\nactions to work Bond either. You can just straight away go to your best friend\nasked him about. All right, whether should I go for Edge\nof Tomorrow not will I",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17625.0,
    "t_end": 17655.0,
    "text": "You can just straight away go to your best friend\nasked him about. All right, whether should I go for Edge\nof Tomorrow not will I like this movie or you\ncan ask Your friends and take their opinion\nconsideration and then based on the final results who can go out and watch Edge\nof Tomorrow, right? So now let's just take\nthe first scenario. So where you go\nto your best friend asked about whether you should go\nout to watch edge of tomorrow or not. So your friend will probably\nask you certain questions",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17650.0,
    "t_end": 17680.0,
    "text": "whether you should go\nout to watch edge of tomorrow or not. So your friend will probably\nask you certain questions like the first one being\nhere Jonah So so let's say your friend asks you if you really like\nThe Adventurous kind of movies or not. So you say yes, definitely I would love to watch\nit Venture kind of movie. So the probabilities that you will like edge\nof tomorrow as well. Since Age of Tomorrow is\nalso a movie of Adventure and sci-fi kind\nof Journal right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17675.0,
    "t_end": 17705.0,
    "text": "that you will like edge\nof tomorrow as well. Since Age of Tomorrow is\nalso a movie of Adventure and sci-fi kind\nof Journal right? So let's say you do not like\nthe adventure John a movie. So then again\nthe probability reduces that you might really\nnot like edge of Morrow right. So from here you can come\nto a certain conclusion right? Let's say your best friend puts\nyou into another situation where he'll ask you or a do you like Emily Blunt\nand you see definitely",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17700.0,
    "t_end": 17730.0,
    "text": "where he'll ask you or a do you like Emily Blunt\nand you see definitely I like Emily Blunt and then he\nputs another question to you. Do you like Emily Blunt\nto be in the main lead and you say yes, then again, the probability arises that you will definitely\nlike edge of tomorrow as well because Edge of Tomorrow\nis Has the Emily plant in the main lead cast so and if you say oh I do not like\nEmily Blunt then again, the probability reduces",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17725.0,
    "t_end": 17755.0,
    "text": "and if you say oh I do not like\nEmily Blunt then again, the probability reduces that you would like Edge\nof Tomorrow to write. So this is one way where you have one decision tree\nand your final outcome. Your final decision will be\nbased on your one decision tree, or you can see your final\noutcome will be based on just one friend. No, definitely not\nreally convinced. You want to consider the options\nof your other friends also so that you can make\nvery precise and crisp",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17750.0,
    "t_end": 17780.0,
    "text": "No, definitely not\nreally convinced. You want to consider the options\nof your other friends also so that you can make\nvery precise and crisp decision right you go out and you approach some other\nbunch of friends of yours. So now let's say you go\nto three of your friends and you ask them\nthe same question whether I would like to watch\nit off tomorrow or not. So you go out and approach three or four friends friend\none friend twin friend three. Now, you will consider\neach of their Sport and then you will your decision\nnow will be dependent",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17775.0,
    "t_end": 17805.0,
    "text": "three or four friends friend\none friend twin friend three. Now, you will consider\neach of their Sport and then you will your decision\nnow will be dependent on the compiled results of all\nof your three friends, right? Now here, let's say you go\nto your first friend and you ask him whether you would like\nto watch it just tomorrow not and your first friend\nputs you to one question. Did you like Top Gun? And you say yes, definitely I did like the movie\nTop Gun then the probabilities that you would like\nedge of tomorrow as",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17800.0,
    "t_end": 17830.0,
    "text": "And you say yes, definitely I did like the movie\nTop Gun then the probabilities that you would like\nedge of tomorrow as well because topgun is actually\na military action drama, which is also Tom Cruise. So now again the probability\nRises that yes, you will like edge\nof tomorrow as well and If you say no I didn't like\nTop Gun then again. The chances are that you wouldn't like Edge\nof Tomorrow, right? And then another question\nthat he puts you across is that do you really like\nto watch action movies? And you say yes,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17825.0,
    "t_end": 17855.0,
    "text": "And then another question\nthat he puts you across is that do you really like\nto watch action movies? And you say yes, I would love to watch\nthem that again. The chances are that you would like\nto watch Edge of Tomorrow. So from your friend when you can come\nto one conclusion now here since the ratio of liking the movie\nto don't like is actually 2 is to 1 so the final\nresult is Actually, you would like Edge of Tomorrow. Now you go to your second friend\nand you ask the same question. So now you are second friend\nasks you did you like far",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17850.0,
    "t_end": 17880.0,
    "text": "Now you go to your second friend\nand you ask the same question. So now you are second friend\nasks you did you like far and away when we went\nout and did the last time when we washed it and you say no I really\ndidn't like far and away then you would say then\nyou are definitely going to like Edge of Tomorrow. Why does so because far\nand away is actually since most of whom\nmight not be knowing it so far in a ways Johner of romance and it revolves around a girl and a guy By falling in love\nwith each other and so on.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17875.0,
    "t_end": 17905.0,
    "text": "and it revolves around a girl and a guy By falling in love\nwith each other and so on. So the probability is that you wouldn't like\nedge of tomorrow. So he ask you another question. Did you like Bolivian and to really like\nto watch Tom Cruise? And you say Yes, again. The probability is that you would like\nto watch Edge of Tomorrow. Why because Oblivion\nagain is a science fiction casting Tom Cruise full\nof strange experiences. And where Tom Cruise is\nthe savior of the masses.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17900.0,
    "t_end": 17930.0,
    "text": "Why because Oblivion\nagain is a science fiction casting Tom Cruise full\nof strange experiences. And where Tom Cruise is\nthe savior of the masses. Kind well, that is the same kind of plot\nin edge of tomorrow as well. So here it is pure yes that you would like\nto watch edge of tomorrow. So you get another second decision\nfrom your second friend. Now you go to your third\nfriend and ask him so probably our third friend is\nnot really interesting in having any sort\nof conversation with you say,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17925.0,
    "t_end": 17955.0,
    "text": "probably our third friend is\nnot really interesting in having any sort\nof conversation with you say, it just simply asks you did you\nlike Godzilla and you said no I didn't like Godzilla's we said definitely\nyou wouldn't like it's of tomorrow why so because Godzilla is also\nactually sign Fiction movie from the adventure Jonah. So now you have got\nthree results from three different decision trees\nfrom three different friends. Now you compile the results\nof all those friends",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17950.0,
    "t_end": 17980.0,
    "text": "three different decision trees\nfrom three different friends. Now you compile the results\nof all those friends and then you make\na final call that yes, would you like to watch edge\nof tomorrow or not? So this is some very real time\nand very interesting example where you can actually\nImplement random Forest into ground reality right\nany questions so far. So far, no, that's good, and then\nwe can move forward. Now let us look\nat various domains",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 17975.0,
    "t_end": 18005.0,
    "text": "that's good, and then\nwe can move forward. Now let us look\nat various domains where random Forest\nis actually used. So because of its diversity\nrandom Forest is actually used in various diverse to means like so beat banking beat medicine beat land use\nbeat marketing name it and random Forest is there so\nin banking particularly random Forest is being\nactually used to make it out whether the applicant\nwill be a default a pair",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18000.0,
    "t_end": 18030.0,
    "text": "and random Forest is there so\nin banking particularly random Forest is being\nactually used to make it out whether the applicant\nwill be a default a pair or it Will be non default of 1 so that it can accordingly approve or reject\nthe applications of loan, right? So that is how random Forest\nis being used in banking talking about medicine. Random. Forest is widely used in medicine field\nto predict beforehand. What is the probability if a person will actually have\na particular disease or not? Right? So it's actually used to look\nat the various disease Trends.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18025.0,
    "t_end": 18055.0,
    "text": "What is the probability if a person will actually have\na particular disease or not? Right? So it's actually used to look\nat the various disease Trends. Let's say you want to figure\nout what is the probability that a person\nwill have diabetes? Not and so what would you do? It'd probably look\nat the medical history of the patient and then\nyou will see or read. This has been\nthe glucose concentration. What was the BMI? What was the insulin levels in the patient in the past\nprevious three months. What is the age\nof this particular person",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18050.0,
    "t_end": 18080.0,
    "text": "What was the BMI? What was the insulin levels in the patient in the past\nprevious three months. What is the age\nof this particular person and will make a different\ndecision trees based on each one of these predictor variables and then you'll finally\ncompiled the results of all those variables\nand then you'll make a fine. Final decision as to whether the person\nwill have diabetes in the near future or not. That is how random\nForest will be used in medicine sector now move. Random Forest is also actually\nused to find out the land use.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18075.0,
    "t_end": 18105.0,
    "text": "That is how random\nForest will be used in medicine sector now move. Random Forest is also actually\nused to find out the land use. For example, I want to set\nup a particular industry in certain area. So what would I probably\nlook for a look for? What is the\nvegetation over there? What is the Urban\npopulation over there? Right and how much is the Is\nfrom the nearest modes of Transport like\nfrom the bus station or the railway station\nand accordingly. I will split my parameters",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18100.0,
    "t_end": 18130.0,
    "text": "of Transport like\nfrom the bus station or the railway station\nand accordingly. I will split my parameters and I will make decision\non each one of these parameters and finally I'll compile\nmy decision of all these parameters in that\nwill be my final outcome. So that is how I\nam finally going to predict whether I should put my industry at this particular\nlocation or not. Right? So these three examples\nhave actually been of majorly around classification problem",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18125.0,
    "t_end": 18155.0,
    "text": "So these three examples\nhave actually been of majorly around classification problem because we are\ntrying to classify whether or not we're actually\ntrying to answer this question whether or not right now, let's move forward and look how marketing is revolving\naround random Forest. So particularly in marketing we try to identify\nthe customer churn. So this is particularly\nthe regression kind of problem right now how let's see so customer churn is nothing but actually\nthe number of people",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18150.0,
    "t_end": 18180.0,
    "text": "So this is particularly\nthe regression kind of problem right now how let's see so customer churn is nothing but actually\nthe number of people which are actually\nThe number of customers who are losing out. So we're going\nout of your market. Now you want to identify what will be your customer churn\nin near future. So you'll most of them eCommerce Industries are\nactually using this like Amazon Flipkart Etc. So they particularly look\nat your each Behavior as to what has been your past history. What has been\nyour purchasing history.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18175.0,
    "t_end": 18205.0,
    "text": "So they particularly look\nat your each Behavior as to what has been your past history. What has been\nyour purchasing history. What do you like\nbased on your activity around certain things around\ncertain ads around certain? Discounts or around certain kind\nof materials right? If you like a particular top\nyour activity will be more around that particular top. So that is how they track each\nand every particular move of yours and then\nthey try to predict whether you will be\nmoving out or not. So that is how they identify\nthe customer churn.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18200.0,
    "t_end": 18230.0,
    "text": "So that is how they track each\nand every particular move of yours and then\nthey try to predict whether you will be\nmoving out or not. So that is how they identify\nthe customer churn. So these all are various domains where random Forest\nis used and this is not the only list so there\nare numerous other examples which are Chile are using random forests that makes\nit so special actually. Now, let's move\nforward and see how random Forest actually works. Right. So let us start with the random\nForest algorithm first.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18225.0,
    "t_end": 18255.0,
    "text": "Now, let's move\nforward and see how random Forest actually works. Right. So let us start with the random\nForest algorithm first. Let's just see it step by step as to how random\nForest algorithm works. So the first step is\nto actually select certain M features from T. Where m is less than T. So here T is the total number\nof the predictor variables that you have in your data set and out of\nthose total predictor variables. You will select some randomly\nsome Features out of those now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18250.0,
    "t_end": 18280.0,
    "text": "in your data set and out of\nthose total predictor variables. You will select some randomly\nsome Features out of those now why we are actually selecting\na few features only. The reason is that if you will select all\nthe predictive variables or the total predictor variables\nthen each of your decision tree will be same. So the model is not actually\nlearning something new. It is learning\nthe same previous thing because all those decision trees\nwill be similar, right if you actually split\nyour predicted variables and you select randomly\na few predicted variables only.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18275.0,
    "t_end": 18305.0,
    "text": "because all those decision trees\nwill be similar, right if you actually split\nyour predicted variables and you select randomly\na few predicted variables only. Let's say there are 14 total\nnumber of variables and out of those you randomly\npick just three right? So every time you will get\na new decision tree, so there will be variety. Right? So the classification model\nwill be actually much more intelligent\nthan the previous one. Now. It has got\nbarrier to experiences. So definitely it will make\ndifferent decisions each time.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18300.0,
    "t_end": 18330.0,
    "text": "much more intelligent\nthan the previous one. Now. It has got\nbarrier to experiences. So definitely it will make\ndifferent decisions each time. And then when you will compile\nall those different decisions, it will be a new more accurate. An efficient result right? So the first important step\nis to select certain number of features out of all\nthe features now, let's move on to\nthe second step. Let's say for any node D. Now. The first step is to calculate\nthe best plate at that point.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18325.0,
    "t_end": 18355.0,
    "text": "Let's say for any node D. Now. The first step is to calculate\nthe best plate at that point. So, you know that decision tree how decision trees\nactually implemented so you pick up a the most\nsignificant variable right? And then you will split\nthat particular node into Other child nodes that is how the split\ntakes place, right? So you will do it\nfor M number of variables that you have selected. Let's say you\nhave selected three so you will implement\nthe split at all.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18350.0,
    "t_end": 18380.0,
    "text": "that you have selected. Let's say you\nhave selected three so you will implement\nthe split at all. Those three nodes\nin one particular decision tree, right the third step\nis split up the node into two daughter nodes. So now you can split\nyour root note into as many notes as you want to put hair\nwill split our node into 2.2 notes as to this or that so it will be an answer\nin terms of You saw that right? Our fourth step will be\nto repeat all these 3 steps that we've done previously",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18375.0,
    "t_end": 18405.0,
    "text": "or that so it will be an answer\nin terms of You saw that right? Our fourth step will be\nto repeat all these 3 steps that we've done previously and we'll repeat\nall this splitting until we have reached all\nthe N number of nodes. Right? So we need to repeat until we have reached\ntill the leaf nodes of a decision tree. That is how we will do it right\nnow after these four steps. We will have\nour one decision tree. But random Forest is\nactually about multiple. Asian trees. So here our fifth step\nwill come into the picture",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18400.0,
    "t_end": 18430.0,
    "text": "We will have\nour one decision tree. But random Forest is\nactually about multiple. Asian trees. So here our fifth step\nwill come into the picture which will actually repeat\nall these previous steps for D number of times now\nhit these the D number of decision trees. Let's say I want to implement\nfive decision trees. So my first step will be to implement all\nthe previous steps 5 times. So the head the eye tration is\n4/5 number of times right now. Once I have created these five decision trees still\nmy task is not complete yet.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18425.0,
    "t_end": 18455.0,
    "text": "So the head the eye tration is\n4/5 number of times right now. Once I have created these five decision trees still\nmy task is not complete yet. On my final task will be\nto compile the results of all these five\ndifferent decision trees and I will make a call in the majority\nvoting right here. As you can see in this picture. I had in different instances. Then I created\nn different decision trees. And finally I will compile\nthe result of all these n",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18450.0,
    "t_end": 18480.0,
    "text": "Then I created\nn different decision trees. And finally I will compile\nthe result of all these n different decision trees and I will take my call\non the majority voting right. So whatever my\nmajority vote says that will be My final result. So this is basically an overview\nof the random Forest algorithm how it actually works. Let's just have a look\nat this example to get much better understanding\nof what we have learnt. So let's say I have\nthis data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18475.0,
    "t_end": 18505.0,
    "text": "much better understanding\nof what we have learnt. So let's say I have\nthis data set which consists of four\ndifferent instances, right? So basically it consists\nof the weather information of previous 14 days right\nfrom D1 tildy 14, and this basically\nOutlook humidity and wind is Click gives me\nthe better condition of those 14 days. And finally I have play which is my target variable\nweather match did take place on that particular day\nor not right. Now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18500.0,
    "t_end": 18530.0,
    "text": "which is my target variable\nweather match did take place on that particular day\nor not right. Now. My main goal is to find out whether the match\nwill actually take place if I have following\nthese weather conditions with me on any particular day. Let's say the Outlook\nis rainy that day and humidity is high\nand the wind is very weak. So now I need to predict whether I will be able\nto play in the match. That they are not. All right. So this is\na problem statement fine. Now, let's see how random Forest\nis used in this to sort it out.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18525.0,
    "t_end": 18555.0,
    "text": "All right. So this is\na problem statement fine. Now, let's see how random Forest\nis used in this to sort it out. Now here the first step\nis to actually split my entire data set\ninto subsets here. I have split my entire\n14 variables into further smaller subsets right\nnow these subsets may or may not overlap like there is certain\noverlapping between d 1 till D3 and D3 till D6 fine. Is an overlapping of D3",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18550.0,
    "t_end": 18580.0,
    "text": "like there is certain\noverlapping between d 1 till D3 and D3 till D6 fine. Is an overlapping of D3 so it might happen\nthat there might be overlapping so you need not really worry\nabout the overlapping but you have to make sure that all those subsets are\nactually different right? So here I have taken\nthree different subsets my first subset consists of D1 till D3 Mexican subset\nconsists of D3 till D6 and methods subset\nconsists of D7 tildy. Now now I will first be focusing\non my first upset now here,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18575.0,
    "t_end": 18605.0,
    "text": "till D6 and methods subset\nconsists of D7 tildy. Now now I will first be focusing\non my first upset now here, let's say that particular day the Outlook was\nOvercast fine if yes, it was overcast\nthen the probabilities that the match will take place. So overcast is basically\nwhen your weather is too cloudy. So if that is the condition\nthen definitely the match will take place and let's say\nit wasn't overcast. Then you will consider these\nsecond most probable option that will be the wind",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18600.0,
    "t_end": 18630.0,
    "text": "will take place and let's say\nit wasn't overcast. Then you will consider these\nsecond most probable option that will be the wind and you will make\na decision based on this now whether wind was weak or strong\nif wind was weak, then you will definitely\ngo out and play them. Judge as you would not so\nnow the final outcome out of this decision\ntree will be Play Because here the ratio\nbetween the play and no play is to is to 1 so we get to a certain decision\nfrom a first decision tree. Now, let us look\nat the second subset now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18625.0,
    "t_end": 18655.0,
    "text": "so we get to a certain decision\nfrom a first decision tree. Now, let us look\nat the second subset now since second subset has\ndifferent number of variables. So that is why this decision\ntrees absolutely different from what we saw in our four subsets. So let's say if it was overcast\nthen you will play the match if It isn't the overcast\nin you would go and look out for humidity. Now further. It will get split into two\nwhether it was high or normal. Now, we'll take the first case if the humidity was high\nand when it was week,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18650.0,
    "t_end": 18680.0,
    "text": "It will get split into two\nwhether it was high or normal. Now, we'll take the first case if the humidity was high\nand when it was week, then you will play\nthe match else if humidity was high\nbut wind was too strong, then you would not go out\nand play the match right now. Let us look at the second dot\nto node of humidity if the humidity was normal. The wind was weak. Then you will definitely go out\nand play the match as you want go out\nand play the match. So here if you look\nat the final result,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18675.0,
    "t_end": 18705.0,
    "text": "Then you will definitely go out\nand play the match as you want go out\nand play the match. So here if you look\nat the final result, then the ratio of placed no play\nis 3 is to 2 then again. The final outcome\nis actually play, right? So from second subset, we get the final\ndecision of play now, let us look at our third subset which consists of D7\ntill D9 here if again the overcast is yes,\nthen you will play a match. Each else you will go\nand check out for humidity.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18700.0,
    "t_end": 18730.0,
    "text": "if again the overcast is yes,\nthen you will play a match. Each else you will go\nand check out for humidity. And if the humidity is\nreally high then you won't play the match else. You will play the match\nagain the probability of playing the matches. Yes, because the ratio\nof no play is Twist one, right? So three different subsets\nthree different decision trees three different outcomes and one final outcome\nafter compiling all the results from these three different\ndecision trees are so I This",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18725.0,
    "t_end": 18755.0,
    "text": "three different outcomes and one final outcome\nafter compiling all the results from these three different\ndecision trees are so I This gives a better perspective\nbetter understanding of random Forest like\nhow it really works. All right. So now let's just have a look at various features\nof random Forest Ray. So the first\nand the foremost feature is that it is one of the most accurate\nlearning algorithms, right? So why it is so because single decision trees\nare actually prone",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18750.0,
    "t_end": 18780.0,
    "text": "of the most accurate\nlearning algorithms, right? So why it is so because single decision trees\nare actually prone to having high variance or Hive bias and on\nthe contrary actually. M4s, it averages\nthe entire variance across the decision trees. So let's say if the variances say\nX4 decision tree, but for random Forest, let's say we have\nimplemented n number of decision trees parallely.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18775.0,
    "t_end": 18805.0,
    "text": "but for random Forest, let's say we have\nimplemented n number of decision trees parallely. So my entire variance\ngets averaged to upon and my final variance\nactually becomes X upon n so that is how the entire variance\nactually goes down as compared to other algorithms. Now second most\nimportant feature is that it works well\nfor both classification and regression problems and by far I have come\nacross this is one and the only algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18800.0,
    "t_end": 18830.0,
    "text": "and regression problems and by far I have come\nacross this is one and the only algorithm which works equally\nwell for both of them these classification kind\nof problem or a regression kind of problem, right? Then it's really runs efficient\non large databases. So basically it's\nreally scalable. Even if you work for\nthe lesser amount of database or if you work for a really\nhuge volume of data, right? So that's a very\ngood part about it. Then the fourth most\nimportant point is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18825.0,
    "t_end": 18855.0,
    "text": "or if you work for a really\nhuge volume of data, right? So that's a very\ngood part about it. Then the fourth most\nimportant point is that it requires almost\nno input preparation. Now, why am I saying this is because it has got\ncertain implicit methods, which actually take care\nand All the outliers and all the missing data and you really don't have to\ntake care about all that thing while you are in the stages\nof input preparations. So Random Forest is\nall here to take care",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18850.0,
    "t_end": 18880.0,
    "text": "and you really don't have to\ntake care about all that thing while you are in the stages\nof input preparations. So Random Forest is\nall here to take care of everything else and next. Is it performs implicit\nfeature selection, right? So while we are implementing\nmultiple decision trees, so it has got implicit method which will automatically pick\nup some random features out. Of all your parameters\nand then it will go on and implementing\ndifferent decision trees. So for example, if you just give\none simple command",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18875.0,
    "t_end": 18905.0,
    "text": "Of all your parameters\nand then it will go on and implementing\ndifferent decision trees. So for example, if you just give\none simple command that all right, I want to implement\n500 decision trees no matter how so Random Forest\nwill automatically take care and it will Implement all\nthose 500 decision trees and those all 500 decision trees\nwill be different from each other and this is because it has\ngot implicit methods which will automatically\ncollect different parameters. Out of all the variables\nthat you have right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18900.0,
    "t_end": 18930.0,
    "text": "which will automatically\ncollect different parameters. Out of all the variables\nthat you have right? Then it can be easily grown\nin parallel why it is so because we are actually implementing multiple\ndecision trees and all those decision trees are running or all those decisions\ntrees are actually getting implemented parallely. So if you say I want thousand\ntrees to be implemented. So all those thousand trees are\ngetting implemented parallely.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18925.0,
    "t_end": 18955.0,
    "text": "So if you say I want thousand\ntrees to be implemented. So all those thousand trees are\ngetting implemented parallely. So that is how the computation\ntime reduces down. Right, and the last point is that it has got methods\nfor balancing error in unbalanced it as it's now what exactly\nunbalanced data sets are let me just give\nyou an example of that. So let's say you're working\non a data set fine and you create a random\nforest model and get 90% accuracy immediately.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18950.0,
    "t_end": 18980.0,
    "text": "So let's say you're working\non a data set fine and you create a random\nforest model and get 90% accuracy immediately. Fantastic you think right. So now you start diving\ndeep you go a little deeper. And you discovered that 90% of that data actually\nbelongs to just one class damn your entire data set. Your entire decision\nis actually biased to just one particular class. So Random Forest actually\ntakes care of this thing",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 18975.0,
    "t_end": 19005.0,
    "text": "to just one particular class. So Random Forest actually\ntakes care of this thing and it is really not biased towards any particular decision\ntree or any particular variable or any class. So it has got methods\nwhich looks after it and they does is all the balance\nof errors in your data sets. So that's pretty much about the features\nof random forests.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19000.0,
    "t_end": 19030.0,
    "text": "about the features\nof random forests. What is KNN algorithm will K. Nearest neighbor\nis a simple algorithm that stores all\nthe available cases and classify the new data or case based\non a similarity measure. It suggests that if you are similar\nto your neighbors, then you are one of them, right? For example, if apple looks more similar\nto banana orange or Melon. Rather than a monkey rat or a cat then most likely Apple\nbelong to the group of fruits. All right. Well in general Cayenne is used\nin Search application",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19025.0,
    "t_end": 19055.0,
    "text": "or a cat then most likely Apple\nbelong to the group of fruits. All right. Well in general Cayenne is used\nin Search application where you are looking\nfor similar items that is when your task is\nsome form of fine items similar to this one. Then you call this search\nas a Cayenne search. But what is this KN KN? Well this K denotes the number\nof nearest neighbor which are voting class\nof the new data or the testing data. For example, if k equal 1 then the testing\ndata are given the same label as a close this Ample\nin the training set similarly",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19050.0,
    "t_end": 19080.0,
    "text": "if k equal 1 then the testing\ndata are given the same label as a close this Ample\nin the training set similarly if k equal to 3 the labels of the three closes classes\nare checked and the most common label is assigned\nto then testing data. So this is what a KN KN algorithm means\nso moving on ahead. Let's see some\nof the example of scenarios where KN is used\nin the industry. So, let's see\nthe industrial application of KNN algorithm starting\nwith recommender system. Well the biggest use case of cayenne and search\nis a recommender system. This recommended system is\nlike an automated form",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19075.0,
    "t_end": 19105.0,
    "text": "of KNN algorithm starting\nwith recommender system. Well the biggest use case of cayenne and search\nis a recommender system. This recommended system is\nlike an automated form of a shop counter guy when you\nasked him for a product. Not only shows you the product but also suggest you or displays\nyour relevant set of products, which are related to the item. You're already interested\nin buying this KNN algorithm applies to recommending\nproducts like an Amazon or for recommending media, like in case of Netflix or even\nfor recommending advertisement to display to a user if I'm not wrong almost all\nof you must have used Amazon for shopping, right? So just to tell you more\nthan 35% of amazon.com revenue",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19100.0,
    "t_end": 19130.0,
    "text": "to display to a user if I'm not wrong almost all\nof you must have used Amazon for shopping, right? So just to tell you more\nthan 35% of amazon.com revenue is generated by\nits recommendation engine. So what's their\nstrategy Amazon uses? Recommendation as\na targeted marketing tool in both the email campaigns around most of its website Pages Amazon will\nrecommend many products from different categories based\non what you have browser and it will pull those products\nin front of you which you are likely to buy like the frequently\nbought together option that comes at the bottom\nof the product page to tempt you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19125.0,
    "t_end": 19155.0,
    "text": "and it will pull those products\nin front of you which you are likely to buy like the frequently\nbought together option that comes at the bottom\nof the product page to tempt you into buying the combo. Well, this recommendation\nhas just one main goal that is increase average\norder value or to upsell and cross-sell customers\nby providing product suggestion based on items\nin the shopping cart, or On the product they are\ncurrently looking at on site. So next industrial\napplication of KNN algorithm is concept search or searching semantically\nsimilar documents and classifying documents\ncontaining similar topics.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19150.0,
    "t_end": 19180.0,
    "text": "or searching semantically\nsimilar documents and classifying documents\ncontaining similar topics. So as you know, the data on the Internet\nis increasing exponentially every single second. There are billions and billions\nof documents on the internet each document on the internet\ncontains multiple Concepts, that could be\na potential concept. Now, this is a situation where the main problem\nis to extract concept from a set of documents as each page could have\nthousands of combination that could be potential Concepts\nan average document could have millions of concept combined",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19175.0,
    "t_end": 19205.0,
    "text": "as each page could have\nthousands of combination that could be potential Concepts\nan average document could have millions of concept combined that the vast amount\nof data on the web. Well, we are talking\nabout an enormous amount of data set and Sample. So what we need is we need\nto find the concept from the enormous amount\nof data set and samples, right? So for this purpose, we'll be using KNN\nalgorithm more advanced example could include handwriting\ndetection like an OCR or image recognization\nor even video recognization. All right. So now that you know\nvarious use cases",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19200.0,
    "t_end": 19230.0,
    "text": "or image recognization\nor even video recognization. All right. So now that you know\nvarious use cases of KNN algorithm, let's proceed and see\nhow does it work. So how does\na KNN algorithm work? Let's start by plotting\nthese blue and orange point on our graph. So these Blue Points\nthe belong to class A and the orange ones\nthey belong to class B. Now you get a star as a new pony\nand your task is to predict whether this new point\nit belongs to class A or it belongs to the class B. So to start the production,\nthe very first thing that you have to do is\nselect the value of K,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19225.0,
    "t_end": 19255.0,
    "text": "whether this new point\nit belongs to class A or it belongs to the class B. So to start the production,\nthe very first thing that you have to do is\nselect the value of K, just as I told you KN KN\nalgorithm refers to the number of nearest neighbors that you\nwant to select for example, in this case k equal to 3. So what does it mean it means that I am selecting three points which are the least distance\nto the new point or you can say I am selecting\nthree different points which are closest to the star. Well at this point\nof time you can ask how will you calculate\nthe least distance? So once you\ncalculate the distance,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19250.0,
    "t_end": 19280.0,
    "text": "which are closest to the star. Well at this point\nof time you can ask how will you calculate\nthe least distance? So once you\ncalculate the distance, you will get one blue\nand two orange points which are closest to this star\nnow since in this case as we have a majority\nof Inch point so you can see that for k equal 3D star\nbelongs to the class B, or you can say that the star is more similar\nto the orange points moving on ahead. Well, what if k equal\nto 6 well for this case, you have to look\nfor six different points which are closest to this star. So in this case\nafter calculating the distance,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19275.0,
    "t_end": 19305.0,
    "text": "Well, what if k equal\nto 6 well for this case, you have to look\nfor six different points which are closest to this star. So in this case\nafter calculating the distance, we find that we have\nfour blue points and two Orange Point which are closest\nto the star now, as you can see that the blue points are\nin majority so you can say that for k equals\n6 this star belongs. These two class A or the star\nis more similar to Blue Points. So by now, I guess you know\nhow a KNN algorithm work. And what is the significance\nof gain KNN algorithm. So how will you\nchoose the value of K? So keeping in mind this case\nthe most important parameter",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19300.0,
    "t_end": 19330.0,
    "text": "And what is the significance\nof gain KNN algorithm. So how will you\nchoose the value of K? So keeping in mind this case\nthe most important parameter in KNN algorithm. So, let's see when you build\na k nearest neighbor classifier. How will you choose\na value of K? Well, you might have\na specific value of K in mind or you could divide up\nyour data and use something like cross-validation technique\nto test several values of K in order to determine which works best for your data. Example if n equal\n2,000 cases then in that case the optimal value\nof K lies somewhere in between 1 to 19. But yes, unless you try it\nyou cannot be sure of it.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19325.0,
    "t_end": 19355.0,
    "text": "Example if n equal\n2,000 cases then in that case the optimal value\nof K lies somewhere in between 1 to 19. But yes, unless you try it\nyou cannot be sure of it. So, you know how the algorithm\nis working on a higher level. Let's move on and see how things are predicted\nusing KNN algorithm. Remember I told you the KNN algorithm uses\nthe least distance measure in order to find\nits nearest neighbors. So let's see\nhow these distances calculated. Well, there are\nseveral distance measure which can be used. So to start with Will mainly\nfocus on euclidean distance in Manhattan distance\nin this session.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19350.0,
    "t_end": 19380.0,
    "text": "which can be used. So to start with Will mainly\nfocus on euclidean distance in Manhattan distance\nin this session. So what is\nthis euclidean distance? Well, this euclidean distance\nis defined as the square root of the sum of difference\nbetween a new point x and an existing Point why so for example here we\nhave Point P1 and P2 Point P. 1 is 1 1 and point B 2 is 5 for so what is the euclidean\ndistance between both of them? So you can say\nthat euclidean distance is a direct distance\nbetween two points. So what is the distance\nbetween the point P1 and P2?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19375.0,
    "t_end": 19405.0,
    "text": "So you can say\nthat euclidean distance is a direct distance\nbetween two points. So what is the distance\nbetween the point P1 and P2? So we Calculate it as\n5 minus 1 whole square plus 4 minus 1 whole square and we can route it\nover which results to 5. So next is\nthe Manhattan distance. Well, this Manhattan distance is\nused to calculate the distance between real Vector using the sum of their absolute\ndifference in this case. The Manhattan distance\nbetween the point P1 and P2 is mod of 5 minus 1\nplus mod value of 4 minus 1,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19400.0,
    "t_end": 19430.0,
    "text": "the sum of their absolute\ndifference in this case. The Manhattan distance\nbetween the point P1 and P2 is mod of 5 minus 1\nplus mod value of 4 minus 1, which results to 3 plus 4. That is 7. So this slide shows\nthe difference between euclidean and Manhattan distance\nfrom point A to point B. So euclidean distance is\nnothing but the direct or the least possible distance\nbetween A and B. Whereas the Manhattan distance\nis a distance between A and B measured along the axis\nat right angle. Let's take an example and see how things are predicted\nusing KNN algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19425.0,
    "t_end": 19455.0,
    "text": "and B measured along the axis\nat right angle. Let's take an example and see how things are predicted\nusing KNN algorithm or how the cannon\nalgorithm is working suppose. We have data set\nwhich consists of height weight and T-shirt size\nof some customers. Now when a new customer\ncome we only have is height. And wait as the information\nnow our task is to predict. What is the T-shirt size\nof that particular customer? So for this will be using\nthe KNN algorithm. So the very first thing\nwhat we need to do, we need to calculate\nthe euclidean distance.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19450.0,
    "t_end": 19480.0,
    "text": "So for this will be using\nthe KNN algorithm. So the very first thing\nwhat we need to do, we need to calculate\nthe euclidean distance. So now that you have a new data\nof height 160 one centimeter and weight as 61 kg. So the very first thing that we'll do is we'll calculate\nthe euclidean distance, which is nothing\nbut the square root of 160 1 minus 158 whole square plus 61 minus 58 whole square\nand square root of that is 4.24. Let's drag and drop it. So these are the various\neuclidean distance of other points. Now, let's suppose k equal\nto 5 then the algorithm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19475.0,
    "t_end": 19505.0,
    "text": "So these are the various\neuclidean distance of other points. Now, let's suppose k equal\nto 5 then the algorithm what it does is it searches\nfor the five customer closest to the new customer that is most similar\nto the new data in terms of its attribute for k equal 5. Let's find the top five\nminimum euclidian distance. So these are the distance which we are going\nto use one two, three, four and five. So let's rank them\nin the order first. This is second. This is third then this one\nis Forward and again, this one is five. So there's our order.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19500.0,
    "t_end": 19530.0,
    "text": "This is third then this one\nis Forward and again, this one is five. So there's our order. So for k equal 5 we\nhave for t-shirts which come under size\nM and one t-shirt which comes under size l so obviously best guess\nfor the best prediction for the T-shirt size of white\n161 centimeters and wait 60 1 kg is M. Or you can say\nthat a new customer fit into size M. Well this was all\nabout the theoretical session. But before we drill down\nto the coding part, let me just tell you why people\ncall KN as a lazy learner.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19525.0,
    "t_end": 19555.0,
    "text": "But before we drill down\nto the coding part, let me just tell you why people\ncall KN as a lazy learner. Well KN for classification. Ocean is a very\nsimple algorithm. But that's not why they are\ncalled lazy KN is a lazy learner because it doesn't have\na discriminative function from the training data. But what it does it\nmemorizes the training data, there is no learning phase\nof the model and all of the work happens at the time. Your prediction is requested. So as such there's the reason\nwhy KN is often referred to us lazy learning algorithm. So this was all about\nthe theoretical session now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19550.0,
    "t_end": 19580.0,
    "text": "So as such there's the reason\nwhy KN is often referred to us lazy learning algorithm. So this was all about\nthe theoretical session now, let's move on\nto the coding part. So for the Practical implementation of\nthe Hands-On part, I'll be using\nthe artists data set so This data set consists\nof 150 observation. We have four features and one class label\nthe four features include the sepal length sepal width\npetal length and the petrol head whereas the class label\ndecides which flower belongs to which category. So this was the description\nof the data set, which we are using now, let's move on and see\nwhat are the step by step solution\nto perform a KNN algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19575.0,
    "t_end": 19605.0,
    "text": "So this was the description\nof the data set, which we are using now, let's move on and see\nwhat are the step by step solution\nto perform a KNN algorithm. So first, we'll start\nby handling the data what we have to do we\nhave to open the data set from the CSV format and split the data set\ninto train and test part next. We'll take the Clarity where we\nhave to calculate the distance between two data instances. Once we calculate the distance\nnext we'll look for the neighbor and select K Neighbors which are having the least\ndistance from a new point. Now once we get our neighbor, then we'll generate a response\nfrom a set of data instances.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19600.0,
    "t_end": 19630.0,
    "text": "which are having the least\ndistance from a new point. Now once we get our neighbor, then we'll generate a response\nfrom a set of data instances. So this will decide whether the new Point belongs\nto class A or Class B. Finally will create\nthe accuracy function and in the end. We'll tie it all together\nin the main function. So let's start with our code for implementing KNN\nalgorithm using python. I'll be using Java. Old book by Don\n3.0 installed on it. Now. Let's move on and see how can an algorithm\ncan be implemented using python. So there's my jupyter notebook, which is a web-based interactive\nComputing notebook environment",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19625.0,
    "t_end": 19655.0,
    "text": "Let's move on and see how can an algorithm\ncan be implemented using python. So there's my jupyter notebook, which is a web-based interactive\nComputing notebook environment with python 3.0 installed on it. So the launch its launching so\nthere's our jupyter notebook and we'll be riding\nour python codes on it. So the first thing that we need to do is\nload our file our data is in CSV format\nwithout a header line or any code we can open\nthe file the open function and read the data line\nusing the reader function. In the CSV module. So let's write a code\nto load our data file.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19650.0,
    "t_end": 19680.0,
    "text": "and read the data line\nusing the reader function. In the CSV module. So let's write a code\nto load our data file. Let's execute the Run button. So once you execute\nthe Run button, you can see the entire training\ndata set as the output next. We need to split the data\ninto a training data set that KN can use to make\nprediction and a test data set that we can use to evaluate\nthe accuracy of the model. So we first need to convert\nthe flower measure that will load it as\nstring into numbers that we can work next. We need to split the data set\nrandomly to train and test.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19675.0,
    "t_end": 19705.0,
    "text": "that will load it as\nstring into numbers that we can work next. We need to split the data set\nrandomly to train and test. Ratio 67's 233 for test is\nto train as a standard ratio, which is used for this purpose. So let's define a function as load data set that loads a CSV\nwith the provided file named and split it\nrandomly into training and test data set using\nthe provided split ratio. So this is our function load\ndata set which is using filename split ratio training data set and testing data\nset as its input. All right. So let's execute the Run button\nand check for any errors.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19700.0,
    "t_end": 19730.0,
    "text": "and testing data\nset as its input. All right. So let's execute the Run button\nand check for any errors. So it's executed\nwith zero errors. Let's test this function. So there's our training\nset testing set load data set. So this is our function\nload data set on inside that we are passing. Our file is data\nwith a split ratio of 0.66 and training data set\nand test data set. Let's see what our training data\nset and test data set. It's dividing into so\nit's giving a count of training data set\nand testing data set. The total number\nof training data set as split into is\n97 and total number",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19725.0,
    "t_end": 19755.0,
    "text": "of training data set\nand testing data set. The total number\nof training data set as split into is\n97 and total number of test data set we have is 53. So total number of training data\nset we have here is 97 and total number of test data\nset we have here is 53. All right. Okay, so Function load\ndata set is performing. Well, so let's move\non to step two which is similarity. So in order to make prediction, we need to calculate\nthe similarity between any two given data instances. This is needed so that we can locate the kamo\nsimilar data instances in the training data set are\nin turn make a prediction given",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19750.0,
    "t_end": 19780.0,
    "text": "any two given data instances. This is needed so that we can locate the kamo\nsimilar data instances in the training data set are\nin turn make a prediction given that all for flower measurement\nare numeric and have same unit. We can directly use\nthe euclidean distance measure. This is nothing\nbut the square root of the sum of squared differences\nbetween two areas of the number given that all the for flower\nAre numeric and have same unit we can directly use\nthe euclidean distance measure which is nothing\nbut the square root of the sum of squared difference\nbetween two areas or the number additionally\nwe want to control",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19775.0,
    "t_end": 19805.0,
    "text": "which is nothing\nbut the square root of the sum of squared difference\nbetween two areas or the number additionally\nwe want to control which field to include\nin the distance calculation. So specifically we only want\nto include first for attribute. So our approach will be\nto limit the euclidean distance to a fixed length. All right. So let's define\nour euclidean function. So this are euclidean\ndistance function which takes instance\none instance to and length as parameters instance 1 and ends. These two are the two points of which you want to calculate\nthe euclidean distance, whereas this length and denote",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19800.0,
    "t_end": 19830.0,
    "text": "These two are the two points of which you want to calculate\nthe euclidean distance, whereas this length and denote that how many attributes\nyou want to include? Okay. So there's our\neuclidean function. Let's execute it. It's executing fine\nwithout any errors. Let's test the function\nsuppose the data one or the first instance consists\nof the data point has two to two and it belongs to class A and data to consist\nof four for four and it belongs to class P. So when we calculate\nthe euclidean distance of data one to data to and what we have to do we\nhave to consider only",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19825.0,
    "t_end": 19855.0,
    "text": "So when we calculate\nthe euclidean distance of data one to data to and what we have to do we\nhave to consider only first three features of them. All right. So let's print the distance\nas you can see here. The distance comes\nout to be three point four six four now like\nso this is nothing but the square root\nof 4 minus 2 whole Square. So this distance is nothing\nbut the euclidean distance and it is calculated as square\nroot of 4 minus 2 whole square plus 4 minus 2 whole square that is nothing but 3\ntimes of 4 minus 2 whole square that is 12 + square root of 12 is nothing\nbut 3.46 for all right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19850.0,
    "t_end": 19880.0,
    "text": "that is nothing but 3\ntimes of 4 minus 2 whole square that is 12 + square root of 12 is nothing\nbut 3.46 for all right. So now that we have calculated\nthe distance now we need to look for K nearest. Neighbors now that we\nhave a similarity measure we can use it to collect\nthe kamo similar instances for a given unseen instance. Well, this is\na straightforward process of calculating the distance\nfor all the instances and selecting a subset with\nthe smallest distance value. And now what we have\nto do we have to select the smallest distance values. So for that will be\ndefining a function as get neighbors. So for that what we will be doing\nwill be defining a function",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19875.0,
    "t_end": 19905.0,
    "text": "the smallest distance values. So for that will be\ndefining a function as get neighbors. So for that what we will be doing\nwill be defining a function as get neighbors what it will do it will return\nthe K most similar Neighbors From the training set\nfor a given test instance. All right, so this is\nhow our get neighbors In look like it takes training data set and test instance\nand K as its input here. The K is nothing but the number of nearest neighbor\nyou want to check for. All right. So basically what\nyou'll be getting from this get Mabel's\nfunction is K different points having least euclidean distance\nfrom the test instance.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19900.0,
    "t_end": 19930.0,
    "text": "So basically what\nyou'll be getting from this get Mabel's\nfunction is K different points having least euclidean distance\nfrom the test instance. All right, let's execute it. So the function executed\nwithout any errors. So let's test our function. So suppose the training data set\nincludes the data like to to to and it belongs to class A and other data includes\nfour four four and it belongs to class P and at testing\nand Census 555 or now, we have to predict whether this test instance\nbelongs to class A or it belongs to class be. All right for k equal 1\nwe have to predict its nearest neighbor and predict",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19925.0,
    "t_end": 19955.0,
    "text": "or it belongs to class be. All right for k equal 1\nwe have to predict its nearest neighbor and predict whether this test instance\nit will belong to class A or will it belong to class be? Alright. So let's execute the Run button. All right. So an executing\nthe Run button you can see that we have output\nas for for for and be a new instance 5 5 5 is closes 2.44\nfor which belongs to class be. All right. Now once you have located\nthe most similar neighbor for a test instance next task\nis to predict a response based on those neighbors. So how we can do that. Well, we can do this",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19950.0,
    "t_end": 19980.0,
    "text": "for a test instance next task\nis to predict a response based on those neighbors. So how we can do that. Well, we can do this by allowing each neighbor\nto vote for the class attribute and take the majority vote\nas a prediction. Let's see how we can do that. So we are function as getresponse with takes\nneighbors as the input. Well, this neighbor was nothing\nbut the output of this get me / function the output of get me were function\nwill be fed to get response. All right. Let's execute the Run button. It's executed. Let's move ahead and test\nour function get response. So we have a But as bun bun\nbun it belongs to class",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 19975.0,
    "t_end": 20005.0,
    "text": "Let's execute the Run button. It's executed. Let's move ahead and test\nour function get response. So we have a But as bun bun\nbun it belongs to class A 2 2 2 it belongs to class a33. It belongs to class B. So this response,\nthat's what it will do. It will store the value\nof get response by passing this neighbor value. I like so what we want\nto check is we want to predict whether that test instance\nfinal outcome will belongs to class A or Class B. When the neighbors are\n1 1 1 a 2 2 A + 3 3 B. So, let's check our response.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20000.0,
    "t_end": 20030.0,
    "text": "When the neighbors are\n1 1 1 a 2 2 A + 3 3 B. So, let's check our response. Now that we have created\nall the different function which are required\nfor a KNN algorithm. So important main concern is how do you evaluate\nthe accuracy of the prediction and easy way to evaluate the accuracy of the model\nis to calculate a ratio of the total correct prediction\nto all the protection made. So for this I will\nbe defining function as get accuracy and inside that I'll be passing\nmy test data set and the predictions get\naccuracy function check get executed without any error.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20025.0,
    "t_end": 20055.0,
    "text": "that I'll be passing\nmy test data set and the predictions get\naccuracy function check get executed without any error. Let's check it\nfor a sample data set. So we have our test data set as\n1 1 1 It belongs to class A 2/2 which again belongs to class\n3 3 3 which belongs to class B and my predictions is\nfor first test data. It predicted latter belongs\nto class A which is true for next it predicted\nthat belongs to class C, which is again to and for\nthe next again and predictive that it belongs to class A\nwhich is false in this case cause the test data\nbelongs to class be.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20050.0,
    "t_end": 20080.0,
    "text": "which is again to and for\nthe next again and predictive that it belongs to class A\nwhich is false in this case cause the test data\nbelongs to class be. All right. So in total we have to correct\nprediction out of three. All right, so the ratio\nwill be 2 by 3, which is nothing but 66.6. So our accuracy rate is 66.6. It's so now that you\nhave created all the function that are required\nfor KNN algorithm. Let's compile them\ninto one single main function. Alright, so this is\nour main function and we are using Iris data set with a split of 0.67 and\nthe value of K is 3 Let's see.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20075.0,
    "t_end": 20105.0,
    "text": "and we are using Iris data set with a split of 0.67 and\nthe value of K is 3 Let's see. What is the accuracy score\nof this check how accurate are modulus so\nin training data set, we have a hundred\nand thirteen values and then the test data set. We have 37 values. These are the predicted and the actual values\nof the output. Okay. So in total we got\nan accuracy of 90s. In point two nine percent,\nwhich is really very good. Alright, so I hope the concept\nof this KNN algorithm is here device in a world\nfull of machine learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20100.0,
    "t_end": 20130.0,
    "text": "Alright, so I hope the concept\nof this KNN algorithm is here device in a world\nfull of machine learning and artificial intelligence\nsurrounding almost everything around us classification and prediction is one of the most important aspects\nof machine learning. So before moving forward, let's have a quick look\nat the agenda. I'll start off this video\nby explaining you guys what exactly is Nave biased then we'll and what\nis Bayes theorem which serves as a logic behind the name pass\nalgorithm going forward.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20125.0,
    "t_end": 20155.0,
    "text": "then we'll and what\nis Bayes theorem which serves as a logic behind the name pass\nalgorithm going forward. I'll explain the steps involved in the neighbors\nalgorithm one by one and finally add finish\nof this video with a demo on the Nave bass using\nthe SQL own package noun a bass is a simple but\nsurprisingly powerful algorithm from penetrative analysis. It is a classification technique\nbased on base theorem with an assumption of\nIndependence among predictors. It comprises of two parts,\nwhich is name.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20150.0,
    "t_end": 20180.0,
    "text": "with an assumption of\nIndependence among predictors. It comprises of two parts,\nwhich is name. And bias in simple terms\nneighbors classifier assumes that the presence\nof a particular feature in a class is unrelated\nto the presence of any other feature, even if this features\ndepend on each other or upon the existence\nof the other features, all of these properties\nindependently contribute to the probability whether a fruit is an apple\nor an orange or a banana. So that is why it is known as naive now naive\nbased model is easy to build",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20175.0,
    "t_end": 20205.0,
    "text": "whether a fruit is an apple\nor an orange or a banana. So that is why it is known as naive now naive\nbased model is easy to build and particularly useful\nfor very large data sets. In probability Theory\nand statistics based theorem, which is already\nknown as the base law or the base rule describes\nthe probability of an event based on prior knowledge\nof the conditions that might be related\nto the event now paste theorem is a way to figure\nout conditional probability. The conditional probability\nis the probability",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20200.0,
    "t_end": 20230.0,
    "text": "theorem is a way to figure\nout conditional probability. The conditional probability\nis the probability of an event happening given that it has some relationship\nto one or more other events. For example, your probability\nof getting a parking space is connected to the time\nof the day you pass. Where you park and what conventions are you\ngoing on at that time based Serum is slightly\nmore nuanced in a nutshell. It gives you an actual\nprobability of an event given information about the tests. Now, if you look\nat the definition",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20225.0,
    "t_end": 20255.0,
    "text": "It gives you an actual\nprobability of an event given information about the tests. Now, if you look\nat the definition of Bayes theorem, we can see\nthat given a hypothesis H and the evidence\ne-base term states that the relationship between the\nprobability of the hypothesis before getting the evidence which is the P of H\nand the probability of the hypothesis\nafter getting the evidence that P of H given e\nis defined as probability of e given H into probability of H divided by probability of e\nit's rather confusing, right?",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20250.0,
    "t_end": 20280.0,
    "text": "of e given H into probability of H divided by probability of e\nit's rather confusing, right? So let's take an example\nto understand this theorem. So suppose I have\na deck of cards and if a single card is drawn\nfrom the deck of playing cards, the probability that the card\nis a king is for by 52 since there are four Kings\nin a standard deck of 52 cards. Now if King is an event,\nthis card is a king. The probability of King\nis given as 4 by 52",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20275.0,
    "t_end": 20305.0,
    "text": "Now if King is an event,\nthis card is a king. The probability of King\nis given as 4 by 52 that is equal to 1 by 13. Now if the evidence is provided\nfor instance someone looks as the That the single card\nis a face card the probability of King given that it's a face\ncan be calculated using the base theorem\nby this formula. The since every King\nis also a face card the probability of face given that it's a king is equal to 1 and since there are\nthree face cards in each suit.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20300.0,
    "t_end": 20330.0,
    "text": "the probability of face given that it's a king is equal to 1 and since there are\nthree face cards in each suit. That is the chat king and queen. The probability of the face card\nis equal to 12 by 52. That is 3 by 30. Now using Bayes theorem we\ncan find out the probability of King given that it's a face so our final answer\ncomes to 1 by 3, which is also true. So if you have a deck of cards which has having only faces now\nthere are three types of phases",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20325.0,
    "t_end": 20355.0,
    "text": "which is also true. So if you have a deck of cards which has having only faces now\nthere are three types of phases which are the chat king\nand queen so the probability that it's the king is 1 by 3. Now. This is the simple example\nof how based on works now if we look at the proof as in\nhow this Bayes theorem Evolved. So here we have\nprobability of a given p and probability of B\ngiven a now for a joint probability distribution\nover the sets A and B,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20350.0,
    "t_end": 20380.0,
    "text": "and probability of B\ngiven a now for a joint probability distribution\nover the sets A and B, the probability of\na intersection B, the conditional probability\nof a given B is defined as the probability of a intersection B divided\nby probability of B, and similarly probability of B, given a is defined as\nprobability of B intersection a divided by probability\nof a now we can Equate probability of\na intersection p and probability of B intersection a as\nboth are the same thing now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20375.0,
    "t_end": 20405.0,
    "text": "Equate probability of\na intersection p and probability of B intersection a as\nboth are the same thing now from this method as you can see, we get our final\nbase theorem proof, which is the probability of a\ngiven b equals probability of B, given a into probability of P divided by\nthe probability of a now while this is the equation that applies to\nany probability distribution over the events A and B. It has a particular nice\ninterpretation in case where a is represented\nas the hypothesis h",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20400.0,
    "t_end": 20430.0,
    "text": "It has a particular nice\ninterpretation in case where a is represented\nas the hypothesis h and B is represented as some observed evidence e\nin that case the formula is p of H given e is equal to P of e given H into probability of H divided\nby probability of e now this relates the probability of hypotheses before\ngetting the evidence, which is p of H\nto the probability of the hypothesis\nafter getting the evidence which is p of H given e",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20425.0,
    "t_end": 20455.0,
    "text": "which is p of H\nto the probability of the hypothesis\nafter getting the evidence which is p of H given e for this reason P of H is known\nas the prior probability while P of Each given e is known\nas the posterior probability and the factor that relates the two is known as\nthe likelihood ratio Now using this term space theorem\ncan be rephrased as the posterior\nprobability equals. The prior probability\ntimes the likelihood ratio. So now that we know the maths",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20450.0,
    "t_end": 20480.0,
    "text": "So now that we know the maths which is involved\nbehind the baster. Mm. Let's see how we can implement\nthis in real life scenario. So suppose we have a data set. In which we have\nthe Outlook the humidity and we need to find out whether we should play\nor not on that day. So the Outlook can be\nsunny overcast rain and the humidity high normal and the wind are categorized\ninto two phases which are the weak\nand the strong winds.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20475.0,
    "t_end": 20505.0,
    "text": "and the humidity high normal and the wind are categorized\ninto two phases which are the weak\nand the strong winds. The first of all will create\na frequency table using each attribute of the data set. So the frequency table\nfor the Outlook looks like this we have Sunny overcast\nand rainy the frequency table of humidity looks like this and Frequency table of when\nlooks like this we have strong and weak for wind and high\nand normal ranges for humidity. So for each frequency table, we will generate\na likelihood table now now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20500.0,
    "t_end": 20530.0,
    "text": "and weak for wind and high\nand normal ranges for humidity. So for each frequency table, we will generate\na likelihood table now now the likelihood table\ncontains the probability of a particular day\nsuppose we take the sunny and we take the play as yes and no so the probability\nof Sunny given that we play yes is 3 by 10, which is 0.3 the\nprobability of X, which is the\nprobability of Sunny Is equal to 5 by 14 now, these are all the terms which are just generated\nfrom the data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20525.0,
    "t_end": 20555.0,
    "text": "Is equal to 5 by 14 now, these are all the terms which are just generated\nfrom the data which we have a and finally the probability\nof yes is 10 out of 14. So if we have a look\nat the likelihood of yes given that it's a sunny we\ncan see using Bayes theorem. It's the probability\nof Sunny given yes into probability of s divided\nby the probability of Sunny. So we have all\nthe values here calculated. So if you put\nthat in our base serum equation, we get the likelihood of yes.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20550.0,
    "t_end": 20580.0,
    "text": "So if you put\nthat in our base serum equation, we get the likelihood of yes. A 0.59 similarly the likelihood of no can also be calculated\nhere is 0.40 now similarly. We are going to create\nthe likelihood table for both the humidity and the win there's a for humidity the likelihood\nfor yes given the humidity is high is equal to 0.4\nto and the probability of playing know\ngiven the vent is high is 0.58.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20575.0,
    "t_end": 20605.0,
    "text": "is high is equal to 0.4\nto and the probability of playing know\ngiven the vent is high is 0.58. The similarly for table wind\nthe probability of he has given that the wind is week is 0.75\nand the probability of no given that the win is week is 0.25\nnow suppose we have of day which has high rain which has high humidity\nand the wind is weak. So should we play or not? That's our for that? We use the base theorem\nhere again the likelihood",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20600.0,
    "t_end": 20630.0,
    "text": "which has high humidity\nand the wind is weak. So should we play or not? That's our for that? We use the base theorem\nhere again the likelihood of yes on that day is equal to the probability\nof Outlook rain given that it's a yes into probability\nof Magic given that say yes, and the probability of\nwhen that is we given that it's we are playing yes\ninto the probability of yes, which equals to zero\npoint zero one nine and similarly the likelihood\nof know on that day is equal",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20625.0,
    "t_end": 20655.0,
    "text": "which equals to zero\npoint zero one nine and similarly the likelihood\nof know on that day is equal to zero point zero one six. Now if we look at the probability\nof yes for that day of playing we just\nneed to divide it with the likelihood\nsome of both the yes and no so the probability\nof playing tomorrow, which is yes is 5 whereas the probability\nof not playing is equal to 0.45. Now. This is based upon the data\nwhich we already have with us.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20650.0,
    "t_end": 20680.0,
    "text": "This is based upon the data\nwhich we already have with us. So now that you have an idea\nof what exactly is named bias how it works and we have seen how it can be implemented\non a particular data set. Let's see where it\nis used in the industry. The started with our first\nindustrial use case, which is news categorization\nor we can use the term text classification\nto broaden the spectrum of this algorithm news in the web are rapidly growing\nin the era of Information Age",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20675.0,
    "t_end": 20705.0,
    "text": "the term text classification\nto broaden the spectrum of this algorithm news in the web are rapidly growing\nin the era of Information Age where each new site has\nits own different layout and categorization\nfor grouping news. Now these heterogeneity of layout and categorization\ncannot always satisfy individual users need\nto remove these heterogeneity and classifying\nthe news articles. Owing to the user preference\nis a formidable task companies use web crawler\nto extract useful text",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20700.0,
    "t_end": 20730.0,
    "text": "Owing to the user preference\nis a formidable task companies use web crawler\nto extract useful text from HTML Pages\nthe news articles and each of these news articles is then tokenized now\nthese tokens are nothing but the categories\nof the news now in order to achieve\nbetter classification result. We remove the less\nsignificant Words, which are the stop was\nfrom the documents or the Articles and then we apply\nthe Nave base classifier for classifying the news\ncontents based on the news.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20725.0,
    "t_end": 20755.0,
    "text": "and then we apply\nthe Nave base classifier for classifying the news\ncontents based on the news. Now this is by far one of the best examples\nof Neighbors classifier, which is Spam filtering. Now. It's the Nave\nBayes classifier are a popular statistical technique\nfor email filtering. They typically use bag\nof words features to identify at the spam email and approach commonly used\nin text classification as well. Now it works by correlating\nthe use of tokens,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20750.0,
    "t_end": 20780.0,
    "text": "and approach commonly used\nin text classification as well. Now it works by correlating\nthe use of tokens, but the spam and non-spam emails\nand then the Bayes theorem, which I explained earlier is used to\ncalculate the probability that an email is or not a Spam so named\nby a Spam filtering is a baseline technique\nfor dealing with Spam that container itself to the emails need\nof an individual user and give low false positive\nspam detection rates that are generally\nacceptable to users.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20775.0,
    "t_end": 20805.0,
    "text": "to the emails need\nof an individual user and give low false positive\nspam detection rates that are generally\nacceptable to users. It is one of the oldest ways\nof doing spam filtering with its roots in the 1990s particular words\nhave particular probabilities of occurring in spam. And and legitimate email\nas well for instance. Most emails users will frequently encounter\nthe world lottery or the lucky draw a spam email, but we'll sell them\nsee it in other emails. The filter doesn't know\nthese probabilities in advance and must be friends.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20800.0,
    "t_end": 20830.0,
    "text": "but we'll sell them\nsee it in other emails. The filter doesn't know\nthese probabilities in advance and must be friends. So it can build them\nup to train the filter. The user must manually indicate whether a new email is Spam\nor not for all the words in each straining email. The filter will\nadjust the probability that each word will appear\nin a Spam or legitimate. Owl in the database now after training the word\nprobabilities also known as the likelihood functions are\nused to compute the probability that an email with a particular\nset of words as in in belongs",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20825.0,
    "t_end": 20855.0,
    "text": "as the likelihood functions are\nused to compute the probability that an email with a particular\nset of words as in in belongs to either category each word in the email contributes\nthe email spam probability. This contribution is called\nthe posterior probability and is computed again\nusing the base 0 then the email spam probability is computed over all\nthe verse in the email and if the total exceeds\na certain threshold say Or 95% the filter will Mark\nthe email as spam. Now object detection is\nthe process of finding instances",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20850.0,
    "t_end": 20880.0,
    "text": "Or 95% the filter will Mark\nthe email as spam. Now object detection is\nthe process of finding instances of real-world objects\nsuch as faces bicycles and buildings in images or video now object detection algorithm typically\nuse extracted features and learning algorithm to recognize instance of\nan object category here again, a bass plays an important\nrole of categorization and classification of object\nnow medical area. This is increasingly voluminous\namount of electronic data,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20875.0,
    "t_end": 20905.0,
    "text": "a bass plays an important\nrole of categorization and classification of object\nnow medical area. This is increasingly voluminous\namount of electronic data, which are becoming more\nand more complicated. The produced medical data\nhas certain characteristics that make the analysis\nvery challenging and attractive as well among all\nthe different approaches. The knave bias is used. It is the most effective\nand efficient classification algorithm and has\nbeen successfully applied to many medical problems\nempirical comparison",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20900.0,
    "t_end": 20930.0,
    "text": "algorithm and has\nbeen successfully applied to many medical problems\nempirical comparison of knave bias versus\nfive popular classifiers on Medical data sets shows that may bias is well suited\nfor medical application and has high performance in most\nof the examine medical problems. Now in the past various\ntesticle methods have been used for modeling in the area\nof disease diagnosis. These methods require\nprior assumptions and are less capable of dealing with massive and complicated\nnonlinear and dependent data one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20925.0,
    "t_end": 20955.0,
    "text": "for modeling in the area\nof disease diagnosis. These methods require\nprior assumptions and are less capable of dealing with massive and complicated\nnonlinear and dependent data one of the main advantages\nof neighbor as approach which is appealing\nto Physicians is that all the available\ninformation is used? To explain the decision\nthis explanation seems to be natural for medical\ndiagnosis and prognosis. That is it is very\nclose to the way how physician diagnosed patients\nnow weather is one of the most influential factor\nin our daily life to an extent that it may affect\nthe economy of a country",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20950.0,
    "t_end": 20980.0,
    "text": "how physician diagnosed patients\nnow weather is one of the most influential factor\nin our daily life to an extent that it may affect\nthe economy of a country that depends on occupation\nlike agriculture. Therefore as a countermeasure\nto reduce the damage caused by uncertainty\nin whether Behavior, there should be an efficient way\nto print the weather now whether projecting\nhas Challenging problem in the meteorological department since ears even\nafter the technology skill and scientific\nadvancement the accuracy and protection of weather\nhas never been sufficient even in current day this domain\nremains as a research topic",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 20975.0,
    "t_end": 21005.0,
    "text": "and scientific\nadvancement the accuracy and protection of weather\nhas never been sufficient even in current day this domain\nremains as a research topic in which scientists and mathematicians are working\nto produce a model or an algorithm that will accurately\npredict the weather now a bias in approach\nbased model is created by where posterior probabilities\nare used to calculate the likelihood of\neach class label for input. Data instance and the one\nwith the maximum likelihood is considered as the resulting\noutput now earlier.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21000.0,
    "t_end": 21030.0,
    "text": "Data instance and the one\nwith the maximum likelihood is considered as the resulting\noutput now earlier. We saw a small implementation\nof this algorithm as well where we predicted whether we should play\nor not based on the data, which we have collected earlier. Now, this is a python Library which is known as scikit-learn\nit helps to build in a bias and model in Python. Now, there are three types\nof named by ass model under scikit-learn Library. The first one is the caution. It is used in classification\nand it Assumes that the feature follow\na normal distribution.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21025.0,
    "t_end": 21055.0,
    "text": "under scikit-learn Library. The first one is the caution. It is used in classification\nand it Assumes that the feature follow\na normal distribution. The next we have is multinomial. It is used for discrete counts. For example, let's say we have\na text classification problem and here we\nconsider bernouli trials, which is one step further and instead of word\noccurring in the document. We have count how often word occurs in the document you\ncan think of it as a number of times\noutcomes number is observed in the given number of Trials.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21050.0,
    "t_end": 21080.0,
    "text": "in the document you\ncan think of it as a number of times\noutcomes number is observed in the given number of Trials. And finally we have\nthe bernouli type. Of neighbors. The binomial model is useful if your feature vectors are\nbinary bag of words model where the once and the zeros are words occur\nin the document and the verse which do not occur in the document respectively\nbased on their data set. You can choose any of\nthe given discussed model here, which is the gaussian\nthe multinomial or the bernouli.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21075.0,
    "t_end": 21105.0,
    "text": "You can choose any of\nthe given discussed model here, which is the gaussian\nthe multinomial or the bernouli. So let's understand\nhow this algorithm works. And what are\nthe different steps? One can take to create\na bison model and use knave bias to predict the output so\nhere to understand better. We are going to predict\nthe onset of diabetes Now this problem comprises of 768 observations\nof medical details for Pima Indian patients.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21100.0,
    "t_end": 21130.0,
    "text": "this problem comprises of 768 observations\nof medical details for Pima Indian patients. The record describes\ninstantaneous measurement taken from the patient such as\nthe age the number of times pregnant and the blood work crew now all\nthe patients are women aged 21 and Older and all\nthe attributes are numeric and the unit's vary\nfrom attribute to attribute. Each record has\na class value that indicate whether the patient suffered\non onset of diabetes",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21125.0,
    "t_end": 21155.0,
    "text": "and the unit's vary\nfrom attribute to attribute. Each record has\na class value that indicate whether the patient suffered\non onset of diabetes within five years\nare the measurements. Now. These are classified as 0 now. I've broken the whole process\ndown into the following steps. The first step\nis handling the data in which we load the data\nfrom the CSV file and split it into training and test it as it's the second step\nis summarizing the data. In which we summarize the properties in the training\ndata sets so that we can calculate the probabilities\nand make predictions.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21150.0,
    "t_end": 21180.0,
    "text": "In which we summarize the properties in the training\ndata sets so that we can calculate the probabilities\nand make predictions. Now the third step comes is\nmaking a particular prediction. We use the summaries of the data set to generate\na single prediction. And after that we generate\npredictions given a test data set and a summarized\ntraining data sets. And finally we evaluate the accuracy of the predictions\nmade for a test data set as the percentage correct\nout of all the predictions made and finally We tied\ntogether and form.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21175.0,
    "t_end": 21205.0,
    "text": "the accuracy of the predictions\nmade for a test data set as the percentage correct\nout of all the predictions made and finally We tied\ntogether and form. Our own model\nof nape is classifier. Now. The first thing we need to do\nis load our data the data is in the CSV format\nwithout a header line or any codes. We can open the file\nwith the open function and read the data lines\nusing the read functions in the CSV module. Now, we also need\nto convert the attributes that were loaded as\nstrings into numbers so that we can work with them. So let me show you",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21200.0,
    "t_end": 21230.0,
    "text": "Now, we also need\nto convert the attributes that were loaded as\nstrings into numbers so that we can work with them. So let me show you how this can be implemented now\nfor that you need to Tall python on a system and use\nthe jupyter notebook or the python shell. Hey, I'm using\nthe Anaconda Navigator which has all the things required to do\nthe programming in Python. We have the Jupiter lab. We have the notebook. We have the QT console. Even we have a studio as well. So what you need to do is just\ninstall the Anaconda Navigator",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21225.0,
    "t_end": 21255.0,
    "text": "We have the QT console. Even we have a studio as well. So what you need to do is just\ninstall the Anaconda Navigator it comes with the pre\ninstalled python also, so the moment you click launch\non The jupyter Notebook. It will take you\nto the Jupiter homepage in a local system and here you\ncan do programming in Python. So let me just rename it as\nby my India diabetes. So first, we need\nto load the data set.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21250.0,
    "t_end": 21280.0,
    "text": "So let me just rename it as\nby my India diabetes. So first, we need\nto load the data set. So I'm creating here a function\nload CSV now before that. We need to import\ncertain CSV the math and the random method. So as you can see, I've created a load CSV function which will take the pie\nmy Indian diabetes data dot CSV file using\nthe CSV dot read a method and then we are converting\nevery element of that data set into float originally all\nthe ants are in string,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21275.0,
    "t_end": 21305.0,
    "text": "and then we are converting\nevery element of that data set into float originally all\nthe ants are in string, but we need to convert\nthem into floor for all calculation purposes. The next we need to split\nthe data into training data sets that nay bias can use\nto make the prediction and this data set that we can use to evaluate\nthe accuracy of the model. We need to split the data\nset randomly into training and testing data set\nin the ratio of usually which is 7230.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21300.0,
    "t_end": 21330.0,
    "text": "We need to split the data\nset randomly into training and testing data set\nin the ratio of usually which is 7230. But for this example, I'm going to use 67 and 33 now 70 and 30 is a Ratio\nfor testing algorithms so you can play around\nwith this number. So this is our split\ndata set function. Now the Navy base\nmodel is comprised of summary of the data\nin the training data set. Now this summary is then used\nwhile making predictions. Now the summary\nof the training data",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21325.0,
    "t_end": 21355.0,
    "text": "of summary of the data\nin the training data set. Now this summary is then used\nwhile making predictions. Now the summary\nof the training data collected involves the mean\nthe standard deviation of each attribute\nby class value now, for example, if there are two class values\nand seven numerical attributes, then we need a mean and the standard deviation for\neach of these seven attributes and the class value which makes The 14\nattributes summaries so we can break the preparation of this summary down\ninto the following sub tasks which are the separating data\nby class calculating mean",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21350.0,
    "t_end": 21380.0,
    "text": "so we can break the preparation of this summary down\ninto the following sub tasks which are the separating data\nby class calculating mean calculating standard deviation\nsummarizing the data sets and summarizing\nattributes by class. So the first task is to separate the training data set\ninstances by class value so that we can calculate\nstatistics for each class. We can do that by creating a map of each class value\nto a list of instances that belong to the class. Class and sort the entire\ndataset of instances",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21375.0,
    "t_end": 21405.0,
    "text": "of each class value\nto a list of instances that belong to the class. Class and sort the entire\ndataset of instances into the appropriate list. Now the separate\nby class function just the same. So as you can see\nthe function assumes that the last attribute\nis the class value the function returns a map\nof class value to the list of data instances next. We need to calculate\nthe mean of each attribute for a class value. Now, the mean is the central middle or\nthe central tendency of the data and we use it as a middle\nof our gaussian distribution",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21400.0,
    "t_end": 21430.0,
    "text": "for a class value. Now, the mean is the central middle or\nthe central tendency of the data and we use it as a middle\nof our gaussian distribution when Calculating\nthe probabilities. So this is our function\nfor mean now. We also need to calculate\nthe standard deviation of each attribute\nfor a class value. The standard deviation\nis calculated as a square root of the variance and the variance\nis calculated as the average of the squared differences for each attribute value from the mean now\none thing to note that here is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21425.0,
    "t_end": 21455.0,
    "text": "of the squared differences for each attribute value from the mean now\none thing to note that here is that we are using\nn minus one method which subtracts one from the number\nof attributes values when calculating the variance. Now that we have the tools\nto summarize the data for a given list of instances. We can calculate the mean\nand standard deviation for each attribute. Now that's if function groups\nthe values for each attribute across our data instances\ninto their own lists so that we can compute the mean\nand standard deviation values",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21450.0,
    "t_end": 21480.0,
    "text": "across our data instances\ninto their own lists so that we can compute the mean\nand standard deviation values for each attribute. Now next comes the summarizing\nattributes by class. We can pull it all together\nby first separating. Our training data sets\ninto instances groped by class then calculating the summaries\nfor each a Should be now. We are ready to make predictions\nusing the summaries prepared from our training data making patients involved\ncalculating the probability that a given data instance\nbelong to each class then",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21475.0,
    "t_end": 21505.0,
    "text": "making patients involved\ncalculating the probability that a given data instance\nbelong to each class then selecting the class with the largest probability\nas a prediction. Now we can divide this whole\nmethod into four tasks which are the calculating\ngaussian probability density function calculating class\nprobability making a prediction and then estimating the accuracy now to calculate the gaussian\nprobability density function. We use the gaussian function\nto estimate the probability of a given attribute value\ngiven the node mean",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21500.0,
    "t_end": 21530.0,
    "text": "now to calculate the gaussian\nprobability density function. We use the gaussian function\nto estimate the probability of a given attribute value\ngiven the node mean and the standard deviation\nof the attribute estimated from the training data. As you can see\nthe parameters RX mean and the standard deviation now in the calculate\nprobability function, we calculate the exponent first\nthen calculate the main division this lets us fit the equation\nnicely into two lines. Now, the next task is calculating the\nclass properties now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21525.0,
    "t_end": 21555.0,
    "text": "this lets us fit the equation\nnicely into two lines. Now, the next task is calculating the\nclass properties now that we had can calculate\nthe probability of an attribute belonging to a class. We can combine the probabilities\nof all the attributes values for a data instance\nand come up with a probability of the entire. Our data instance\nbelonging to the class. So now that we have calculated\nthe class properties. It's time to finally make\nour first prediction now, we can calculate the probability\nof the data instance belong to each class value and we can look\nfor the largest probability",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21550.0,
    "t_end": 21580.0,
    "text": "we can calculate the probability\nof the data instance belong to each class value and we can look\nfor the largest probability and return the associated class and for that we are going\nto use this function predict which uses the summaries and the input Vector which is\nbasically all the probabilities which are being input\nfor a particular label now finally we can\nAn estimate the accuracy of the model\nby making predictions for each data instances\nin our test data for that. We use the get\npredictions method.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21575.0,
    "t_end": 21605.0,
    "text": "for each data instances\nin our test data for that. We use the get\npredictions method. Now this method is used to calculate the predictions\nbased upon the test data sets and the summary\nof the training data set. Now, the predictions\ncan be compared to the class values\nin our test data set and classification accuracy\ncan be calculated as an accuracy ratio\nbetween the zeros and the hundred percent. Now the get accuracy method will\ncalculate this accuracy ratio. Now finally to sum it all up. We Define our main function\nwe call all these methods",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21600.0,
    "t_end": 21630.0,
    "text": "Now the get accuracy method will\ncalculate this accuracy ratio. Now finally to sum it all up. We Define our main function\nwe call all these methods which we have defined\nearlier one by one to get the Courtesy of the model\nwhich we have created. So as you can see, this is our main function\nin which we have the file name. We have defined the split ratio. We have the data set. We have the training\nand test data set. We are using the split\ndata set method next. We are using the summarized\nby class function using the get protection and\nthe get accuracy method as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21625.0,
    "t_end": 21655.0,
    "text": "We are using the split\ndata set method next. We are using the summarized\nby class function using the get protection and\nthe get accuracy method as well. So guys as you can see\nthe output of this one gives us that we are splitting\nthe 768 Rose into 514 which is the training and 254 which is the test data set rows\nand the accuracy of this model is 68% Now we can play\nwith the amount of training and test data sets\nwhich are to be used so we can change\nthe split ratio to seventies.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21650.0,
    "t_end": 21680.0,
    "text": "is 68% Now we can play\nwith the amount of training and test data sets\nwhich are to be used so we can change\nthe split ratio to seventies. 238 is 220 to get\ndifferent sort of accuracy. So suppose I change\nthe split ratio from 0.67 20.8. So as you can see, we get the accuracy\nof 62 percent. So splitting it into 0.67\ngave us a better result which was 68 percent. So this is how you can Implement\nNavy bias caution classifier.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21675.0,
    "t_end": 21705.0,
    "text": "So splitting it into 0.67\ngave us a better result which was 68 percent. So this is how you can Implement\nNavy bias caution classifier. These are the step\nby step methods which you need to do in case of\nusing the Nave Bayes classifier, but don't worry. We do not need to write\nall this many lines of code to make a model\nthis with the second. And I really comes into picture\nthe scikit-learn library has a predefined method or as say a predefined\nfunction of nape bias,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21700.0,
    "t_end": 21730.0,
    "text": "And I really comes into picture\nthe scikit-learn library has a predefined method or as say a predefined\nfunction of nape bias, which converts all\nof these lines, of course into merely just\ntwo or three lines of codes. So, let me just open\nanother jupyter notebook. So let me name it\nas sklearn a pass. Now here we are going to use\nthe most famous data set which is the iris De Casa. Now, the iris flower data\nset is a multivariate",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21725.0,
    "t_end": 21755.0,
    "text": "Now here we are going to use\nthe most famous data set which is the iris De Casa. Now, the iris flower data\nset is a multivariate data set introduced by\nthe British statistician and biologists Roland Fisher and based on this fish is linear\ndiscriminant model this data set became a typical test case for many statistical\nclassification techniques in machine learning. So here we are going to use\nthe caution NB model, which is already available\nin the sklearn. As I mentioned earlier, there were three\ntypes of Neighbors",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21750.0,
    "t_end": 21780.0,
    "text": "which is already available\nin the sklearn. As I mentioned earlier, there were three\ntypes of Neighbors which are the question\nmultinomial and the bernouli. So here we are going to use\nthe caution and be model which is already present\nin the SK loan Library, which is the cycle in library. So first of all, what we need to do is\nimport the sklearn data sets and the metrics and we also need\nto import the caution NB Now once all these libraries are lowered we need\nto load the data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21775.0,
    "t_end": 21805.0,
    "text": "and the metrics and we also need\nto import the caution NB Now once all these libraries are lowered we need\nto load the data set which is the iris dataset. The next what we need\nto do is fit a Nave by a smaller to this data set. So as you can see we have so\neasily defined the model which is the gaussian\nNB which contains all the programming which I just showed you\nearlier all the methods which are taking the input\ncalculating the mean the standard deviation\nseparating it bike last and finally making predictions.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21800.0,
    "t_end": 21830.0,
    "text": "the standard deviation\nseparating it bike last and finally making predictions. Calculating the\nprediction accuracy. All of this comes\nunder the caution and be method which is inside already present\nin the sklearn library. We just need to fit it\naccording to the data set which we have so next if we print the model we see\nwhich is the gaussian NB model. The next what we need to do\nis make the predictions. So the expected output\nis data set dot Target and the projected\nis using the pretend model",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21825.0,
    "t_end": 21855.0,
    "text": "The next what we need to do\nis make the predictions. So the expected output\nis data set dot Target and the projected\nis using the pretend model and the model we are using\nis the cause in N be here. Now to summarize the model which created we calculate\nthe confusion Matrix and the classification report. So guys, as you can see\nthe classification to provide we have the Precision\nof Point Ninety Six, we have the recall of 0.96. We have the F1 score and the support and finally if\nwe print our confusion Matrix,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21850.0,
    "t_end": 21880.0,
    "text": "we have the recall of 0.96. We have the F1 score and the support and finally if\nwe print our confusion Matrix, as you can see it gives\nus this output. So as you can see\nusing the gaussian and we method just\nputting it in the model and using any of the data. fitting the model which you created\ninto a particular data set and getting the desired\noutput is so easy with the scikit-learn library as we Mo support\nVector machine is one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21875.0,
    "t_end": 21905.0,
    "text": "as we Mo support\nVector machine is one of the most effective\nmachine learning classifier and it has been used\nin various Fields such as face recognition\ncancer classification and so on today's session is dedicated to how svm works\nthe various features of svm and how it Is used\nin the real world. All right. Okay. Now let's move on and see\nwhat svm algorithm is all about. So guys s VM or support Vector machine is\na supervised learning algorithm,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21900.0,
    "t_end": 21930.0,
    "text": "Now let's move on and see\nwhat svm algorithm is all about. So guys s VM or support Vector machine is\na supervised learning algorithm, which is mainly used to classify\ndata into different classes now unlike most algorithms svm\nmakes use of a hyperplane which acts like\na decision boundary between the various classes in general svm can\nbe used to generate multiple separating hyperplanes so that the data\nis Divided into segments. Okay, and each of these segments will contain\nonly one kind of data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21925.0,
    "t_end": 21955.0,
    "text": "so that the data\nis Divided into segments. Okay, and each of these segments will contain\nonly one kind of data. It's mainly used for classification purpose\nwearing you want to classify or data into two different\nsegments depending on the features of the data. Now before moving any further, let's discuss a few\nfeatures of svm. Like I mentioned earlier svm is\na supervised learning algorithm. This means that svm trains on a set of labeled data svm\nstudies the label training data and then classifies\nany new input Data,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21950.0,
    "t_end": 21980.0,
    "text": "on a set of labeled data svm\nstudies the label training data and then classifies\nany new input Data, depending on what it learned in the training phase\na main advantage of support Vector machine is that it can be used\nfor both classification and regression problems. All right. Now even though svm is mainly\nknown for classification the svr which is the support\nVector regressor is used for regression problems. All right, so svm can be used\nboth for classification. And for regression. Now, this is one of the reasons\nwhy a lot of people prefer svm",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 21975.0,
    "t_end": 22005.0,
    "text": "for regression problems. All right, so svm can be used\nboth for classification. And for regression. Now, this is one of the reasons\nwhy a lot of people prefer svm because it's a very\ngood classifier and along That it is also\nused for regression. Okay. Another feature is the svm\nkernel functions svm can be used for classifying nonlinear data by using the kernel trick\nthe kernel trick basically means to transform your data\ninto another dimension so that you can easily\ndraw a hyperplane between the different\nclasses of the data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22000.0,
    "t_end": 22030.0,
    "text": "means to transform your data\ninto another dimension so that you can easily\ndraw a hyperplane between the different\nclasses of the data. Alright, nonlinear data\nis basically data which cannot be separated\nwith a straight line. Alright, so svm can even be used\non nonlinear data sets. You just have to use\na A kernel functions to do this. All right. So guys, I hope\nyou all are clear with the basic concepts of svm. Now, let's move on\nand look at how svm works so there's an order\nto understand how svm Works let's consider a small scenario\nnow for a second pretend",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22025.0,
    "t_end": 22055.0,
    "text": "so there's an order\nto understand how svm Works let's consider a small scenario\nnow for a second pretend that you own a firm. Okay, and let's say\nthat you have a problem and you want to set up a fence\nto protect your rabbits from the pack of wolves. Okay, but where do you build your films\none way to get around? The problem is to build\na classifier based. On the position of the rabbits\nand words in your pasture. So what I'm telling you is\nyou can classify the group of rabbits as one group and draw a decision\nboundary between the rabbits",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22050.0,
    "t_end": 22080.0,
    "text": "So what I'm telling you is\nyou can classify the group of rabbits as one group and draw a decision\nboundary between the rabbits and the world correct. So if I do that and if I try\nto draw a decision boundary between the rabbits\nand the Wolves, it looks something like this. Okay. Now you can clearly build\na fence along this line in simple terms. This is exactly how SPM work it draws\na decision boundary, which is a hyperplane between any New classes\nin order to separate them or classify them now. I know you're thinking\nhow do you know",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22075.0,
    "t_end": 22105.0,
    "text": "between any New classes\nin order to separate them or classify them now. I know you're thinking\nhow do you know where to draw a hyperplane the basic principle behind\nsvm is to draw a hyperplane that best separates\nthe two classes in our case the two glasses\nof the rabbits and the Wolves. So you start off by drawing\na random hyperplane and then you check the distance\nbetween the hyperplane and the closest data points from each Club these closes\non your is data points to the hyperplane are known\nas support vectors.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22100.0,
    "t_end": 22130.0,
    "text": "from each Club these closes\non your is data points to the hyperplane are known\nas support vectors. And that's where the name comes\nfrom support Vector machine. So basically the\nhyperplane is drawn based on these support vectors. So guys an optimal\nhyperplane will have a maximum distance from each\nof these support vectors. All right. So basically the hyperplane\nwhich has the maximum distance from the support vectors is\nthe most optimal hyperplane and this distance\nbetween the hyperplane and the support vectors\nis known as the margin.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22125.0,
    "t_end": 22155.0,
    "text": "from the support vectors is\nthe most optimal hyperplane and this distance\nbetween the hyperplane and the support vectors\nis known as the margin. All right, so to sum it up svm\nis used to classify data. By using a hyper plane such\nthat the distance between the hyperplane and\nthe support vectors is maximum. So basically your margin\nhas to be maximum. All right, that way, you know that you're actually\nseparating your classes or add because the distance between\nthe two classes is maximum. Okay. Now, let's try\nto solve a problem. Okay. So let's say that I input\na new data point.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22150.0,
    "t_end": 22180.0,
    "text": "because the distance between\nthe two classes is maximum. Okay. Now, let's try\nto solve a problem. Okay. So let's say that I input\na new data point. Okay. This is a new data point and now I want to draw\na hyper plane such that it best separates\nthe two classes. Okay, so I start off\nby drawing a hyperplane. Like this and then\nI check the distance between the hyperplane\nand the support vectors. Okay, so I'm trying to check if the margin is maximum\nfor this hyper plane, but what if I draw a hyperplane\nwhich is like this? All right. Now I'm going to check\nthe support vectors over here.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22175.0,
    "t_end": 22205.0,
    "text": "but what if I draw a hyperplane\nwhich is like this? All right. Now I'm going to check\nthe support vectors over here. Then I'm going\nto check the distance from the support vectors and for\nthis hyperplane, it's clear that the margin is more red. When you compare the margin\nof the previous one to this hyperplane. It is more. So the reason why I'm choosing\nthis hyperplane is because the Distance\nbetween the support vectors and the hyperplane is maximum\nin this scenario. Okay. So guys, this is\nhow you choose a hyperplane. You basically have to make sure that the hyper plane\nhas a maximum.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22200.0,
    "t_end": 22230.0,
    "text": "and the hyperplane is maximum\nin this scenario. Okay. So guys, this is\nhow you choose a hyperplane. You basically have to make sure that the hyper plane\nhas a maximum. Margin. All right, it has to best\nseparate the two classes. All right. Okay so far it was quite easy. Our data was linearly separable which means that you\ncould draw a straight line to separate the two classes. All right, but what will you do? If the data set is like this you possibly can't draw\na hyperplane like Is on it, it doesn't separate\nthe two classes at all. So what do you do in such situations now earlier\nin the session I mentioned",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22225.0,
    "t_end": 22255.0,
    "text": "you possibly can't draw\na hyperplane like Is on it, it doesn't separate\nthe two classes at all. So what do you do in such situations now earlier\nin the session I mentioned how a kernel can be used\nto transform data into another dimension that has a clear dividing margin\nbetween the classes of data. Alright, so kernel functions\noffer the user this option of transforming nonlinear spaces\ninto linear ones. Nonlinear data set is the one that you can't separate\nusing a straight line. All right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22250.0,
    "t_end": 22280.0,
    "text": "Nonlinear data set is the one that you can't separate\nusing a straight line. All right. In order to deal\nwith such data sets, you're going to transform them\ninto linear data sets and then use svm on them. Okay. So simple trick would be\nto transform the two variables X and Y into a new\nfeature space involving a new variable called Z. All right, so guys so far\nwe were plotting our data on two dimensional space. Correct? We will only using the X and the y axis so we had only\nthose two variables X and Y now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22275.0,
    "t_end": 22305.0,
    "text": "on two dimensional space. Correct? We will only using the X and the y axis so we had only\nthose two variables X and Y now in order to deal with this kind\nof data a simple trick. Be to transform\nthe two variables X and Y into a new feature space\ninvolving a new variable called Z. Okay, so we're basically\nvisualizing the data on a three-dimensional space. Now when you transform\nthe 2D space into a 3D space you can clearly see\na dividing margin between the two classes\nof data right now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22300.0,
    "t_end": 22330.0,
    "text": "Now when you transform\nthe 2D space into a 3D space you can clearly see\na dividing margin between the two classes\nof data right now. You can go ahead\nand separate the two classes by drawing the best\nhyperplane between them. Okay, that's exactly what we discussed\nin the previous slides. So guys, why don't you\ntry this yourself dried. Drawing a hyperplane, which is the most Optimum\nfor these two classes. All right, so guys, I hope you have\na good understanding about nonlinear svm's now. Let's look at a real\nworld use case if support Vector machines. So guys s VM as a classifier has been used\nin cancer classification",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22325.0,
    "t_end": 22355.0,
    "text": "Let's look at a real\nworld use case if support Vector machines. So guys s VM as a classifier has been used\nin cancer classification since the early 2000s. So there was an experiment held\nby a group of professionals who applied svm in a colon\ncancer tissue classification. So the data set\nconsisted of about Transmembrane protein samples and only about 50 to 200\ngenes samples were input Into the svm classifier Now this sample which was input into the svm classifier had\nboth colon cancer tissue samples",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22350.0,
    "t_end": 22380.0,
    "text": "and only about 50 to 200\ngenes samples were input Into the svm classifier Now this sample which was input into the svm classifier had\nboth colon cancer tissue samples and normal colon tissue\nsamples right now. The main objective of this study\nwas to classify Gene samples based on whether they\nare cancerous or not. Okay, so svm was trained\nusing the 50 to 200 samples in order to discriminate\nbetween non-tumor from A tumor specimens. So the performance of the svm classifier\nwas very accurate",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22375.0,
    "t_end": 22405.0,
    "text": "from A tumor specimens. So the performance of the svm classifier\nwas very accurate for even a small data set. All right, we had only\n50 to 200 samples and even for the small data set\nsvm was pretty accurate with this results. Not only that its\nperformance was compared to other classification\nalgorithms like naive Bayes and in each case svm\noutperform naive Bayes. So after this experiment\nit was clear that svm classified the data\nmore effectively and it worked exceptionally good.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22400.0,
    "t_end": 22430.0,
    "text": "So after this experiment\nit was clear that svm classified the data\nmore effectively and it worked exceptionally good. Small data sets. Let's go ahead and understand what exactly\nis unsupervised learning. So sometimes the given data\nis unstructured and unlabeled so it becomes difficult\nto classify the data into different categories. So unsupervised learning\nhelps to solve this problem. This learning is used\nto Cluster the input data and classes on the basis\nof their statistical properties.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22425.0,
    "t_end": 22455.0,
    "text": "So unsupervised learning\nhelps to solve this problem. This learning is used\nto Cluster the input data and classes on the basis\nof their statistical properties. So example, we can cluster Different Bikes based\nupon the speed limit there. Acceleration or the average that they are giving so and suppose learning is a type\nof machine learning algorithm used to draw inferences from beta sets consisting\nof input data without labeled responses. So if you have a look\nat the workflow or the process flow\nof unsupervised learning, so the training data is\ncollection of information",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22450.0,
    "t_end": 22480.0,
    "text": "So if you have a look\nat the workflow or the process flow\nof unsupervised learning, so the training data is\ncollection of information without any label. We have the machine\nlearning algorithm and then we have\nthe clustering malls. So what it does is that distributes the data\ninto a different class. And again, if you provide\nany unreliable new data, it will make a prediction and find out to which cluster\nthat particular data or the data set belongs to or the particular data point\nbelongs to so one of the most important algorithms in unsupervised\nlearning is clustering.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22475.0,
    "t_end": 22505.0,
    "text": "to or the particular data point\nbelongs to so one of the most important algorithms in unsupervised\nlearning is clustering. So let's understand exactly\nwhat is clustering. So a clustering basically is the process\nof dividing the data sets into groups consisting\nof similar data points. It means grouping\nof objects based on the information found in\nthe data describing the object. Objects or their relationships so clustering malls focus on and defying groups\nof similar records and labeling records according to the group to which\nthey belong now this is done",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22500.0,
    "t_end": 22530.0,
    "text": "and defying groups\nof similar records and labeling records according to the group to which\nthey belong now this is done without the benefit\nof prior knowledge about the groups\nand their characteristics. So and in fact, we may not even know exactly\nhow many groups are there to look for. Now. These models are often\nreferred to as unsupervised learning models, since there's no external\nstandard by which to judge. One is\nclassification performance. There are no right or wrong\nanswers to these model.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22525.0,
    "t_end": 22555.0,
    "text": "since there's no external\nstandard by which to judge. One is\nclassification performance. There are no right or wrong\nanswers to these model. And if we talk about why\nclustering is used so the goal of clustering\nis to determine the intrinsic group in a set\nof unlabeled data sometime. The partitioning is the goal or the purpose of clustering\nalgorithm is to make sense of and exact value from the last set of structured\nand unstructured data. So that is why clustering\nis used in the industry and if you have a look at the video,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22550.0,
    "t_end": 22580.0,
    "text": "So that is why clustering\nis used in the industry and if you have a look at the video, These use cases of clustering\nin the industry. So first of all,\nit's being used in marketing. So discovering distinct groups in customer databases\nsuch as customers who make a lot\nof long-distance calls customers who use internet more than cause they're also\nusing insurance companies. So like I need to find groups\nof Corporation insurance policy holders with high average\nclaim rate Farmers crash cops,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22575.0,
    "t_end": 22605.0,
    "text": "So like I need to find groups\nof Corporation insurance policy holders with high average\nclaim rate Farmers crash cops, which is profitable. They are using C Smith studies\nand defined problem areas of Oil or gas exploration\nBased on seesmic data, and they're also used\nin the recommendation of movies. If you would say they\nare also used in Flickr photos. They also used by Amazon for recommending the product\nwhich category it lies in. So basically if we talk about clustering there are\nthree types of clustering. So first of all, we have the exclusive clustering",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22600.0,
    "t_end": 22630.0,
    "text": "for recommending the product\nwhich category it lies in. So basically if we talk about clustering there are\nthree types of clustering. So first of all, we have the exclusive clustering which is the hard clustering\nso here and item belongs exclusively to one cluster\nnot several clusters and the data point. Along exclusively\nto one cluster. So an example of this is\nthe k-means clustering so k-means clustering\ndoes this exclusive kind of clustering so secondly, we have overlapping clustering so it is also known as\nsoft clusters in this and item can belong",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22625.0,
    "t_end": 22655.0,
    "text": "we have overlapping clustering so it is also known as\nsoft clusters in this and item can belong to multiple clusters as\nits degree of association with each cluster\nis shown and for example, we have fuzzy\nor the c means clustering which is being used\nfor overlapping clustering and finally we have\nThe hierarchical clustering so when two clusters have\na parent-child relationship or a tree-like structure, then it is known\nas hierarchical cluster. So as you can see here\nfrom the example,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22650.0,
    "t_end": 22680.0,
    "text": "so when two clusters have\na parent-child relationship or a tree-like structure, then it is known\nas hierarchical cluster. So as you can see here\nfrom the example, we have a parent-child kind of relationship in\nthe cluster given here. So let's understand what exactly is\nK means clustering. So k-means clustering is\nan algorithm whose main goal is to group similar elements\nof data points into a cluster and it is the process by which objects are classified\ninto a predefined number. Of groups so that they\nare as much dissimilar as possible from one group\nto another group",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22675.0,
    "t_end": 22705.0,
    "text": "by which objects are classified\ninto a predefined number. Of groups so that they\nare as much dissimilar as possible from one group\nto another group but as much as similar or\npossible within each group now if you have a look at the\nalgorithm working here, right? So first of all, it starts with and defying\nthe number of clusters, which is k then I can we find the centroid we find\nthe distance objects to the distance object to the centroid distance\nof object to the centroid then we find the Dropping based",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22700.0,
    "t_end": 22730.0,
    "text": "to the distance object to the centroid distance\nof object to the centroid then we find the Dropping based on the minimum distance has\nthe centroid Converse if true then we make\na cluster false. We then I can't find\nthe centroid repeat all of the steps\nagain and again, so let me show you how exactly clustering was\nwith an example here. So first we need\nto decide the number of clusters to be made now\nanother important task here is how to decide the important\nnumber of clusters or how to decide the number\nof clusters really get",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22725.0,
    "t_end": 22755.0,
    "text": "of clusters to be made now\nanother important task here is how to decide the important\nnumber of clusters or how to decide the number\nof clusters really get into that later. So first, let's assume that the number Number\nof clusters we have decided is 3 so after that then\nwe provide the centroids for all the Clusters which is guessing and the algorithm calculates\nthe euclidean distance of the point from each centroid and assigns the data point to the closest cluster\nnow euclidean distance. All of you know\nis the square root of the distance the square root\nof the square of the distance.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22750.0,
    "t_end": 22780.0,
    "text": "to the closest cluster\nnow euclidean distance. All of you know\nis the square root of the distance the square root\nof the square of the distance. So next when the center\nis a calculated again, we have our new clusters\nfor each data point. And again the distance\nfrom the points to the new clusters\nare calculated and then again, the points are assigned\nto the closest cluster. And then again, we have the new centroid scattered and now\nthese steps are repeated until we have\na repetition the centroids",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22775.0,
    "t_end": 22805.0,
    "text": "we have the new centroid scattered and now\nthese steps are repeated until we have\na repetition the centroids or the new center eyes are very\nclose to the very previous ones. So antenna and less\noutput gets repeated or the outputs are\nvery very close enough. We do not stop this process. We keep on calculating\nthe euclidean distance. It's of all the points\nto the centroids. Then we calculate\nthe new centroids and that is how clay means\nclustering Works basically, so an important part\nhere is to understand",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22800.0,
    "t_end": 22830.0,
    "text": "and that is how clay means\nclustering Works basically, so an important part\nhere is to understand how to decide the value of K\nor the number of clusters because it does\nnot make any sense. If you do not know how many classes\nare you going to make? So to decide\nthe number of clusters, we have the elbow method. So let's assume first of all compute\nthe sum squared error, which is the sse4 some value. A for example, let's take two four six\nand eight now the SS e",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22825.0,
    "t_end": 22855.0,
    "text": "which is the sse4 some value. A for example, let's take two four six\nand eight now the SS e which is the sum squared\nis defined as a sum of the squared distance\nbetween each number member of the cluster and its centroid\nmathematically and if you mathematically it\nis given by the equation which is provided here. And if you brought\nthe key against the SSE, you will see\nthat the error decreases as K gets large now this is because the number\nof cluster increases they should be smaller. So does this torsion is\nalso smaller know the idea",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22850.0,
    "t_end": 22880.0,
    "text": "as K gets large now this is because the number\nof cluster increases they should be smaller. So does this torsion is\nalso smaller know the idea of the elbow method is\nto choose the K at which the SSC decreases abruptly. So for example here if we have a look\nat the figure given here. We see that the best number\nof cluster is at the elbow as you can see here the graph\nhere changes abruptly after number four. So for this particular example, we're going to use\nfor as a number of cluster.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22875.0,
    "t_end": 22905.0,
    "text": "as you can see here the graph\nhere changes abruptly after number four. So for this particular example, we're going to use\nfor as a number of cluster. So first of all while working with k-means clustering\nthere are two key points, As to know first of all\nbe careful about various start. So choosing the first center at random choosing\nthe second center that is far away from the first\ncenter similarly choosing the NIH Center as far away\nas possible from the closest of the all the other centers and the second idea\nis to do as many runs of k-means each with different\nrandom starting points",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22900.0,
    "t_end": 22930.0,
    "text": "the NIH Center as far away\nas possible from the closest of the all the other centers and the second idea\nis to do as many runs of k-means each with different\nrandom starting points so that you get an idea\nof where exactly and how many clusters\nyou need to make and where exactly the centroid lies. And how the data\nis getting confused now k-means is not exactly\na very good method. So let's understand the pros and\ncons of clay means clusterings. We know that k-means is simple\nand understandable. Everyone loves you that the first go\nthe items automatically assigned",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22925.0,
    "t_end": 22955.0,
    "text": "We know that k-means is simple\nand understandable. Everyone loves you that the first go\nthe items automatically assigned to the Clusters. Now if we have\na look at the cons, so first of all one needs to\ndefine the number of clusters, there's a very\nheavy task asks us if we have 3/4 or if we have 10 categories\nand if we do not know what the number\nof clusters are going to be. It's Difficult for anyone\nto you know to guess the number of clusters not all items\nare forced into clusters whether they are actually belong\nto any other cluster or any other category,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22950.0,
    "t_end": 22980.0,
    "text": "of clusters not all items\nare forced into clusters whether they are actually belong\nto any other cluster or any other category, they are forced to to lie in that other category\nin which they are closest to this against happens\nbecause of the number of clusters with not defining\nthe correct number of clusters or not being able to guess\nthe correct number of clusters. So and most of all it's unable to handle the noisy data and\nthe outliners because anyway, As machine learning engineers and data scientists\nhave to clean the data. But then again it comes down",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 22975.0,
    "t_end": 23005.0,
    "text": "to handle the noisy data and\nthe outliners because anyway, As machine learning engineers and data scientists\nhave to clean the data. But then again it comes down to the analysis watch they\nare doing and the method that they are using so typically\npeople do not clean the data for k-means clustering even if the clean there's\nsometimes a now see noisy and outliners data\nwhich affect the whole model so that was all\nfor k-means clustering. So what we're going to do\nis now use k-means clustering for the We data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23000.0,
    "t_end": 23030.0,
    "text": "so that was all\nfor k-means clustering. So what we're going to do\nis now use k-means clustering for the We data set so we have to find out\nthe number of clusters and divide it accordingly. So the use case is\nthat first of all, we have a data set\nof five thousand movies. And what you want\nto do is grip them if the movies into clusters\nbased on the Facebook likes, so guys, let's have a look\nat the demo here. So first of all, what we're going to do is\nimport deep copy numpy pandas",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23025.0,
    "t_end": 23055.0,
    "text": "so guys, let's have a look\nat the demo here. So first of all, what we're going to do is\nimport deep copy numpy pandas Seaborn the various libraries, which we're going to use now\nand from map popular videos. In the use ply plot, and we're going to use\nthis ggplot and next what we're going to do\nis import the data set and look at the shape\nof the data is it so if we have a look at the\nshape of the data set we can see that it has 5043 rows\nwith Twenty Eight columns. And if you have a look at the head of the data set we\ncan see it has 5043 data points,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23050.0,
    "t_end": 23080.0,
    "text": "that it has 5043 rows\nwith Twenty Eight columns. And if you have a look at the head of the data set we\ncan see it has 5043 data points, so What we're going to do\nis place the data points in the plot me take\nthe director Facebook likes and we have a look\nat the data columns face number and post cars total Facebook likes director\nFacebook likes. So what we have done here now is taking the director\nFacebook likes and the actor three Facebook likes, right.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23075.0,
    "t_end": 23105.0,
    "text": "So what we have done here now is taking the director\nFacebook likes and the actor three Facebook likes, right. So we have five thousand\nforty three rows and two columns Now using\nthe k-means from sklearn what we're going\nto do is import it. First we're going\nto import k-means from sklearn dot cluster. Remember guys Escalon is\na very important library in Python for machine learning. So and the number of cluster what we're going to do is\nprovide as five now this again, the number of cluster\ndepends upon the SSE,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23100.0,
    "t_end": 23130.0,
    "text": "what we're going to do is\nprovide as five now this again, the number of cluster\ndepends upon the SSE, which is the sum\nof squared errors or the we're going\nto use the elbow method. So I'm not going to go\ninto the details of that again. So we're going to fit the data\ninto the k-means to fit and if you find the cluster, Us then for the\nk-means and printed. So what we find is is\nan array of five clusters and Fa print the label\nof the Caymans cluster.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23125.0,
    "t_end": 23155.0,
    "text": "So what we find is is\nan array of five clusters and Fa print the label\nof the Caymans cluster. Now next what we're going\nto do is plot the data which we have with the Clusters\nwith the new data clusters, which we have found\nand for this we're going to use the si bon and\nas you can see here, we have plotted that car. We have plotted\nthe data into the grid and You can see here. We have five clusters. So probably what I would say is that the cluster\n3 and the cluster",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23150.0,
    "t_end": 23180.0,
    "text": "We have five clusters. So probably what I would say is that the cluster\n3 and the cluster zero are very very close. So it might depend\nsee that's exactly what I was going to say. Is that initially\nthe main Challenge and k-means clustering is\nto define the number of centers which are the K. So as you can see here that the third Center and the zeroth cluster\nthe third cluster and the zeroth cluster up\nvery very close to each other so It probably could have been\nin one another cluster",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23175.0,
    "t_end": 23205.0,
    "text": "and the zeroth cluster up\nvery very close to each other so It probably could have been\nin one another cluster and the another disadvantage was that we do not exactly know how the points are\nto be arranged. So it's very difficult to force\nthe data into any other cluster which makes our analysis\na little different works fine. But sometimes it\nmight be difficult to code in the k-means clustering now, let's understand what exactly\nis seems clustering. So the fuzzy c means is an extension of the k-means\nclustering the popular simple.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23200.0,
    "t_end": 23230.0,
    "text": "let's understand what exactly\nis seems clustering. So the fuzzy c means is an extension of the k-means\nclustering the popular simple. Clustering technique so\nfuzzy clustering also referred as soft clustering is a form of clustering in which\neach data point can belong to more than one cluster. So k-means tries to find\nthe heart clusters where each point belongs\nto one cluster. Whereas the fuzzy c means\ndiscovers the soft clusters in a soft cluster\nany point can belong to more than one cluster",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23225.0,
    "t_end": 23255.0,
    "text": "Whereas the fuzzy c means\ndiscovers the soft clusters in a soft cluster\nany point can belong to more than one cluster at a time with\na certain Affinity value towards each 4zc means assigns\nthe degree of membership, which Just from 0 to 1\nto an object to a given cluster. So there is a stipulation\nthat the sum of the membership of an object to all the cluster. It belongs to must be equal\nto 1 so the degree of membership of this particular point to pull\nof these clusters as 0.6 0.4.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23250.0,
    "t_end": 23280.0,
    "text": "It belongs to must be equal\nto 1 so the degree of membership of this particular point to pull\nof these clusters as 0.6 0.4. And if you add up we get 1 so that is one of the logic\nbehind the fuzzy c means so and and this Affinity\nis proportional to the distance from the point to the center\nof the cluster now then again Now we have the pros\nand cons of fuzzy see means. So first of all, it allows a data point to be\nin multiple cluster. That's a pro. It's a more neutral\nrepresentation of the behavior of jeans jeans usually are\ninvolved in multiple functions.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23275.0,
    "t_end": 23305.0,
    "text": "It's a more neutral\nrepresentation of the behavior of jeans jeans usually are\ninvolved in multiple functions. So it is a very\ngood type of clustering when we're talking\nabout genes First of and again, if we talk about the cons again, we have to Define c\nwhich is the number of clusters same as K next. We need to determine the\nmembership cutoff value also, so that takes a lot of Time\nand it's time-consuming and the Clusters are sensitive to initial\nassignment of centroid. So a slight change",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23300.0,
    "t_end": 23330.0,
    "text": "so that takes a lot of Time\nand it's time-consuming and the Clusters are sensitive to initial\nassignment of centroid. So a slight change or deviation from the center\nhas it's going to result in a very different\nkind of, you know, a funny kind of output we get\nfrom the fuzzy c means and one of the major disadvantage\nof see means clustering is that it's this are\nnon deterministic algorithm. So it does not give you a particular output\nas in such that's that now let's have a look. At the third type of clustering which is\nthe hierarchical clustering.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23325.0,
    "t_end": 23355.0,
    "text": "a particular output\nas in such that's that now let's have a look. At the third type of clustering which is\nthe hierarchical clustering. So hierarchical clustering\nis an alternative approach which builds a hierarchy\nfrom the bottom up or the top to bottom and does not require\nto specify the number of clusters beforehand. Now, the algorithm works\nas in first of all, we put each data point\nin its own cluster and if I the closest to Cluster and combine them into one more\ncluster repeat the above step till the data points are\nin a single cluster.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23350.0,
    "t_end": 23380.0,
    "text": "and combine them into one more\ncluster repeat the above step till the data points are\nin a single cluster. Now, there are two types of\nhierarchical clustering one is I've number 80 plus string and the other one\nis division clustering. So a commemorative\nclustering bills the dendogram from bottom level while the division clustering\nit starts all the data points in one cluster\nthe fruit cluster now again hierarchical clustering also\nhas some sort of pros and cons. So in the pros\ndon't know Assumption of a particular number\nof cluster is required",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23375.0,
    "t_end": 23405.0,
    "text": "hierarchical clustering also\nhas some sort of pros and cons. So in the pros\ndon't know Assumption of a particular number\nof cluster is required and it may correspond\nto meaningful taxonomist. Whereas if we talk\nabout the cons once a decision is made\nto combine two clusters. Has it cannot be undone and one of the major disadvantage of\nthese hierarchical clustering is that it becomes very slow. If we talked about very very\nlarge data sets and nowadays. I think every industry are using\nlast year as its and collecting large amounts of data. So hierarchical clustering\nis not the act",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23400.0,
    "t_end": 23430.0,
    "text": "I think every industry are using\nlast year as its and collecting large amounts of data. So hierarchical clustering\nis not the act or the best method someone\nmight need to go for so there's that now when we talk\nabout unsupervised learning, so we have K means\nclustering and again, Another important term which people usually Miss while\ntalking about us was running and there's one very\nimportant concept of Market Basket analysis. Now, it is one\nof the key techniques",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23425.0,
    "t_end": 23455.0,
    "text": "there's one very\nimportant concept of Market Basket analysis. Now, it is one\nof the key techniques used by large retailers\nto uncover association between items now\nit works by looking for combination of items that occur together frequently in the transactions\nto put it in other way. It allows retailers\nto identify the relationships between the items that the People by\nfor example people who buy bread also tend to buy\nbutter the marketing team at the retail stores\nshould Target customers who buy bread and butter\nand provide them and offer",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23450.0,
    "t_end": 23480.0,
    "text": "who buy bread also tend to buy\nbutter the marketing team at the retail stores\nshould Target customers who buy bread and butter\nand provide them and offer so that they buy\na third item like an egg. So if a customer buys bread\nand butter and sees a discount or an offer on X, he will be encouraged to spend\nmore money and buy the eggs. Now, this is what Market Basket\nanalysis is all about now to find the association\nbetween the two items and make predictions about\nwhat the customers will buy. There are two Cartoons which are\nthe association rule Mining",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23475.0,
    "t_end": 23505.0,
    "text": "and make predictions about\nwhat the customers will buy. There are two Cartoons which are\nthe association rule Mining and the ebrary algorithms. So let's discuss each\nof these algorithm with an example. First of all, if we have a look at\nthe association rule mining now, it's a technique that's shows how items are associated to\neach other for example customers who purchased spread have\na 60 percent likelihood of also purchasing\njam and customers who purchase laptop are more\nlikely to purchase laptop bags. Now if you take an example\nof an association rule",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23500.0,
    "t_end": 23530.0,
    "text": "of also purchasing\njam and customers who purchase laptop are more\nlikely to purchase laptop bags. Now if you take an example\nof an association rule if we have a look\nat the Example here a arrow B. It means that if a person buys an atom a then\nhe will also buy an atom P. Now. There are three common ways to\nmeasure a particular Association because we have to find\nthese rules not on the basis of some statistics, right? So what we do is use support confidence and lift\nnow these three common ways and the measures to have a look at the association rule\nMining and know exactly",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23525.0,
    "t_end": 23555.0,
    "text": "support confidence and lift\nnow these three common ways and the measures to have a look at the association rule\nMining and know exactly how good is that rule. So first of all, we have support So support\ngifts the fraction of the Which contains an item A and B. So it's basically\nthe frequency of the item in the whole item set. Where's confidence gifts how often the item\nA and B occurred together given the number\nof item given the number of times a occur. So it's frequency\na comma B divided by the frequency of a now left",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23550.0,
    "t_end": 23580.0,
    "text": "given the number\nof item given the number of times a occur. So it's frequency\na comma B divided by the frequency of a now left what indicates is the strength\nof the rule over the random co-occurrence of A and B. If you have a close look\nat the denominator of the lift formula here, we have support a into support\nbe and now a major thing which can be noted from this is that the support of A\nand B are independent here. So if the value of lift or the denominator value\nof the lift is more it means",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23575.0,
    "t_end": 23605.0,
    "text": "So if the value of lift or the denominator value\nof the lift is more it means that the items are independently\nselling more not together. So that in turn will decrease\nthe value of lift. So what happens is that suppose the value\nof lift is more that implies that the rule which we get. It implies that the rule\nis strong and it And we used for later purposes\nbecause in that case the support in to support P value, which is the denominator\nof lift will be low",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23600.0,
    "t_end": 23630.0,
    "text": "And we used for later purposes\nbecause in that case the support in to support P value, which is the denominator\nof lift will be low which in turn means that there is a relationship\nbetween the items in the and B. So let's take an example\nof Association rule Mining and understand how\nexactly it works. So let's suppose we have\na set of items a b c d and e and we have\nthe set of transactions which are T1 T2, T3, T4 and T5 and what we need to do is\ncreate some sort of Rules, for example, you can see a d",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23625.0,
    "t_end": 23655.0,
    "text": "and what we need to do is\ncreate some sort of Rules, for example, you can see a d which means that\nif a person buys a he buys D if a person by see he buys a\nif a person buys a he by C. And for the fourth one is if a person by B\nand C Hill in turn by a now what we need to do is calculate\nthe support confidence and lift of these rules now here again, we talked about\na priority algorithm. So a priori algorithm and the association rule mining\ngo hand in hand.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23650.0,
    "t_end": 23680.0,
    "text": "we talked about\na priority algorithm. So a priori algorithm and the association rule mining\ngo hand in hand. So what a predator\nThis algorithm. It uses the frequent itemsets to\ngenerate the association rules and it is based on the concept that a subset of a frequent itemsets must also\nbe a frequent Isom set. So let's understand what is a frequent item set and\nhow all of these work together. So if we take the following\ntransactions of items, we have transaction T\n1 2 T 5 and the items are 1 3 4",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23675.0,
    "t_end": 23705.0,
    "text": "what is a frequent item set and\nhow all of these work together. So if we take the following\ntransactions of items, we have transaction T\n1 2 T 5 and the items are 1 3 4 2 3 5 1 2 3 5 2 5 and 1 3 5 now. Now another more\nimportant thing about support which I forgot to mention was that when talking about Association rule mining\nthere is a minimum support count what we need to do. Now. The first step is\nto build a list of items that of size 1 using\nthis transaction data set and use the minimum\nsupport count to now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23700.0,
    "t_end": 23730.0,
    "text": "The first step is\nto build a list of items that of size 1 using\nthis transaction data set and use the minimum\nsupport count to now, let's see how we do\nthat if we create the table see when you have a close look\nat the table c 1 we have the items at one\nwhich has support three because it appears\nin the transaction one. Three and five similarly if you have a look at the item\nset the single item 3. So it has the support\nof for it appears in t 1 T 2 T 3 and T 5 but",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23725.0,
    "t_end": 23755.0,
    "text": "So it has the support\nof for it appears in t 1 T 2 T 3 and T 5 but if we have a look at the item\nset for it only appears in the transaction once so it's support value is\n1 now the item set with the support value Which is less\nthan the minimum support value that is to have\nto be eliminated. So the final table which is a table F1\nhas one two three. And five it does not\ncontain the for now. What we're going to do is\ncreate the item list of the size 2 and all the combination\nof the item sets in F1.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23750.0,
    "t_end": 23780.0,
    "text": "And five it does not\ncontain the for now. What we're going to do is\ncreate the item list of the size 2 and all the combination\nof the item sets in F1. I used in this iteration. So we're left for behind. We just have 1 2 3 & 5. So the possible item\nsets a 1 2 1 3 1 5 2 3 2 5 & 3 5 then again. We will calculate the support So in this case if we have\na closer look at the table c 2 we see\nthat the items at once. What to do is having a support value 1\nwhich has to be eliminated.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23775.0,
    "t_end": 23805.0,
    "text": "in this case if we have\na closer look at the table c 2 we see\nthat the items at once. What to do is having a support value 1\nwhich has to be eliminated. So the final table f 2 does\nnot contain 1 comma 2 similarly if we create the item sets of size 3 and calculate\nthis support values, but before calculating\nthe support, let's perform the puring on the data set. Now what's appearing? So after all the combinations\nare made we divide the table c 3 items to check if there are another subset\nwhose support is less",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23800.0,
    "t_end": 23830.0,
    "text": "So after all the combinations\nare made we divide the table c 3 items to check if there are another subset\nwhose support is less than the minimum support value. This is a prairie algorithm. So in the item sets one, two, three what we can see\nthat we have one two, and in the one to five again, we have one too so build this\ncardboard of these item sets and we'll be left\nwith 1 3 5 and 2 3 5. So with one three five, we have three subsets\none five one, three three five, which are present in table F2.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23825.0,
    "t_end": 23855.0,
    "text": "So with one three five, we have three subsets\none five one, three three five, which are present in table F2. Then again. We have two three\nto five and 3/5 which are also present\nin t will f 2 so we have 2 Move 1 comma\n2 from the table c 3 and create the table F3 now if you're using the items of C3\nto create the atoms of C-4. So what we find is that we have the item set\n1 2 3 5 the support value is 1 Which is less than\nthe minimum support value of 2.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23850.0,
    "t_end": 23880.0,
    "text": "So what we find is that we have the item set\n1 2 3 5 the support value is 1 Which is less than\nthe minimum support value of 2. So what we're going\nto do is stop here and we're going to return\nto the previous item set. That is the table\nc 3 so the final table. Well, if three was\none three five with the support value of 2 and 2 3 5\nwith the support value of 2 now, what we're gonna do is\ngenerate all the subsets of each frequent itemsets. So let's assume",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23875.0,
    "t_end": 23905.0,
    "text": "what we're gonna do is\ngenerate all the subsets of each frequent itemsets. So let's assume that minimum confidence value is\n60% So for every subset s of I the output rule is\nthat s gives i2s is that s recommends i ns. If the support of I / support\nof s is greater than or equal. Equal to the minimum\nconfidence value, then only will proceed further. So keep in mind that we have not used\nleft till now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23900.0,
    "t_end": 23930.0,
    "text": "Equal to the minimum\nconfidence value, then only will proceed further. So keep in mind that we have not used\nleft till now. We are only working\nwith support and confidence. So applying rules\nwith item sets of F3 we get rule 1 which is 1 comma\n3 which gives 1 3 5 and 1/3. It means if you buy one\nand three there's a 66% chance that you will buy item 5 also similarly the rule\n1 comma 5 it means that If you buy one and five,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23925.0,
    "t_end": 23955.0,
    "text": "similarly the rule\n1 comma 5 it means that If you buy one and five, there's a hundred percent chance that you will buy\nthree also similarly if we have a look\nat Rule 5 and 6 here the confidence value is less than 60 percent which was\nthe assumed confidence value. So what we're going to do is\nwith reject these files now an important thing\nto note here is that have a closer look\nto the Rule 5 and root 3, you see it has one five three\none five three three point five.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23950.0,
    "t_end": 23980.0,
    "text": "that have a closer look\nto the Rule 5 and root 3, you see it has one five three\none five three three point five. It's very confusing. So one thing to keep in Mine is that the order of the item sets\nis also very important that will help us\nallow create good rules and avoid any kind of confusion. So that's that. So now let's learn how Association rule I used in\nMarket Basket analysis problems. So what we'll do\nis we will be using the online transactions data of a retail store for\ngenerating Association rules.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 23975.0,
    "t_end": 24005.0,
    "text": "how Association rule I used in\nMarket Basket analysis problems. So what we'll do\nis we will be using the online transactions data of a retail store for\ngenerating Association rules. So first of all, what you need to do is\nimport pandas MSD ml. D&D libraries from the imported\nand read the data. So first of all, what we're\ngoing to do is read the data, what we're going\nto do is from M LX T and E dot frequent patterns. We're going to improve the a\npriori and Association rules. As you can see here. We have the head of the data.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24000.0,
    "t_end": 24030.0,
    "text": "We're going to improve the a\npriori and Association rules. As you can see here. We have the head of the data. You can see we have invoice\nnumber stock code the description quantity the invoice dt8 unit price\ncustomer ID and the country. So in the next step, what we will do is we\nwill do the data cleanup which includes removing. His from some\nof the descriptions given and what we're going\nto do is drop the rules that do not have the invoice numbers every move\nthe crate transactions. So hey, what what you're\ngoing to do is remove which do not have\nany invoice number",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24025.0,
    "t_end": 24055.0,
    "text": "the invoice numbers every move\nthe crate transactions. So hey, what what you're\ngoing to do is remove which do not have\nany invoice number if the string tight ainst Epstein was a number then\nwe're going to remove that. Those are the credits remove\nany kind of spaces from the descriptions. So as you can see here, we have like five hundred\nand thirty-two thousand rows with eight columns. So next one. We're going to do is\nafter the cleanup. We need to consolidate the items\ninto one transaction per row with each product for the sake\nof keeping the data set small.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24050.0,
    "t_end": 24080.0,
    "text": "We're going to do is\nafter the cleanup. We need to consolidate the items\ninto one transaction per row with each product for the sake\nof keeping the data set small. We're going to only look\nat the sales for France. So we're going to use\nthe only France and group by invoice number description with the quantity sum\nup and see so which leaves us\nwith three ninety two rows and one thousand five\nhundred sixty three columns. Now, there are a lot\nof zeros in the data, but we also need to make sure\nAny positive values are converted to a 1 and\nanything less than 0 is set to 0",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24075.0,
    "t_end": 24105.0,
    "text": "Now, there are a lot\nof zeros in the data, but we also need to make sure\nAny positive values are converted to a 1 and\nanything less than 0 is set to 0 so for that we're going\nto use this code defining and code units if x is less than\n0 return 0 if x is greater than 1 returned one. So what we're going to do is map and apply it to the whole data\nset we have here. So now that we\nhave structured data properly. So the next step is to generate\nthe frequent item set that has support of at\nleast seven percent.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24100.0,
    "t_end": 24130.0,
    "text": "So the next step is to generate\nthe frequent item set that has support of at\nleast seven percent. Now this number is chosen so\nthat you can get close enough. Now, what we're going\nto do is generate the rules with the corresponding\nsupport confidence and lift. So we had given\nthe minimum support a 0.7. The metric is left\nfrequent Island set and threshold is 1 so these are the following rules now a few\nrules with a high lift value, which means that it\noccurs more frequently than would be expected\ngiven the number of transaction",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24125.0,
    "t_end": 24155.0,
    "text": "the following rules now a few\nrules with a high lift value, which means that it\noccurs more frequently than would be expected\ngiven the number of transaction the product combinations most\nof the places the confidence. Is high as well. So these are few to observations\nwhat we get here. If we filter the data frame\nusing the standard pandas code for large lift six\nand high confidence 0.8. This is what the output\nis going to look like. These are 1 2 3 4 5 6 7 8.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24150.0,
    "t_end": 24180.0,
    "text": "This is what the output\nis going to look like. These are 1 2 3 4 5 6 7 8. So as you can see here, we have the H rules\nwhich are the final rules which are given by\nthe Association rule Mining and this is how all\nthe industries are. Are any of these we've talked\nabout largely retailers. They tend to know how their products are used\nand how exactly they should rearrange and provide\nthe offers on the product so that people spend\nmore and more money and time in the shop.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24175.0,
    "t_end": 24205.0,
    "text": "should rearrange and provide\nthe offers on the product so that people spend\nmore and more money and time in the shop. So that was all\nabout Association rule mining. So so guys, that's all for\nunsupervised learning. I hope you got to know\nabout the different formulas how unsupervised learning works\nbecause you know, we did not provide\nany label to the data. All we did was create some rules\nand not knowing what the data is and we did clusterings\ndifferent types of clusterings came in simi's\nhierarchical clustering.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24200.0,
    "t_end": 24230.0,
    "text": "and we did clusterings\ndifferent types of clusterings came in simi's\nhierarchical clustering. The reinforcement learning\nis a part of machine learning where an agent is put\nin an environment and he learns to behave\nin this environment by performing certain actions. Okay, so it basically performs\nactions and it either gets a rewards on the actions or It gets a punishment\nand observing the reward which it gets from those actions\nreinforcement learning is all",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24225.0,
    "t_end": 24255.0,
    "text": "a rewards on the actions or It gets a punishment\nand observing the reward which it gets from those actions\nreinforcement learning is all about taking an appropriate\naction in order to maximize the reward\nin a particular situation. So guys in supervised learning\nthe training data comprises of the input and the expected output and so the model is trained\nwith the expected output itself, but when it comes\nto reinforcement learning, there is no expected output here\nthe reinforcement agent decides. What actions to take in order\nto perform a given task.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24250.0,
    "t_end": 24280.0,
    "text": "there is no expected output here\nthe reinforcement agent decides. What actions to take in order\nto perform a given task. In the absence of a training\ndata set it is bound to learn from its experience itself. All right. So reinforcement learning\nis all about an agent who's put in\nan unknown environment and he's going to use a hit\nand trial method in order to figure out the environment and then come up\nwith an outcome. Okay. Now, let's look\nat reinforcement learning within an analogy. So consider a scenario\nwhere in a baby is learning how to walk the scenario\ncan go about in two ways.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24275.0,
    "t_end": 24305.0,
    "text": "So consider a scenario\nwhere in a baby is learning how to walk the scenario\ncan go about in two ways. Now in the first case\nthe baby starts walking and makes it to the candy here. The candy is basically\nthe reward it's going to get so since the candy is the end goal. The baby is happy. It's positive. Okay, so the baby is happy\nand it gets rewarded a set of candies now another way\nin which this could go is that the baby starts walking but Falls due to some hurdle\nin between the baby gets hurt and it doesn't get any candy\nand obviously the baby is sad.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24300.0,
    "t_end": 24330.0,
    "text": "but Falls due to some hurdle\nin between the baby gets hurt and it doesn't get any candy\nand obviously the baby is sad. So this is a negative reward. Okay, or you can say\nthis is a setback. So just like how we humans learn from our mistakes\nby trial and error. Learning is also similar. Okay, so we have an agent which is basically\nthe baby and a reward which is the candy over here. Okay, and with many hurdles\nin between the agent is supposed to find the best possible path\nto read through the reward. So guys, I hope\nyou all are clear",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24325.0,
    "t_end": 24355.0,
    "text": "Okay, and with many hurdles\nin between the agent is supposed to find the best possible path\nto read through the reward. So guys, I hope\nyou all are clear with the reinforcement learning. Now. Let's look at the\nreinforcement learning process. So generally a reinforcement\nlearning system has two main components. All right, the first is an agent\nand the second one is an environment now\nin the previous case, we saw that the\nagent was a baby. B and the environment\nwas the living room where in the baby was crawling. Okay. The environment is the setting that the agent is acting\non and the agent over here represents the reinforcement\nlearning algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24350.0,
    "t_end": 24380.0,
    "text": "The environment is the setting that the agent is acting\non and the agent over here represents the reinforcement\nlearning algorithm. So guys the reinforcement\nlearning process starts when the environment\nsends a state to the agent and then the agent\nwill take some actions based on the observations in turn the environment\nwill send the next state and the respective reward\nback to the agent. The agent will update its knowledge with the reward\nreturned by the I meant and it uses that to evaluate\nits previous action. So guys this\nLoop keeps continuing",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24375.0,
    "t_end": 24405.0,
    "text": "its knowledge with the reward\nreturned by the I meant and it uses that to evaluate\nits previous action. So guys this\nLoop keeps continuing until the environment sends\na terminal state which means that the agent has\naccomplished all his tasks and he finally gets the reward. Okay. This is exactly what was depicted\nin this scenario. So the agent keeps\nclimbing up ladders until he reaches his reward\nto understand this better. Let's suppose that our agent is\nlearning to play Counter-Strike. Okay, so let's break it down\nnow initially the RL agent which is Only the player player\n1 let's say it's the player",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24400.0,
    "t_end": 24430.0,
    "text": "Let's suppose that our agent is\nlearning to play Counter-Strike. Okay, so let's break it down\nnow initially the RL agent which is Only the player player\n1 let's say it's the player 1 who is trying to learn\nhow to play the game. Okay. He collects some state\nfrom the environment. Okay. This could be the first state\nof Counter-Strike now based on the state the agent\nwill take some action. Okay, and this action\ncan be anything that causes a result. So if the player moves left or right it's also\nconsidered as an action. Okay. So initially the action\nis going to be random because obviously the first time\nyou pick up Counter-Strike,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24425.0,
    "t_end": 24455.0,
    "text": "or right it's also\nconsidered as an action. Okay. So initially the action\nis going to be random because obviously the first time\nyou pick up Counter-Strike, you're not going\nto be a master at it. So you're going to try\nwith different actions and you're just going\nto Up a random action in the beginning. Now the environment is going\nto give a new state. So after clearing that the environment\nis now going to give a new state to the agent or to the player. So maybe he's\nacross stage 1 now. He's in stage 2. So now the player will get a reward\nour one from the environment because it cleared stage 1. So this reward can be anything.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24450.0,
    "t_end": 24480.0,
    "text": "will get a reward\nour one from the environment because it cleared stage 1. So this reward can be anything. It can be additional points\nor coins or anything like that. Okay. So basically this Loop\nkeeps going on until the player is dead\nor reaches the destination. Okay, and it Continuously\noutputs a sequence of States actions and rewards. So guys. This was a small example to show you how reinforcement\nlearning process works. So you start\nwith an initial State and once a player clothes\nthat state he gets a reward after that the environment will\ngive another stage to the player",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24475.0,
    "t_end": 24505.0,
    "text": "So you start\nwith an initial State and once a player clothes\nthat state he gets a reward after that the environment will\ngive another stage to the player and after it clears that state\nit's going to get another reward and it's going to keep happening until the player\nreaches his destination. All right, so guys,\nI hope this is clear now, let's move on and look at the reinforcement\nlearning definition. So there are a few Concepts\nthat you should be aware of while studying\nreinforcement learning. Let's look at those\ndefinitions over here. So first we have the agent\nnow an agent is basically",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24500.0,
    "t_end": 24530.0,
    "text": "of while studying\nreinforcement learning. Let's look at those\ndefinitions over here. So first we have the agent\nnow an agent is basically the reinforcement learning\nalgorithm that learns from trial and error. Okay. So an agent takes actions, like for example a soldier\nin Counter-Strike navigating through the game. That's also an action. Okay, if he moves left right\nor if he shoots at somebody that's also an action. Okay. So the agent is responsible for taking actions\nin the environment. Now the environment is\nthe whole Counter-Strike game. Okay. It's basically the world\nthrough which the agent",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24525.0,
    "t_end": 24555.0,
    "text": "Now the environment is\nthe whole Counter-Strike game. Okay. It's basically the world\nthrough which the agent moves the environment takes\nthe agents current state and action as input and it Returns the agency reward\nand its next state as output. Alright, next we have action\nnow all the possible steps that an agent can take\nare called actions. So like I said, it can be moving right left\nor shooting or any of that. Alright, then we have\nstate now state is basically the current condition\nreturned by the environment. So Double State you are in",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24550.0,
    "t_end": 24580.0,
    "text": "Alright, then we have\nstate now state is basically the current condition\nreturned by the environment. So Double State you are in if you are in state 1 or\nif you're interested to that represents\nyour current condition. All right. Next we have reward a reward\nis basically an instant return from the environment\nto appraise Your Last Action. Okay, so it can be\nanything like coins or it can be additional points. So basically a reward\nis given to an agent after it clears. The specific stages. Next we have policy policy is\nbasically the strategy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24575.0,
    "t_end": 24605.0,
    "text": "So basically a reward\nis given to an agent after it clears. The specific stages. Next we have policy policy is\nbasically the strategy that the agent uses to find\nout his next action. In based on his current\nstate policy is just the strategy with which\nyou approach the game. Then we have value. Now while you is the expected\nlong-term return with discount so value and action value\ncan be a little bit confusing for you right now. But as we move further, you'll understand what\nI'm talking about. Okay, so value is basically\nthe long-term return",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24600.0,
    "t_end": 24630.0,
    "text": "But as we move further, you'll understand what\nI'm talking about. Okay, so value is basically\nthe long-term return that you get with discount. Okay discount, I'll explain\nin the further slides. Then we have action value now action value\nis also known as Q value. Okay, it's very similar\nto what You except that it takes\nan extra parameter, which is the current action. So basically here you'll find\nout the Q value depending on the particular action\nthat you took. All right. So guys don't get confused\nwith value and action value. We look at examples in the further slides and you\nwill understand this better.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24625.0,
    "t_end": 24655.0,
    "text": "So guys don't get confused\nwith value and action value. We look at examples in the further slides and you\nwill understand this better. Okay, so guys make sure that you're familiar\nwith these terms because you'll be seeing\na lot of these terms in the further slides. All right. Now before we move any further, I'd like to discuss\na few more Concepts. Okay. So first we will discuss\nthe reward maximization. So if you haven't already\nrealize the it the basic aim of the RL agent is\nto maximize the reward now, how does that happen? Let's try to understand\nthis in depth.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24650.0,
    "t_end": 24680.0,
    "text": "of the RL agent is\nto maximize the reward now, how does that happen? Let's try to understand\nthis in depth. So the agent must be\ntrained in such a way that he takes the best action\nso that the reward is maximum because the end goal\nof reinforcement learning is to maximize your reward\nbased on a set of actions. So let me explain this\nwith a small game now in the figure you can see there\nis a Forks there's some meat and there's a tiger So\nodd agent is basically the fox and his end goal is to eat\nthe maximum amount of meat",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24675.0,
    "t_end": 24705.0,
    "text": "and there's a tiger So\nodd agent is basically the fox and his end goal is to eat\nthe maximum amount of meat before being eaten\nby the tiger now since the fox is a clever fellow he eats the meat that is closer to him\nrather than the meat which is closer to the tiger. Now this is because the\ncloser he is to the tiger the higher are his chances\nof getting killed. So because of this the rewards\nwhich are near the tiger, even if they are\nbigger meat chunks, they will be discounted. So this is exactly\nwhat discounting means so our agent is not going\nto eat the meat chunks which are Closer to the tiger\nbecause of the risk.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24700.0,
    "t_end": 24730.0,
    "text": "So this is exactly\nwhat discounting means so our agent is not going\nto eat the meat chunks which are Closer to the tiger\nbecause of the risk. All right now even though the meat chunks\nmight be larger. He does not want to take\nthe chances of getting killed. Okay. This is called discounting. Okay. This is where you discount because it improvised\nand you just eat the meat which are closer to you\ninstead of taking risks and eating the meat which are closer\nto your opponent. All right. Now the discounting\nof reward Works based on a value called gamma\nwill be discussing gamma in our further slides,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24725.0,
    "t_end": 24755.0,
    "text": "Now the discounting\nof reward Works based on a value called gamma\nwill be discussing gamma in our further slides, but in short the value\nof gamma is between 0 and 1. Okay. So the Follow the gamma. The larger is\nthe discount value. Okay. So if the gamma value is lesser, it means that the agent\nis not going to explore and he's not going\nto try and eat the meat chunks which are closer to the tiger. Okay, but if the gamma value\nis closer to 1 it means that our agent is actually\ngoing to explore and it's going to dry\nand eat the meat chunks which are closer to the tiger.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24750.0,
    "t_end": 24780.0,
    "text": "Okay, but if the gamma value\nis closer to 1 it means that our agent is actually\ngoing to explore and it's going to dry\nand eat the meat chunks which are closer to the tiger. All right now, I'll be explaining this\nin depth in the further slides. So don't worry if you haven't got\na clear concept yet, but just understand\nthat reward maximized. Ation is a very important step when it comes\nto reinforcement learning because the agent has\nto collect maximum rewards by the end of the game. All right. Now, let's look\nat another concept which is called exploration\nand exploitation. So exploration like the name\nsuggests is about exploring",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24775.0,
    "t_end": 24805.0,
    "text": "Now, let's look\nat another concept which is called exploration\nand exploitation. So exploration like the name\nsuggests is about exploring and capturing more information\nabout an environment on the other hand exploitation\nis about using the already known exploited information\nto hide in the rewards. So guys consider the fox\nand tiger example that we discussed now here the foxy Only the meat chunks\nwhich are close to him, but he does not eat\nthe meat chunks which are closer to the tiger. Okay, even though they\nmight give him more Awards. He does not eat them if the fox only focuses\non the closest rewards,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24800.0,
    "t_end": 24830.0,
    "text": "which are closer to the tiger. Okay, even though they\nmight give him more Awards. He does not eat them if the fox only focuses\non the closest rewards, he will never reach\nthe big chunks of meat. Okay, this is\nwhat exploitation is about you just going to use\nthe currently known information and you're going\nto try and get rewards based on that information. But if the fox decides\nto explore a bit, it can find the bigger award\nwhich is the big chunks of meat. This is exactly\nwhat exploration is. So the agent is not going\nto stick to one corner instead. He's going to explore\nthe entire environment and try",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24825.0,
    "t_end": 24855.0,
    "text": "This is exactly\nwhat exploration is. So the agent is not going\nto stick to one corner instead. He's going to explore\nthe entire environment and try and collect bigger rewards. All right, so guys, I hope you all are clear with\nexploration and exploitation. Now, let's look\nat the markers decision process. So guys, this is basically\na mathematical approach for mapping a solution in\nreinforcement learning in a way. The purpose of reinforcement\nlearning is to solve a Markov decision process. Okay, so there are\na few parameters.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24850.0,
    "t_end": 24880.0,
    "text": "The purpose of reinforcement\nlearning is to solve a Markov decision process. Okay, so there are\na few parameters. Was that I used to get\nto the solution. So the parameters include\nthe set of actions the set of states the rewards the policy that you're taking to approach\nthe problem and the value that you get. Okay, so to sum it up\nthe agent must take an action a to transition from a start state\nto the end State s while doing so the agent\nwill receive a reward are for each action that he takes. So guys a series",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24875.0,
    "t_end": 24905.0,
    "text": "while doing so the agent\nwill receive a reward are for each action that he takes. So guys a series of actions taken by\nthe agent Define the policy or a defines the approach. And the rewards that are collected\nDefine the value. So the main goal here is\nto maximize the rewards by choosing the optimum policy. All right. Now, let's try to understand\nthis with the help of the shortest path problem. I'm sure a lot of you might\nhave gone through this problem when you are in college, so guys look\nat the graph over here. So our aim here is\nto find the shortest path",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24900.0,
    "t_end": 24930.0,
    "text": "I'm sure a lot of you might\nhave gone through this problem when you are in college, so guys look\nat the graph over here. So our aim here is\nto find the shortest path between a and d\nwith minimum possible cost. So the value that you see\non each of these edges basically denotes the cost. So if I want to go from A to see\nit's gonna cost me 15 points. Okay. So let's look at\nhow this is done. Now before we move\nand look at the problem in this problem the set of\nstates are denoted by the nodes, which is ABCD and the action is to Traverse\nfrom one node to the other.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24925.0,
    "t_end": 24955.0,
    "text": "in this problem the set of\nstates are denoted by the nodes, which is ABCD and the action is to Traverse\nfrom one node to the other. So if I'm going from A to B, that's an action\nsimilarly a to see that's an action. Okay, the reward is\nbasically the cost which is represented\nby each Edge over here. All right. Now the policy is basically\nthe path that I choose to reach the destination, so Let's say I choose\na seed be okay, that's one policy\nin order to get to D and choosing a CD\nwhich is a policy. Okay. It's basically how\nI'm approaching the problem.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24950.0,
    "t_end": 24980.0,
    "text": "and choosing a CD\nwhich is a policy. Okay. It's basically how\nI'm approaching the problem. So guys here you\ncan start off at node a and you can take baby steps\nto your destination. Now initially you're clueless so you can just take\nthe next possible node, which is visible to you. So guys, if you're smart enough, you're going to choose a\nto see instead of ABCD or ABD. All right. So now if you are at nodes\nsee you want to drive. String note D. You must again\nchoose a weisbarth. All right, you just have\nto calculate which path has",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 24975.0,
    "t_end": 25005.0,
    "text": "So now if you are at nodes\nsee you want to drive. String note D. You must again\nchoose a weisbarth. All right, you just have\nto calculate which path has the highest cost or which path will give\nyou the maximum rewards. So guys, this is\na simple problem. We just trying to calculate\nthe shortest path between a and d by traversing\nthrough these nodes. So if I Traverse from a CD,\nit gives me the maximum reward. Okay, it gives me 65, which is more than any other\npolicy would give me. Okay. So if I go from ABD, it would be 40 when you\ncompare this to a CD. It gives me more reward.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25000.0,
    "t_end": 25030.0,
    "text": "which is more than any other\npolicy would give me. Okay. So if I go from ABD, it would be 40 when you\ncompare this to a CD. It gives me more reward. So obviously I'm going\nto go with a CB. Okay, so guys was\na simple problem in order to understand how\nMarkov decision process works. All right, so guys,\nI want to ask you a question. What do you think? I did hear did I perform\nexploration or did I perform exploitation now the policy for the above example\nis of exploitation because we didn't explore\nthe other nodes. Okay. We just selected three notes\nand we travel through them.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25025.0,
    "t_end": 25055.0,
    "text": "the policy for the above example\nis of exploitation because we didn't explore\nthe other nodes. Okay. We just selected three notes\nand we travel through them. So that's why this\nis called exploitation. We must always explore\nthe different notes so that we Find\na more optimal policy. But in this case, obviously a CD has\nthe highest reward and we're going with a CD but\ngenerally it's not so simple. There are a lot of nodes there\nhundreds of notes you Traverse and there are like\n50 60 policies. Okay, 50 60 different policies. So you make sure you explore\nthrough all the policies and then decide\non an Optimum policy",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25050.0,
    "t_end": 25080.0,
    "text": "Okay, 50 60 different policies. So you make sure you explore\nthrough all the policies and then decide\non an Optimum policy which will give you\na maximum reward the for a robot and environment is a place where It has been\nput to use now. Remember this reward is itself the agent for example\nan automobile Factory where a robot is used\nto move materials from one place to another now\nthe task we discussed just now have a property in common.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25075.0,
    "t_end": 25105.0,
    "text": "from one place to another now\nthe task we discussed just now have a property in common. Now, these tasks involve\nand environment and expect the agent to learn\nfrom the environment. Now, this is where traditional\nmachine learning phase and hence the need\nfor reinforcement learning now. It is good to have\nan established overview of the problem. That is to be Of using\nthe Q learning or the reinforcement learning so it helps to define\nthe main components of a reinforcement\nlearning solution. That is the agent environment\naction rewards and States.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25100.0,
    "t_end": 25130.0,
    "text": "so it helps to define\nthe main components of a reinforcement\nlearning solution. That is the agent environment\naction rewards and States. So let's suppose we are to build a few autonomous robots for\nan automobile building Factory. Now, these robots will help\nthe factory personal by conveying them\nthe necessary parts that they would need\nin order to pull the car. Now. These different parts\nare located at nine different positions\nwithin the factory warehouse. The car part include\nthe chassis Wheels dashboard the engine and so on",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25125.0,
    "t_end": 25155.0,
    "text": "The car part include\nthe chassis Wheels dashboard the engine and so on and the factory workers\nhave prioritized the location that contains the body or the chassis to be\nthe topmost but they have provided the priorities\nfor other locations as well, which will look into the moment. Now these locations within the factory look\nsomewhat like this. So as you can see here, we have L1 L2 L3 all of these stations now\none thing you might notice here that there Little obstacle\nprison in between the locations.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25150.0,
    "t_end": 25180.0,
    "text": "we have L1 L2 L3 all of these stations now\none thing you might notice here that there Little obstacle\nprison in between the locations. So L6 is the top\npriority location that contains the chassis\nfor preparing the car bodies. Now the task is\nto enable the robots so that they can find\nthe shortest route from any given location to\nanother location on their own. Now the agents in this case\nare the robots the environment is the automobile\nFactory warehouse. So let's talk about the state's\nthe states are the location",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25175.0,
    "t_end": 25205.0,
    "text": "Now the agents in this case\nare the robots the environment is the automobile\nFactory warehouse. So let's talk about the state's\nthe states are the location in which a particular robot is And in the particular\ninstance of time, which will denote it states\nthe machines understand numbers rather than let us so let's map\nthe location codes to number. So as you can see here, we have mapped location\nl 1 to this t 0 L 2 and 1 and so on we have L8 as\nstate 7 and L line at state. So next what we're going to talk\nabout are the actions.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25200.0,
    "t_end": 25230.0,
    "text": "and so on we have L8 as\nstate 7 and L line at state. So next what we're going to talk\nabout are the actions. So in our example, the action will be\nthe direct location that a robot can go from a particular location\nright considering What that is a tel to location and the Direct locations to\nwhich it can move rl5 L1 and L3. Now the figure here may come\nin handy to visualize this now as you might have already\nguessed the set of actions",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25225.0,
    "t_end": 25255.0,
    "text": "Now the figure here may come\nin handy to visualize this now as you might have already\nguessed the set of actions here is nothing but the set of all possible states of the robot for each location\nthe set of actions that a robot can take\nwill be different. For example, the set\nof actions will change if the robot is\nin L1 rather than L2. So if the robot is Is\nin L1 it can only go to L 4 and L 2 directly now that we are done with the states\nand the actions. Let's talk about the rewards. So the states are\nbasically zero one two,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25250.0,
    "t_end": 25280.0,
    "text": "that we are done with the states\nand the actions. Let's talk about the rewards. So the states are\nbasically zero one two, three four and the\nactions are also 0 1 2 3 4 up to 8. Now. The rewards now will\nbe given to a robot. If a location which is the state\nis directly reachable from a particular location. So let's take an example suppose\nL line is directly reachable from L8, right? If a robot goes from LA\nto align and vice versa, it will be rewarded by one and",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25275.0,
    "t_end": 25305.0,
    "text": "If a robot goes from LA\nto align and vice versa, it will be rewarded by one and if I look a shin is\nnot directly reachable from a particular equation. We do not give any reward\na reward of 0 now the reward is just a number and nothing else it enables\nthe robots to make sense of the movements helping them in deciding what locations\nare directly reachable and what are not now with this Q. We can\nconstruct a reward table which contains all\nthe required values mapping between all possible States. So as you can see here\nin the table the positions",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25300.0,
    "t_end": 25330.0,
    "text": "which contains all\nthe required values mapping between all possible States. So as you can see here\nin the table the positions which are marked green\nhave a positive reward. And as you can see here, we have all the possible rewards\nthat a robot can get by moving in between the different states. Now comes an\ninteresting decision. Now remember that the factory\nadministrator prioritized L6 to be the topmost. So how do we incorporate\nthis fact in the above table. Now, this is done by associating\nthe topmost priority location",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25325.0,
    "t_end": 25355.0,
    "text": "So how do we incorporate\nthis fact in the above table. Now, this is done by associating\nthe topmost priority location with a very high reward\nthan the usual ones. So let's put 990. And in the cell L 6 comma and 6 now the table of rewards\nwith a higher reward for the topmost location\nlooks something like this. We have not formally defined\nall the vital components for the solution. We are aiming for\nthe problem discussed. Now, you will shift gears\na bit and study some of the fundamental concepts that Prevail in the world\nof reinforcement learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25350.0,
    "t_end": 25380.0,
    "text": "Now, you will shift gears\na bit and study some of the fundamental concepts that Prevail in the world\nof reinforcement learning and q-learning the first\nof all we'll start with the Bellman\nequation now consider the following Square rooms, which is analogous\nto the actual environment. Aunt from our original problem, but without the barriers now\nsuppose a robot needs to go to the room marked in the green promise\ncurrent position a using the specified Direction now, how can we enable the robot\nto do this programmatically one idea would be introduced\nsome kind of a footprint",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25375.0,
    "t_end": 25405.0,
    "text": "the specified Direction now, how can we enable the robot\nto do this programmatically one idea would be introduced\nsome kind of a footprint which the robot will be able\nto follow now here a constant value is specified\nin each of the rooms which will come\nalong the robots way if it follows the direction\nspecified above now in this way if it starts at A it\nwill be able to scan through this constant value and will move accordingly\nbut this will only work if the direction is prefix and the robot always starts",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25400.0,
    "t_end": 25430.0,
    "text": "and will move accordingly\nbut this will only work if the direction is prefix and the robot always starts at the location a now\nconsider the robot starts at this location rather\nthan its previous one. Now the robot\nnow sees Footprints in two different directions. It is therefore unable\nto decide which way to go in order to get the destination\nwhich is the Green Room. It happens primarily because the robot\ndoes not have a weight. Remember the directions\nto proceed so our job now is to enable\nthe robot with a memory.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25425.0,
    "t_end": 25455.0,
    "text": "Remember the directions\nto proceed so our job now is to enable\nthe robot with a memory. Now, this is where the Bellman\nequation comes into play. So as you can see here, the main reason\nof the Bellman equation is to enable the reward\nwith the memory. That's the thing\nwe're going to use. So the equation goes\nsomething like this V of s gives maximum a r\nof s comma a plus gamma of vs - where s is a particular state which is a ROM a is\nthe Action Moving between the rooms as -",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25450.0,
    "t_end": 25480.0,
    "text": "where s is a particular state which is a ROM a is\nthe Action Moving between the rooms as - is the state to which\nthe robot goes from s and gamma is the discount Factor now we'll get\ninto it in a moment and obviously R of s comma\na is a reward function which takes a state as an action\na and outputs the reward now V of s is the value of being\nin a particular state which is the footprint now we consider all\nthe possible actions and take the one that yields\nthe maximum value now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25475.0,
    "t_end": 25505.0,
    "text": "which is the footprint now we consider all\nthe possible actions and take the one that yields\nthe maximum value now, there is one constraint however\nregarding the value Footprint, that is the row marked in the yellow just\nbelow the Green Room. It will always have\nthe value of 1 to denote that is one of the nearest room adjacent to the Green Room\nnot this is also to ensure that a robot gets a reward when it goes from a yellow room\nto The Green Room. Let's see how to make\nsense of the equation which we have here. So let's assume\na discount factor of 0.9",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25500.0,
    "t_end": 25530.0,
    "text": "when it goes from a yellow room\nto The Green Room. Let's see how to make\nsense of the equation which we have here. So let's assume\na discount factor of 0.9 as remember gamma is\nthe discount value or the discount Factor. So let's take a 0.9\nnow for the room, which is Just below the one or the yellow room, which is\nthe Aztec Mark for this room. What will be the V of s that is the value of being\nin a particular state? So for this V of s\nwould be something like maximum of a will take 0 which is the initial\nof our s comma.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25525.0,
    "t_end": 25555.0,
    "text": "So for this V of s\nwould be something like maximum of a will take 0 which is the initial\nof our s comma. Hey plus 0.9\nwhich is gamma into 1 that gives us zero point\nnine now here the robot will not get any reward for going to a state\nmarked in yellow. Hence the ER s comma a is 0 here but the robot knows the value\nof being in the yellow room. Hence V of s Dash is\none following this",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25550.0,
    "t_end": 25580.0,
    "text": "but the robot knows the value\nof being in the yellow room. Hence V of s Dash is\none following this for the other states. We should get 0.9 then again, if we put 0.9 in this equation, we get 0.81 than 0.7 to 9\nand then we again reach the starting point. So this is how the table looks with\nsome value Footprints computed from the Bellman equation now\na couple of things to It is here is that the max function\nhas the robot to always choose the state that gives it the maximum value\nof being in that state.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25575.0,
    "t_end": 25605.0,
    "text": "to It is here is that the max function\nhas the robot to always choose the state that gives it the maximum value\nof being in that state. Now the discount Factor\ngamma notifies the robot about how far it is\nfrom the destination. This is typically specified by\nthe developer of the algorithm. That would be installed\nin the robot. Now, the other states can also\nbe given their respective values in a similar way. So as you can see here\nthe boxes adjacent to the green one have one and if we Move away from 1 we\nget 0.9 0.8 1 0 1 7 to 9",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25600.0,
    "t_end": 25630.0,
    "text": "So as you can see here\nthe boxes adjacent to the green one have one and if we Move away from 1 we\nget 0.9 0.8 1 0 1 7 to 9 and finally we reach 0.66. Now the robot now\ncan precede its way through the Green Room utilizing\nthese value Footprints event if it's dropped\nat any arbitrary room in the given location now, if a robot Lance up in\nthe highlighted Sky Blue Area, it will still find\ntwo options to choose from but eventually either\nof the parts will be good enough",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25625.0,
    "t_end": 25655.0,
    "text": "if a robot Lance up in\nthe highlighted Sky Blue Area, it will still find\ntwo options to choose from but eventually either\nof the parts will be good enough for the robot to take because Auto V\nthe value for prints and only that out. Now one thing to note is that the Bellman equation is one\nof the key equations in the world of reinforcement\nlearning and Q learning. So if we think realistically our\nsurroundings do not always work in the way we expect\nthere is always a bit of stochastic City\ninvolved in it. So this applies\nto robot as well.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25650.0,
    "t_end": 25680.0,
    "text": "in the way we expect\nthere is always a bit of stochastic City\ninvolved in it. So this applies\nto robot as well. Sometimes it might so happen that the robots\nMachinery got corrupted. Sometimes the robot may come\nacross some hindrance on its way which it\nmay not be known to it beforehand. Right and sometimes even\nif the robot knows that it needs to take\nthe right turn it will not so how do we introduce\nthis to cast a city in our case now here comes\nthe Markov decision process. So consider the robot is\ncurrently in the Red Room",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25675.0,
    "t_end": 25705.0,
    "text": "in our case now here comes\nthe Markov decision process. So consider the robot is\ncurrently in the Red Room and it needs to go\nto the green room. Now. Let's now consider\nthe robot has a slight chance of dysfunctioning and might take\nthe left or the right or the bottom turn instead\nof digging the upper turn and are Get to the Green Room\nfrom where it is now, which is the Retro. Now the question is, how do we enable the robot\nto handle this when it is out in the given environment right. Now, this is a situation",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25700.0,
    "t_end": 25730.0,
    "text": "how do we enable the robot\nto handle this when it is out in the given environment right. Now, this is a situation where the decision making regarding which turn is\nto be taken is partly random and partly another control\nof the robot now partly random because we are not sure when exactly the robot mind\ndysfunctional and partly under the control of the robot because it is still making a decision of taking\na turn right on its own. And with the help\nof the program embedded into it. So a Markov decision process is a discrete time\nstochastic Control process.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25725.0,
    "t_end": 25755.0,
    "text": "And with the help\nof the program embedded into it. So a Markov decision process is a discrete time\nstochastic Control process. It provides a mathematical\nframework for modeling decision-making in situations where the outcomes\nare partly random and partly under the control\nof the decision maker. Now we need to give this concept a mathematical shape\nmost likely an equation which then can be taken further. Now you might be surprised that we can do this with the\nhelp of the Bellman equation.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25750.0,
    "t_end": 25780.0,
    "text": "which then can be taken further. Now you might be surprised that we can do this with the\nhelp of the Bellman equation. Action with a few minor tweaks. So if we have a look\nat the original Bellman equation V of X is equal to maximum of our s comma\na plus gamma V of s - what needs to be changed\nin the above equation so that we can introduce\nsome amount of Randomness here as long as we are not sure when the robot might not take\nthe expected turn. We are then also not sure\nin which room it might end up in which is nothing",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25775.0,
    "t_end": 25805.0,
    "text": "when the robot might not take\nthe expected turn. We are then also not sure\nin which room it might end up in which is nothing but the ROM it moves from its current room\nat this point according. To the equation. We are not sure of the a stash which is the next state\nor the room, but we do know all the probable\nturns the robot might take now in order to incorporate each of this probabilities\ninto the above equation. We need to associate\na probability with each of the turns to\nquantify the robot.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25800.0,
    "t_end": 25830.0,
    "text": "of this probabilities\ninto the above equation. We need to associate\na probability with each of the turns to\nquantify the robot. If it has got any expertise\nchance of taking the stern know if we do so we get\nPS is equal to maximum of RS comma a plus gamma\ninto summation of s - PS comma a comma s stash into V\nof his stash now the PS a-- and a stash is the probability of moving from room s\nto establish with the action a",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25825.0,
    "t_end": 25855.0,
    "text": "PS comma a comma s stash into V\nof his stash now the PS a-- and a stash is the probability of moving from room s\nto establish with the action a and the submission\nhere is the expectation of the situation. That's a robot in curse, which is the randomness now,\nlet's take a look at this example here. So when we associate the probabilities to each\nof these terms Owns, we essentially mean\nthat there is an 80% chance that the robot will\ntake the upper turn. Now, if you put all\nthe required values in our equation, we get V of s is equal\nto maximum of R of s comma a +",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25850.0,
    "t_end": 25880.0,
    "text": "that the robot will\ntake the upper turn. Now, if you put all\nthe required values in our equation, we get V of s is equal\nto maximum of R of s comma a + comma of 0.8 into V of room up plus zero point 1 into V\nof room down 0.03 into Rome of V of from left plus 0.03\ninto V of room right now note that the value footprints. Not change due to the fact that we are incorporating\nstochastically here. But this time we\nwill not calculate",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25875.0,
    "t_end": 25905.0,
    "text": "Not change due to the fact that we are incorporating\nstochastically here. But this time we\nwill not calculate those values Footprints instead. We will let the robot\nto figure it out. Now up until this point. We have not considered\nabout rewarding the robot for its action of going\ninto a particular room. We are only watering the robot when it gets\nto the destination now, ideally there should be a reward\nfor each action the robot takes to help it better assess\nthe quality of the actions, but the there was need\nnot to be always be the same",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25900.0,
    "t_end": 25930.0,
    "text": "ideally there should be a reward\nfor each action the robot takes to help it better assess\nthe quality of the actions, but the there was need\nnot to be always be the same but it is much better\nthan having some amount of reward for the actions\nthan having no rewards at all. Right and this idea is known as\nthe living penalty in reality. The reward system\ncan be very complex and particularly modeling\nsparse rewards is an active area of research in the domain\nof reinforcement learning. So by now we have got\nthe equation which we have a so",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25925.0,
    "t_end": 25955.0,
    "text": "of research in the domain\nof reinforcement learning. So by now we have got\nthe equation which we have a so what we're going to do is\nnow transition to Q learning. So this equation gives\nus the value of going to a particular State\ntaking the stochastic city of the environment into account. Now, we have also learned\nvery briefly about the idea of living penalty which deals with associating\neach move of the robot with a reward. So Q learning processes and idea of assessing\nthe quality of an action that is taken to move to\na state rather than determining",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25950.0,
    "t_end": 25980.0,
    "text": "So Q learning processes and idea of assessing\nthe quality of an action that is taken to move to\na state rather than determining the possible value of the state which is being moved\nto so earlier. We had 0.8 into V. E\nof s 1 0.03 into V of S 2 0 point 1 into V\nof S 3 and so on now if you incorporate the idea\nof assessing the quality of the action for moving\nto a certain state so the environment\nwith the agent and the quality of the action\nwill look something like this.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 25975.0,
    "t_end": 26005.0,
    "text": "if you incorporate the idea\nof assessing the quality of the action for moving\nto a certain state so the environment\nwith the agent and the quality of the action\nwill look something like this. So instead of 0.8 V of s 1 will have q of s\n1 comma a one will have q of S 2 comma 2 Q of S 3 now\nthe robot now has food. In states to choose from\nand along with that there are four different actions also for\nthe current state it is in so how do we calculate Q of s comma a that is the cumulative quality\nof the possible actions",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26000.0,
    "t_end": 26030.0,
    "text": "four different actions also for\nthe current state it is in so how do we calculate Q of s comma a that is the cumulative quality\nof the possible actions the robot might take so\nlet's break it down. Now from the equation V of s\nequals maximum a RS comma a + comma summation s -\nPSAs - into V of s - if we discard them. Maximum function we have is\nof a plus gamma into summation p and v now essentially\nin the equation",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26025.0,
    "t_end": 26055.0,
    "text": "Maximum function we have is\nof a plus gamma into summation p and v now essentially\nin the equation that produces V of s. We are considering\nall possible actions and all possible States\nfrom the current state that the robot is in and then we are taking the maximum value caused\nby taking a certain action and the equation produces\na value footprint, which is for just\none possible action. In fact, we can think\nof it as the quality of the So Q of s comma a\nis equal to RS comma a +",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26050.0,
    "t_end": 26080.0,
    "text": "which is for just\none possible action. In fact, we can think\nof it as the quality of the So Q of s comma a\nis equal to RS comma a + comma of summation p and v now that we have got an equation\nto quantify the quality of a particular action. We are going to make\na little adjustment in the equation we can now say that V of s is the maximum\nof all the possible values of Q of s comma a right. So let's utilize this fact",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26075.0,
    "t_end": 26105.0,
    "text": "that V of s is the maximum\nof all the possible values of Q of s comma a right. So let's utilize this fact and replace V of s Dash as\na function of Q. So Q U.s. Comma a becomes R of s comma a +\ncomma of summation PSAs - and maximum of the que es - a - so the equation of V is now\nturned into an equation of Q, which is the quality. But why would we do that now? This is done to\nease our calculations",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26100.0,
    "t_end": 26130.0,
    "text": "so the equation of V is now\nturned into an equation of Q, which is the quality. But why would we do that now? This is done to\nease our calculations because now we have\nonly one function Q which is also the core of the\ndynamic programming language. We have only one. Ocean Q to calculate and R of s comma a is\na Quantified metric which produces reward\nof moving to a certain State. Now, the qualities of the actions are\ncalled The Q values and from now on we will refer\nto the value Footprints",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26125.0,
    "t_end": 26155.0,
    "text": "of the actions are\ncalled The Q values and from now on we will refer\nto the value Footprints as the Q values\nan important piece of the puzzle is\nthe temporal difference. Now temporal difference\nis the component that will help the robot\ncalculate the Q values which respect to the changes\nin the environment over time. So consider Our robot is\ncurrently in the mark State and it wants to move\nto the Upper State. One thing to note that here is that the robot already knows\nthe Q value of making the action that is moving through\nthe Upper State and we know",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26150.0,
    "t_end": 26180.0,
    "text": "One thing to note that here is that the robot already knows\nthe Q value of making the action that is moving through\nthe Upper State and we know that the environment\nis stochastic in nature and the reward that the robot will get\nafter moving to the Upper State might be different\nfrom an earlier observation. So how do we capture\nthis change the real difference? We calculate the new q s comma a\nwith the same formula and subtract the Previously\nknown qsa from it. So this will in turn\ngive us the new QA.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26175.0,
    "t_end": 26205.0,
    "text": "and subtract the Previously\nknown qsa from it. So this will in turn\ngive us the new QA. Now the equation that we just derived gifts\nthe temporal difference in the Q values which further helps\nto capture the random changes in the environment which may impose now\nthe name q s comma a is updated as the following\nso Q T of s comma is equal to QT minus 1 s comma a plus Alpha D DT of a comma s now here Allah Alpha is\nthe learning rate which controls",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26200.0,
    "t_end": 26230.0,
    "text": "plus Alpha D DT of a comma s now here Allah Alpha is\nthe learning rate which controls how quickly the robot adapts\nto the random changes imposed by the environment the qts comma\nis the current state q value and a QT minus 1 s comma is\nthe previously recorded Q value. So if we replace the TDS comma a\nwith its full form equation, we should get Q T of s\ncomma is equal to QT - 1 of s comma y plus Alpha into R of s\ncomma a plus gamma maximum.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26225.0,
    "t_end": 26255.0,
    "text": "we should get Q T of s\ncomma is equal to QT - 1 of s comma y plus Alpha into R of s\ncomma a plus gamma maximum. Q s Dash a dash minus QT minus 1 s comma a now that we have all the little\npieces of q line together. Let's move forward\nto its implementation part. Now, this is the final equation\nof q-learning, right? So, let's see how we can implement this\nand obtain the best path for any robot to take now\nto implement the algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26250.0,
    "t_end": 26280.0,
    "text": "So, let's see how we can implement this\nand obtain the best path for any robot to take now\nto implement the algorithm. We need to understand\nthe warehouse location and how that can be mapped\nto different states. So let's start by reconnecting\nthe sample environment. So as you can see here, we have L1 L2 L3 to align\nand as you can see here, we have certain borders also. So first of all, let's map each of the above\nlocations in the warehouse",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26275.0,
    "t_end": 26305.0,
    "text": "we have certain borders also. So first of all, let's map each of the above\nlocations in the warehouse two numbers or the states so that it will ease\nour calculations, right? So what I'm going to do is\ncreate a new Python 3 file in the jupyter notebook\nand I'll name it as q-learning. Number. Okay. So let's define the states. But before that what we\nneed to do is import numpy because we're going to use numpy for this purpose and let's\ninitialize the parameters.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26300.0,
    "t_end": 26330.0,
    "text": "But before that what we\nneed to do is import numpy because we're going to use numpy for this purpose and let's\ninitialize the parameters. That is the gamma\nand Alpha parameters. So gamma is 0.75 which is the discount Factor\nwhereas Alpha is 0.9, which is the learning rate. Now next what we're going to do\nis Define the states and map it to numbers. So as I mentioned Earlier l\n1 is 0 and Dylan line. We have defined the states\nin the numerical form. Now. The next step is to define\nthe actions which is",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26325.0,
    "t_end": 26355.0,
    "text": "So as I mentioned Earlier l\n1 is 0 and Dylan line. We have defined the states\nin the numerical form. Now. The next step is to define\nthe actions which is as mentioned above\nrepresents the transition to the next state. So as you can see here, we have an array\nof actions from 0 to 8. Now, what we're going to do\nis Define the reward table. So as you can see,\nit's the same Matrix that we created just now that I showed you just now now\nif you understood it correctly, there isn't any real\nBarrel limitation",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26350.0,
    "t_end": 26380.0,
    "text": "that I showed you just now now\nif you understood it correctly, there isn't any real\nBarrel limitation as depicted in the image, for example, the transitional\nfor tell one is allowed but the reward will be\nzero to discourage that path or in tough situation. What we do is add\na minus 1 there so that it gets\na negative reward. So in the above code snippet\nas you can see here. I took each of the states and\nput once in the respective state that are directly reachable\nfrom the certain State now,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26375.0,
    "t_end": 26405.0,
    "text": "I took each of the states and\nput once in the respective state that are directly reachable\nfrom the certain State now, if you refer to that reward\ntable, once again, what we created the above, our reconstruction will\nbe easy to understand but one thing to note here is that we did not consider the top\npriority location L6 yet. We would also need\nan inverse mapping from the state's back\nto its original location and it will be cleaner when we reach to the utter\ndepths of the algorithms. So for that what we're going\nto do Is have the inverse",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26400.0,
    "t_end": 26430.0,
    "text": "when we reach to the utter\ndepths of the algorithms. So for that what we're going\nto do Is have the inverse map location State delegation. We will take the distinct\nState and location and convert it back. Now. What we'll do is we will now\nDefine a function get optimal which is the get optimal route, which will have a start location\nand an N location. Don't worry. The code is pick but I'll explain you each\nand every bit of the code. Now the get optimal\nroute function will take",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26425.0,
    "t_end": 26455.0,
    "text": "Don't worry. The code is pick but I'll explain you each\nand every bit of the code. Now the get optimal\nroute function will take two arguments the style location\nin the warehouse and the end location\nin the warehouse recipe lovely and it will return\nthe optimal route for reaching the end location from the starting location\nin the form of an ordered list containing the letters. So we'll start by defining the function by initializing\nthe Q values to be all zeros. So as you can see here, we have given the Q value\nhas to be 0 but For that",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26450.0,
    "t_end": 26480.0,
    "text": "the function by initializing\nthe Q values to be all zeros. So as you can see here, we have given the Q value\nhas to be 0 but For that what we need to do is copy\nthe reward Matrix to a new one. So this is the rewards\nnew and next again. What we need to do is get\nthe ending State corresponding to the ending location. And with this information\nautomatically will set the priority of the given ending\nstay to the highest one that we are not defining it now, but will automatically\nset the priority of the given ending\nState as nine nine nine. So what we're going\nto do is initialize",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26475.0,
    "t_end": 26505.0,
    "text": "but will automatically\nset the priority of the given ending\nState as nine nine nine. So what we're going\nto do is initialize the Q values to be 0 and\nin the queue learning process what you can see See here. We are taking I in range\n1,000 and we're going to pick up a state randomly. So we're going to use\nthe MP dot random r + NT and for traversing\nthrough the neighbor location in the same maze. We're going to iterate\nthrough the new reward Matrix and get the actions which are greater\nthan 0 and after that what we're going to do is pick\nan action randomly from the list",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26500.0,
    "t_end": 26530.0,
    "text": "Matrix and get the actions which are greater\nthan 0 and after that what we're going to do is pick\nan action randomly from the list of the playable actions in years to the next state will going to compute\nthe temporal difference, which is TD, which is the rewards plus gamma\ninto The queue of next state and will take n p dot ARG Max of Q of next eight minus Q\nof the current state. We going to then update the Q values using\nthe Bellman equation as you can see here, you have the Bellman equation and we're going\nto update the Q values",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26525.0,
    "t_end": 26555.0,
    "text": "the Q values using\nthe Bellman equation as you can see here, you have the Bellman equation and we're going\nto update the Q values and after that we're going\nto initialize the optimal route with a starting location\nnow here we do not know what the next location yet. So initialize it with the value\nof the starting location, which again is the random Shh\nnow we do not know about the exact number\nof iteration needed to reach to the final location. Hence while loop will be\na good choice for the iteration. So when you're going to fetch\nthe starting State fetch",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26550.0,
    "t_end": 26580.0,
    "text": "to the final location. Hence while loop will be\na good choice for the iteration. So when you're going to fetch\nthe starting State fetch the highest Q value penetrating to the starting State\nwe go to the index or the next state, but we need\nthe corresponding letter. So we're going to use that state\nto location function. We just mentioned there and after that we're going\nto update the starting location for the next iteration. Finally, we'll return the root. So let's take the starting\nlocation of n line",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26575.0,
    "t_end": 26605.0,
    "text": "Finally, we'll return the root. So let's take the starting\nlocation of n line and and location of L1 and see\nwhat part do we actually get? So as you can see here, we get Airline l8l\nfive L2 and L1. And if you have a look\nat the image here, we have if we start from L9 to L1 we got l8l 5 L\n2 l 1 L HL 5 L2 L1. That would yield us the maximum. Mm value of the maximum\nreward for the robot.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26600.0,
    "t_end": 26630.0,
    "text": "to L1 we got l8l 5 L\n2 l 1 L HL 5 L2 L1. That would yield us the maximum. Mm value of the maximum\nreward for the robot. So now we have come to the end of this Q learning session\nthe past year has seen a lot of great examples\nfor machine learning and many new high-impact application of machine\nlearning with discovered and brought to light especially\nin the healthcare Finance the speech recognition\naugmented reality",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26625.0,
    "t_end": 26655.0,
    "text": "application of machine\nlearning with discovered and brought to light especially\nin the healthcare Finance the speech recognition\naugmented reality and much more complex 3D\nand video applications. The natural language\nprocessing was easily the most talked about domain within the community\nwith the likes of you. Lmf it and but\nbeing open sourced. So let's have a look at some of the amazing\nmachine learning projects which are open sourced\nthe code is available for you. And those are discussed in\nthis 2018 to nine in Spectrum.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26650.0,
    "t_end": 26680.0,
    "text": "which are open sourced\nthe code is available for you. And those are discussed in\nthis 2018 to nine in Spectrum. So the first and the foremost\nis tensorflow dot DS now machine learning in the browser or fictional thought\na few years back. Back and a stunning reality. Now a lot of us in this field\nare welded to our favorite IDE, but tells of not DOT JS has the\npotential to change your habits. It's become a very popular\nreleased since its release earlier this year and continues to amaze\nwith its flexibility.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26675.0,
    "t_end": 26705.0,
    "text": "It's become a very popular\nreleased since its release earlier this year and continues to amaze\nwith its flexibility. Now as a repository states, there are primarily\nthree major features of terms of rho dot J's\ndevelop machine learning and deep learning models in your process\nitself run pre-existent as a flow models within\nthe browser retrain our Gene these prediction models as well. And if you are familiar with\nKara's the high-level layers EPA will seem quite familiar, but there are plenty of examples\navailable on GitHub repository.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26700.0,
    "t_end": 26730.0,
    "text": "And if you are familiar with\nKara's the high-level layers EPA will seem quite familiar, but there are plenty of examples\navailable on GitHub repository. So do check out those legs\nto Quicken your learning curve. And as I mentioned earlier, I'll leave the links\nto all of these open source machine learning projects\nin the description below. The next what we\nnot discuss is detector on it is developed by Facebook\nand made a huge Splash when it was earlier launched in. An 80 those developed by\nFacebook's AI research team, which is fa ir. And it implements the state",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26725.0,
    "t_end": 26755.0,
    "text": "An 80 those developed by\nFacebook's AI research team, which is fa ir. And it implements the state of the art object\ndetection frame was it is written in Python and as help enable\nmultiple projects including the dance pose. Now, we'll know what exactly is then suppose\nafter this example and this repository\ncontains the code of over 70 preacher involves. So it's a very good\nopen source small guys. So to check it out now\nthe moment I talked about then suppose. That's the next one. I'm going to talk about so That's supposed stents human\npose estimation in the wild,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26750.0,
    "t_end": 26780.0,
    "text": "So to check it out now\nthe moment I talked about then suppose. That's the next one. I'm going to talk about so That's supposed stents human\npose estimation in the wild, but the code to train\nand evaluate your own dance pose using the our CNN model\nis included here and I've given the link\nto the open source code in the description below and there are notebooks\navailable as well to visualize certain Sports cocoa data set\nthe next on our list. We have D\npainterly harmonization. Now, I want you to take\na moment to just admire the above images. Can you tell which ones\nwe're done by a human",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26775.0,
    "t_end": 26805.0,
    "text": "We have D\npainterly harmonization. Now, I want you to take\na moment to just admire the above images. Can you tell which ones\nwe're done by a human and which one by a machine? I certainly could not now here. The first frame is\nthe input image the original one and a third frame as you can see here\nhas been generated by this technique amazing, right? The algorithm has\nan external object to your choosing to any image and manages it to make it look\nlike nothing touched it now, make sure you check out\nthe code and try to implement it",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26800.0,
    "t_end": 26830.0,
    "text": "and manages it to make it look\nlike nothing touched it now, make sure you check out\nthe code and try to implement it on different sets\nof images yourself. It is really really fun. But talking about images. We have image out painting now what if I give you an image and\nask you to extend Its boundaries by imagining what it would look like when the entire\nscene was captured. You would understandably turn\nto some image editing software. But here's the awesome news. You can achieve it\nin few lines of code, which is the image out painting. Now.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26825.0,
    "t_end": 26855.0,
    "text": "But here's the awesome news. You can achieve it\nin few lines of code, which is the image out painting. Now. This project is Akira's\nimplementation of Stanford image out failing paper, which is incredibly cool\nand Illustrated paper. And this is how most\nresearch paper should be. I've given the links\nin the description below to check it out\nguys and see how you can. Implement it now. Let's talk about audio\nprocessing which is an another field where machine learning\nhas started to make its mark. It is not just limited\nto generate music. You can do tasks like audio\nclassification fingerprinting",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26850.0,
    "t_end": 26880.0,
    "text": "where machine learning\nhas started to make its mark. It is not just limited\nto generate music. You can do tasks like audio\nclassification fingerprinting segmentation tagging and much\nmore and there is a lot that's still yet to be explored and who knows perhaps you\ncould use this project to Pioneer your way to the top. Now what if you want\nto discover your own planner now that might perhaps\nbe overstating things a bit, but the astronaut repository\nwill definitely get you close. The Google brain team discovered two new planets in the summer\n2017 by applying the astronaut.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26875.0,
    "t_end": 26905.0,
    "text": "The Google brain team discovered two new planets in the summer\n2017 by applying the astronaut. It's a deep neural network\nmeant for working with astronomical data. It goes to show\nthe far-ranging application of machine learning and was\na truly Monumental development. And now the team behind the technology has\nopen source the entire code, so go ahead and check\nout your own planet and who knows you might even have\na planet on your name now, I could not possibly\nlet this section. Pass by without\nmentioning the brt.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26900.0,
    "t_end": 26930.0,
    "text": "who knows you might even have\na planet on your name now, I could not possibly\nlet this section. Pass by without\nmentioning the brt. The Google AI is released\nhas smashed record on his way to winning the hearts\nof NLP enthusiasts and experts alike following you. Lmf it and he LMO brt really\nblew away the competition with its performance. It obtained a state\nof art result on 11 and LP task apart from\nthe official Google repository. There is a python\nimplementation of birth, which is worth checking out\nwhether it makes a new era",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26925.0,
    "t_end": 26955.0,
    "text": "on 11 and LP task apart from\nthe official Google repository. There is a python\nimplementation of birth, which is worth checking out\nwhether it makes a new era or not in natural\nlanguage processing. The thing we will soon\nfind out now add on it. I'm sure you guys\nmight have heard of it. It is a framework\nfor automatically learning high quality models without\nrequiring programming expertise since it's a Google invention. The framework is based\non tensorflow and you can build and simple models\nusing a Danette and even extend it to use\nto train a neural network.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26950.0,
    "t_end": 26980.0,
    "text": "The framework is based\non tensorflow and you can build and simple models\nusing a Danette and even extend it to use\nto train a neural network. Now the GitHub page contains\nthe code and example the API documentation and other things to get\nyour hands dirty the trust me Otto ml is the next big thing. NG in our field now if you follow a few researchers\non social media, you must have come\nacross some of the images. I am showing here in a video form a stick human\nrunning across the terrain or trying to stand\nup or some sort, but that my friends\nis reinforcement learning",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 26975.0,
    "t_end": 27005.0,
    "text": "in a video form a stick human\nrunning across the terrain or trying to stand\nup or some sort, but that my friends\nis reinforcement learning and action now, here's a signature example\nof it a framework to create a simulated humanoid to imitate\nmultiple motion skin. So let's have a look\nat the top 10 skills. Are required to become a successful machine\nlearning engineer. So starting with\nprogramming languages python is the lingua Franca\nof machine learning. You may have had\nexposure to buy them. Even if you weren't previously",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27000.0,
    "t_end": 27030.0,
    "text": "So starting with\nprogramming languages python is the lingua Franca\nof machine learning. You may have had\nexposure to buy them. Even if you weren't previously in programming or in a computer\nscience research field. However, it is important to have\na solid understanding of glasses and data structures. Sometimes python won't\nbe enough often. You'll encounter projects that need to leverage hardware\nfor Speed improvements. Now, make sure you are familiar\nwith the basic algorithms as well as the classes. Memory management\nand linking now if you want a job\nin machine learning, you will probably have\nto learn all of these languages",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27025.0,
    "t_end": 27055.0,
    "text": "Memory management\nand linking now if you want a job\nin machine learning, you will probably have\nto learn all of these languages at some point C++ can help\nin speeding code up. Whereas our works great\nin statistics and plots and Hadoop is java-based. So you probably need\nto implement mappers and reducers in Java. Now next we have linear algebra. You need to be intimately\nfamiliar with mattresses vectors and matrix multiplication if you have an understanding\nof derivatives and integrals, You should be in the clear.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27050.0,
    "t_end": 27080.0,
    "text": "and matrix multiplication if you have an understanding\nof derivatives and integrals, You should be in the clear. Otherwise even simple concept like gradient descent\nwill elude you statistic is going to come up a lot at\nleast make sure you are familiar with the caution distributions\nmeans standard deviation and much more every bit\nof statistical understanding Beyond this helps\nthe theories help in learning about algorithms great\nsamples are naive buys gaussian mixture models\nand hidden Markov models.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27075.0,
    "t_end": 27105.0,
    "text": "about algorithms great\nsamples are naive buys gaussian mixture models\nand hidden Markov models. You need to have a firm\nunderstanding of probability and stats to understand\nthese these models just go nuts and study measure Theory and next we have advanced\nsignal processing techniques. Now feature extraction is one\nof the most important parts of machine learning\ndifferent types of problems need various Solutions. You may be able to utilize\nreally cool Advanced signal processing algorithms\nsuch as wavelets share. Let's go blades\nand bandless you need to learn",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27100.0,
    "t_end": 27130.0,
    "text": "signal processing algorithms\nsuch as wavelets share. Let's go blades\nand bandless you need to learn about the time-frequency\nanalysis and try to apply it in your problems. Now, this skill will give\nyou an edge over all the other skills not this kid. Will give you an edge while you're applying for a machine learning engine\nthe job or others or next we have applied maths a lot of machine\nlearning techniques out. There are just fancy types\nof functional approximation. Now these often get developed\nby theoretical mathematician and then get applied by people",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27125.0,
    "t_end": 27155.0,
    "text": "There are just fancy types\nof functional approximation. Now these often get developed\nby theoretical mathematician and then get applied by people who do not understand\nthe theory at all. Now the result is that many developers\nmight have a hard time finding the best techniques\nfor the problem. So even a basic understanding\nof numerical analysis will give you a huge Edge having\na firm understanding. Ending of algorithm\nTheory and knowing how the algorithm works. You can also discriminate models\nsuch as svm's now you will need to understand subjects such as gradient descent convex\noptimization LaGrange",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27150.0,
    "t_end": 27180.0,
    "text": "You can also discriminate models\nsuch as svm's now you will need to understand subjects such as gradient descent convex\noptimization LaGrange quadratic programming partial\ndifferentiation equations and much more now all this math\nmight seem intimidating at first if you have been away\nfrom it for a while just machine learning is\nmuch more math intensive than something like\nfront-end developer. Just like any other skill\ngetting better at math is a man. Our Focus practice\nthe next skill in our list is the neural\nnetwork architectures. We need machine learning\nfor tasks that are too complex",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27175.0,
    "t_end": 27205.0,
    "text": "Our Focus practice\nthe next skill in our list is the neural\nnetwork architectures. We need machine learning\nfor tasks that are too complex for human to quote\ndirectly that is tasks that are so complex that it is Impractical now\nneural networks are a class of models within the general\nmachine learning literature or neural networks are\na specific set of algorithms that have revolutionized\nmachine learning. They're inspired by\nbiological neural networks, and the current so-called\ndeep neural networks have proven to work quite well. Well, the neural\nnetworks are themselves",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27200.0,
    "t_end": 27230.0,
    "text": "and the current so-called\ndeep neural networks have proven to work quite well. Well, the neural\nnetworks are themselves General function approximations, which is why they can be applied to almost\nany machine learning problem about learning a complex mapping from the input\nto the output space. Of course, there are still\ngood reason for the surge in the popularity\nof neural networks, but neural networks have been\nby far the most accurate way of approaching many problems like\ntranslation speech recognition and image classification now\ncoming to our next point which is the natural\nlanguage processing now",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27225.0,
    "t_end": 27255.0,
    "text": "approaching many problems like\ntranslation speech recognition and image classification now\ncoming to our next point which is the natural\nlanguage processing now since it combines\ncomputer science and Listed, there are a bunch of libraries\nlike the NLT K chances. Mm and the techniques\nsuch as sentimental analysis and summarization that are unique to NLP now audio\nand video processing has a frequent overlap with\nthe natural language processing. However, natural language\nprocessing can be applied to non audio data\nlike text voice and audio analysis involves\nextracting useful information",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27250.0,
    "t_end": 27280.0,
    "text": "However, natural language\nprocessing can be applied to non audio data\nlike text voice and audio analysis involves\nextracting useful information from the audio signals\nthemselves being well-versed in math will get\nyou far in this one and you should also be familiar. Her with the concepts such as\nthe fast Fourier transforms. Now, these were\nthe technical skills that are required to become a successful\nmachine learning engineer. So next I'm going to discuss\nsome of the non-technical skills or the soft skills, which are required to become\na machine-learning engineer.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27275.0,
    "t_end": 27305.0,
    "text": "So next I'm going to discuss\nsome of the non-technical skills or the soft skills, which are required to become\na machine-learning engineer. So first of all,\nwe have the industry knowledge. Now the most successful\nmachine learning projects out. There are going to be those that address real pain points\nwhichever industry we are working for you should know how that industry works and Will be beneficial\nfor the business if a machine learning engineer\ndoes not have business Acumen and the know-how of the elements that make up\na successful business model or any particular algorithm.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27300.0,
    "t_end": 27330.0,
    "text": "and the know-how of the elements that make up\na successful business model or any particular algorithm. Then all those technical skills\ncannot be Channel productively, you won't be able\nto discern the problems and potential challenges\nthat need solving for the business to sustain and grow you won't\nreally be able to help your organization explore\nnew business opportunities. So this is a must-have\nskill now next we have effective communication. You'll need to explain\nthe machine learning Concepts to the people\nwith little to no expertise in the field chances\nare you'll need to work",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27325.0,
    "t_end": 27355.0,
    "text": "You'll need to explain\nthe machine learning Concepts to the people\nwith little to no expertise in the field chances\nare you'll need to work with a team of Engineers as\nwell as many other teams. So communication is going\nto make all of this much more easier companies searching for a strong machine learning\nengineer looking for someone who can clearly and fluently translate\ntheir technical findings to a non technical team\nsuch as marketing or sales department\nand next on our list. We have rapid prototyping so\nIterating on ideas as quickly as",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27350.0,
    "t_end": 27380.0,
    "text": "or sales department\nand next on our list. We have rapid prototyping so\nIterating on ideas as quickly as possible is mandatory\nfor finding one that works in machine learning\nthis applies to everything from picking up the right model to working on projects\nsuch as A/B Testing you need to do a group of techniques used to quickly\nfabricate a scale model of a physical part or assembly using the three-dimensional\ncomputer aided design, which is the cat so last but not the least we\nhave the final skill",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27375.0,
    "t_end": 27405.0,
    "text": "the three-dimensional\ncomputer aided design, which is the cat so last but not the least we\nhave the final skill and that is to keep updated. You must stay up to date\nwith Any upcoming changes every month new neural\nnetwork models come out that are performed\nthe previous architecture. It also means being aware of the news regarding\nthe development of the tools the changelog the conferences and much more you need to know about\nthe theories and algorithms. Now this you can achieve by reading the research papers\nblogs the conference's videos.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27400.0,
    "t_end": 27430.0,
    "text": "need to know about\nthe theories and algorithms. Now this you can achieve by reading the research papers\nblogs the conference's videos. And also you need to focus\non the online community with changes very quickly. So expect and cultivate\nthis change now, this is not the Here we have\ncertain skills the bonus skills, which will give you an edge\nover other competitors or the other persons who are applying for a machine-learning engineer\nposition on the bonus point. We have physics. Now, you might be in a situation where you're like to apply\nmachine learning techniques to A system",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27425.0,
    "t_end": 27455.0,
    "text": "We have physics. Now, you might be in a situation where you're like to apply\nmachine learning techniques to A system that will interact with the real\nworld having some knowledge of physics will take\nyou far the next we have reinforcement learning. So this reinforcement learning\nhas been a driver behind many of the most\nexciting developments in the Deep learning and the AI community. T from the alphago zero to\nthe open a is Dota 2 pot. This will be\na critical to understand if you want to go\ninto robotics self-driving cars or other AI related areas. And finally we have",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27450.0,
    "t_end": 27480.0,
    "text": "if you want to go\ninto robotics self-driving cars or other AI related areas. And finally we have computer vision out of all\nthe disciplines out there. There are by far the most resources available\nfor learning computer vision. This field appears to have\nthe lowest barriers to entry but of course this likely means you will face\nslightly more competition. So having a good knowledge\nof computer vision how it rolls will\ngive you an edge. Other competitors now. I hope you got acquainted\nwith all the skills which are required\nto become a successful",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27475.0,
    "t_end": 27505.0,
    "text": "Other competitors now. I hope you got acquainted\nwith all the skills which are required\nto become a successful machine learning engineer. As you know, we are living in the worlds\nof humans and machines in today's world. These machines are\nthe robots have to be programmed before they start\nfollowing your instructions. But what if the machine started learning on its own from\ntheir experience work like us and feel like us and do things more\naccurately than us now? Well his machine learning Angela\ncomes into picture to make sure",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27500.0,
    "t_end": 27530.0,
    "text": "learning on its own from\ntheir experience work like us and feel like us and do things more\naccurately than us now? Well his machine learning Angela\ncomes into picture to make sure everything is working\naccording to the procedures and the guidelines. So in my opinion machine\nlearning is one of the most recent and And Technologies, there is you probably use it\nat dozens of times every day without even knowing it. So before we indulge into the different roles\nthe salary Trends and what should be\nthere on the resume of a machine learning engineer while applying for a job. Let's understand",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27525.0,
    "t_end": 27555.0,
    "text": "and what should be\nthere on the resume of a machine learning engineer while applying for a job. Let's understand who exactly a machine learning\nengineering is so machine learning Engineers are\nsophisticated programmers who develop machines and systems that can learn and apply knowledge without\nspecific Direction artificial intelligence is the goal\nof a machine-learning engineer. They are computer programmers but their focus goes\nbeyond specifically programming machines to\nperform specific tasks. They create programs that will enable\nmachines to take actions",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27550.0,
    "t_end": 27580.0,
    "text": "programming machines to\nperform specific tasks. They create programs that will enable\nmachines to take actions without being specifically\ndirected to perform those tasks. Now if we have a look\nat the job trends of machine learning in general. So as you can see\nin Seattle itself, we have 2,000 jobs in New York. We have 1100 San Francisco. We have 1100 in Bengaluru India, we have 1100 and then\nwe have Sunnyvale, California where we have\nIf I were a number of jobs, so as you can see the number of\njobs in the market is too much",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27575.0,
    "t_end": 27605.0,
    "text": "California where we have\nIf I were a number of jobs, so as you can see the number of\njobs in the market is too much and probably with the emergence\nof machine learning and artificial intelligence. This number is just\ngoing to get higher now. If you have a look at the job\nopening salary-wise percentage, so you can see for the $90,000\nper annum bracket. We have 32.7 percentage\nand that's the maximum. So be assured that if you get a job as\na machine-learning engineer, you'll probably get\naround 90 thousand bucks a year. That's safe to say.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27600.0,
    "t_end": 27630.0,
    "text": "that if you get a job as\na machine-learning engineer, you'll probably get\naround 90 thousand bucks a year. That's safe to say. Now for the hundred and\nten thousand dollars per year. We have 25% $120,000. We have 20 percent almost then we have a hundred\nand thirty thousand dollars which are the senior\nmachine learning and Jenna's that's a 13 point\n6 7% And finally, we have the most senior\nmachine learning engineer or we have\nthe data scientist here, which have the salary of a hundred and forty thousand\ndollars per annum",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27625.0,
    "t_end": 27655.0,
    "text": "or we have\nthe data scientist here, which have the salary of a hundred and forty thousand\ndollars per annum and the percentage\nfor that one is really low. So as you can see there is\na great opportunity for people. What trying to go\ninto machine learning field and get started with it? So let's have a look\nat the machine learning in junior salary. So the average salary\nin the u.s. Is around a hundred eleven\nthousand four hundred and ninety dollars and the average salary\nin India is around seven last nineteen thousand\nsix hundred forty six rupees.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27650.0,
    "t_end": 27680.0,
    "text": "and ninety dollars and the average salary\nin India is around seven last nineteen thousand\nsix hundred forty six rupees. That's a very\ngood average salary for any particular profession. So moving forward\nif we have a look at the salary of\nan entry-level machine learning. You know, so the salary\nranges from $76,000 or seventy seven thousand\ndollars two hundred and fifty one thousand\ndollars per annum. That's a huge salary. And if you talk\nabout the bonus here, we have like three thousand dollars to twenty\nfive thousand dollars depending",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27675.0,
    "t_end": 27705.0,
    "text": "That's a huge salary. And if you talk\nabout the bonus here, we have like three thousand dollars to twenty\nfive thousand dollars depending on the work YouTube and\nthe project you are working on. Let's talk about\nthe profit sharing now. So it's around\ntwo thousand dollars to fifty thousand dollars. Now this again depends upon the project you are working\nthe company you are working for and the percentage that Give to the in general\nor the developer for that particular project. Now, the total pay comes around\nseventy six thousand dollars or seventy-five thousand dollars two hundred and sixty\ntwo thousand dollars",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27700.0,
    "t_end": 27730.0,
    "text": "for that particular project. Now, the total pay comes around\nseventy six thousand dollars or seventy-five thousand dollars two hundred and sixty\ntwo thousand dollars and this is just for the entry\nlevel machine learning engineer. Just imagine if you become\nan experience machine learning engineer your salary\nis going to go through the roof. So now that we have understood who exactly is\na machine learning engineer the various salary Trends\nthe job Trends in the market and how it's rising. Let's understand. What skills it takes to become\na machine learning engine. So first of all,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27725.0,
    "t_end": 27755.0,
    "text": "Let's understand. What skills it takes to become\na machine learning engine. So first of all, we have programming languages\nnow programming languages are big deal when it comes\nto machine learning because you don't just\nneed to have Proficiency in one language you might\nrequire Proficiency in Python. Java are or C++ because you might be working\nin a Hadoop environment where you require Java programming to do\nthe mapreduce Coatings and sometimes our is very great for visualization purposes\nand python has you know,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27750.0,
    "t_end": 27780.0,
    "text": "Java programming to do\nthe mapreduce Coatings and sometimes our is very great for visualization purposes\nand python has you know, Another favorite languages when comes to machine\nlearning now next scale that particular individual needs\nis calculus and statistics. So a lot of machine learning\nalgorithms are mostly maths and statistics. So and a lot of static is required majorly\nthe matrix multiplication and all so good understanding of calculus as well as\nstatistic is required. Now next we have signal processing now Advanced\nsignal processing is something",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27775.0,
    "t_end": 27805.0,
    "text": "of calculus as well as\nstatistic is required. Now next we have signal processing now Advanced\nsignal processing is something that will give you an upper Edge over other machine\nlearning engine is if you are Applying\nfor a job anywhere. Now the next kill we\nhave is applied maths as I mentioned earlier\nmany of the machine learning algorithms here are\npurely mathematical formulas. So a good understanding of maths\nand how the algorithm Works will take you far ahead\nthe next on our list. We have neural networks. No real networks are something",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27800.0,
    "t_end": 27830.0,
    "text": "will take you far ahead\nthe next on our list. We have neural networks. No real networks are something that has been emerging quite popularly in the recent\nyears and due to its efficiency and the extent to which it\ncan walk and get the results as soon as possible. Neural networks are a must for machine learning engine\nnow moving forward. We have language processing. So a lot of times machine\nlearning Engineers have to deal with text Data the voice data\nas well as video data now processing any kind\nof language audio",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27825.0,
    "t_end": 27855.0,
    "text": "with text Data the voice data\nas well as video data now processing any kind\nof language audio or the video is something that a machine-learning engineer\nhas to do on a daily basis. So one needs to be proficient\nin this area also now, these are only some\nof the few skills which are absolutely necessary. I would say for\nany machine learning and Engineer so let's\nnow discuss the job description or the roles and responsibilities of a particular machine\nlearning engineer now depending on their level",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27850.0,
    "t_end": 27880.0,
    "text": "or the roles and responsibilities of a particular machine\nlearning engineer now depending on their level of expertise machine\nlearning Engineers may have to study and transform\ndata science prototypes. They need to design\nmachine Learning Systems. They also need to research and\nImplement appropriate machine learning algorithms and tools as it's a very\nimportant part of the job. They need to develop\nnew machine learning application according to the industry\nrequirements the Select the appropriate data sets and the data\nrepresentation methods because if there is a slight\ndeviation in the data set",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27875.0,
    "t_end": 27905.0,
    "text": "according to the industry\nrequirements the Select the appropriate data sets and the data\nrepresentation methods because if there is a slight\ndeviation in the data set and the data representation that's going to\naffect Model A lot. They need to run machine\nlearning tests and experiments. They need to perform\nstatistical analysis and fine-tuning using\nthe test results. So sometimes people ask what exactly is a difference\nbetween a data analyst and a machine learning engineer. So so static analysis just a small part of of\nmachine learning Engineers job.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27900.0,
    "t_end": 27930.0,
    "text": "what exactly is a difference\nbetween a data analyst and a machine learning engineer. So so static analysis just a small part of of\nmachine learning Engineers job. Whereas it is a major part or it probably covers a large\npart of a data analyst job rather than a machine\nlearning Engineers job. So machine learning\nEngineers might need to train and retrain the systems\nwhenever necessary and they also need to extend the existing\nmachine learning libraries and Frameworks to\ntheir full potential so that they could make\nthe model Works superbly and finally they need to keep\nabreast of the developments",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27925.0,
    "t_end": 27955.0,
    "text": "to extend the existing\nmachine learning libraries and Frameworks to\ntheir full potential so that they could make\nthe model Works superbly and finally they need to keep\nabreast of the developments in the field needless to say that any machine. In general or any particular\nindividual has to stay updated to the technologies that are coming in the market and every now and then\na new technology arises which will overthrow\nthe older one. So you need to be\nup to date now coming to the resume part\nof a machine learning engineer. So any resume of a particular\nmachine learning Engineers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27950.0,
    "t_end": 27980.0,
    "text": "to the resume part\nof a machine learning engineer. So any resume of a particular\nmachine learning Engineers should consist like clear\ncareer objective skills, which a particular\nindividual possesses the educational qualification certain certification\nthe past experience if you are an experienced\nmachine learning and Jen are the projects which you\nhave worked on and that's it. So let's have a look\nat the various elements that are required in a machine-learning\nEngineers resume. So first of all, you need to have\na clear career objective.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 27975.0,
    "t_end": 28005.0,
    "text": "that are required in a machine-learning\nEngineers resume. So first of all, you need to have\na clear career objective. So here you will need\nnot stretch it too much and keep it as\nprecise as possible. So next we have the skills\nrequired and these skills can be technical as\nwell as non technical. So let's have a look at the various Technical and\nnon-technical skills out here. So starting with\nthe technical skills. First of all, we have programming languages\nas an our Java Python and C++. But the first and the foremost requirement\nis to have a good grip",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28000.0,
    "t_end": 28030.0,
    "text": "we have programming languages\nas an our Java Python and C++. But the first and the foremost requirement\nis to have a good grip on any programming languages\npreferably python as it is easy to learn and it's applications are wider\nthan any other language now, it is important to have\na good understanding of topics like data structures memory\nmanagement and classes. All the python is\na very good language it alone cannot help you so you will probably\nhave to learn all these he's languages\nlike C++ are python Java and also work on mapreduce",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28025.0,
    "t_end": 28055.0,
    "text": "so you will probably\nhave to learn all these he's languages\nlike C++ are python Java and also work on mapreduce at some point of time\nthe next on our list. We have calculus and linear\nalgebra and statistics. So you'll need to be\nintimately familiar with matrices the vectors\nand the matrix multiplication. So statistics is going\nto come up a lot and at least make sure\nyou are familiar with caution distribution\nmeans standard deviations and much more. So you also need to have a firm\nunderstanding of probability.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28050.0,
    "t_end": 28080.0,
    "text": "with caution distribution\nmeans standard deviations and much more. So you also need to have a firm\nunderstanding of probability. Stats to understand the machine\nlearning models the next as I mentioned earlier, it's\nsignal processing techniques. So feature extraction is one\nof the most important parts of machine learning different types of problems\nneed various Solutions. So you may be able to utilize the really cool Advanced signal\nprocessing algorithms such as wavelengths shallots curve. Let's and the ballast\nso try to learn about",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28075.0,
    "t_end": 28105.0,
    "text": "the really cool Advanced signal\nprocessing algorithms such as wavelengths shallots curve. Let's and the ballast\nso try to learn about the time-frequency analysis and\ntry to apply it to your problems as it gives you an upper jaw. Our other machine\nlearning Engineers, so just go for the next we have mathematics and a lot of\nmachine learning techniques out. There are just fancy types\nof function approximation having a firm understanding\nof algorithm Theory and knowing how the algorithm works\nis really necessary and understanding subjects like gradient descent\nconvex optimization",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28100.0,
    "t_end": 28130.0,
    "text": "how the algorithm works\nis really necessary and understanding subjects like gradient descent\nconvex optimization quadratic programming and partial differentiation will\nhelp a lot the neural networks as I was talking earlier. So we need machine learning\nfor tasks that are too Flex for humans to quote directly. So that is the tasks\nthat are so complex that it is Impractical neural\nnetworks are a class of models within the general\nmachine learning literature. They are specific\nset of algorithms that have revolutionized machine",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28125.0,
    "t_end": 28155.0,
    "text": "of models within the general\nmachine learning literature. They are specific\nset of algorithms that have revolutionized machine learning deep neural networks\nhave proven to work quite well and neural networks are themself General\nfunction approximations, which is why they can be applied to almost any machine\nlearning problem out there and they help a lot\nabout learning a complex mapping from the input to The output space now next\nwe have language processing since natural language\nprocessing combines two of the major areas of work that are linguistic\nand computer science",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28150.0,
    "t_end": 28180.0,
    "text": "since natural language\nprocessing combines two of the major areas of work that are linguistic\nand computer science and chances are at some point\nyou are going to work with either text\nor audio or the video. So it's necessary to have\na control over libraries like gents mm and ltk and techniques like\nwhat to wet sentimental analysis and text summarization Now voice and audio analysis involves\nextracting useful information from the Your signals themselves\nvery well versed in maths and concept like Fourier\ntransformation will get",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28175.0,
    "t_end": 28205.0,
    "text": "and audio analysis involves\nextracting useful information from the Your signals themselves\nvery well versed in maths and concept like Fourier\ntransformation will get you far in this one. These were the technical skills\nthat are required but be assured that there are a lot\nof non technical skills. Also that are required\nto land a good job in a machine learning industry. So first of all, you need to have\nan industry knowledge. So the most successful\nmachine learning projects out. There are going to be those\nthat address real pain points, don't you agree? So whichever industry\nare working for You should know",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28200.0,
    "t_end": 28230.0,
    "text": "There are going to be those\nthat address real pain points, don't you agree? So whichever industry\nare working for You should know how that industry works and what will be beneficial\nfor the industry. Now, if a machine\nlearning engineer does not have business Acumen\nand the know-how of the elements that make up\na successful business model. All those technical\nskills cannot be channeled productively. You won't be able\nto discern the problems and the potential challenges\nthat need solving for the business to sustain\nand grow the next on our list. We have effective communication\nand not this is one",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28225.0,
    "t_end": 28255.0,
    "text": "and the potential challenges\nthat need solving for the business to sustain\nand grow the next on our list. We have effective communication\nand not this is one of the most important parts\nin any job requirements. So you'll need to In machine\nlearning Concepts to people with little to no expertise\nin the field a chances are you will need to work\nwith a team of Engineers as well as many other\nteams like marketing and the sales team. So communication is going\nto make all of this much easier companies searching for the strong machine learning\nengineer looking for someone who can clearly and fluency\ntranslate technical findings",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28250.0,
    "t_end": 28280.0,
    "text": "easier companies searching for the strong machine learning\nengineer looking for someone who can clearly and fluency\ntranslate technical findings to a non technical team. Rapid prototyping\nis another skill, which is very much required for\nany machine learning engineer. So iterating on ideas as\nquickly as possible is mandatory for finding the one that works in machine learning\nthis applies to everything from picking the right model to working on projects\nsuch as a/b testing and much more now you\nneed to do a group",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28275.0,
    "t_end": 28305.0,
    "text": "from picking the right model to working on projects\nsuch as a/b testing and much more now you\nneed to do a group of techniques used to quickly\nfabricate a scale model of a physical part or assembly using the three-dimensional\ncomputer aided design, which is the cat data now coming\nto the final skills, which will be required for any machine learning agenda\nis to keep updated. So you must stay up to date\nwith any upcoming changes every month new neural\nnetwork models come out that outperformed\nthe previous architecture. It also means being aware of the\nnews regarding the development",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28300.0,
    "t_end": 28330.0,
    "text": "every month new neural\nnetwork models come out that outperformed\nthe previous architecture. It also means being aware of the\nnews regarding the development of the tools Theory and algorithms through research\npapers blocks conference videos and much more. Now another part of any machine\nlearning engineer's resume is the education qualification. So a bachelor's or master's degree in computer\nscience RIT economics statistics or even mathematics can help. Up you land a job\nin machine learning plus if you are an experienced\nmachine learning engineer,",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28325.0,
    "t_end": 28355.0,
    "text": "or even mathematics can help. Up you land a job\nin machine learning plus if you are an experienced\nmachine learning engineer, so probably some standard\ncompany certifications will help you a lot when Landing a good job\nin machine learning and finally coming\nto the professional experience. You need to have experience in\ncomputer science statistics data as is if you are switching from any other profession into\na machine learning engineer, or if you have a previous\nexperience in machine learning that is very well. Now finally if we talk\nabout The projects",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28350.0,
    "t_end": 28380.0,
    "text": "or if you have a previous\nexperience in machine learning that is very well. Now finally if we talk\nabout The projects so you need to have\nnot just any project that you have worked on you\nneed to have working on machine learning related projects that involve a\ncertain level of AI and working on neural networks\nto a certain degree to land a good job as\na machine-learning engineer. Now if you have a look\nat the company's hiring machine learning Engineers, so every other\ncompany is looking for machine learning Engineers",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28375.0,
    "t_end": 28405.0,
    "text": "Now if you have a look\nat the company's hiring machine learning Engineers, so every other\ncompany is looking for machine learning Engineers who can modify the existing\nmodel to something that did not need much more. Of Maintenance and cancel\nsustain so basically working on artificial intelligence\nand new algorithms that can work on their own is\nwhat every company deserves. So Amazon Facebook. We have Tech giants like Microsoft IBM again\nin the gaming industry, we have or the GPU\nindustry Graphics industry.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28400.0,
    "t_end": 28430.0,
    "text": "like Microsoft IBM again\nin the gaming industry, we have or the GPU\nindustry Graphics industry. We have Nvidia\nin banking industry. We have JPMorgan Chase again, we have LinkedIn\nand also we have Walmart. So all of these companies\nrequire machine learning engine at some part of the time. So be assured that if you are looking for a machine\nlearning engineer post, every other companies be it\na big shot company or even the new startups are looking\nfor machine learning Engineers. So be assured you will get\na job now with this we come to an end of this video.",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28425.0,
    "t_end": 28455.0,
    "text": "the new startups are looking\nfor machine learning Engineers. So be assured you will get\na job now with this we come to an end of this video. So I hope you've got\na good understanding of who exactly are\nmachine learning engineer is the way just job Trends\nthe salary Trends. What are the skills required to\nbecome machine learning engineer and once you become\na machine-learning engineer, what are the roles\nand responsibilities or the Job description what appears to be on the resume\nor the job description what appears to be on the job application of\nany machine learning engineers? And also I hope you got to know\nhow to prepare your resume",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28450.0,
    "t_end": 28480.0,
    "text": "what appears to be on the job application of\nany machine learning engineers? And also I hope you got to know\nhow to prepare your resume or how to prepare it\nin the correct format. And what on to keep their in the resume the career\nobjectives the skills Technical and non-technical previous experience\neducation qualification and certain projects which are related to it. So that's it guys Ed Rica as you know provides\na machine learning. Engineer master's program now\nthat is aligned in such a way that will get you acquainted\nin all the skills",
    "title": "YouTube:GwIo3gDZCVQ"
  },
  {
    "video_id": "GwIo3gDZCVQ",
    "t_start": 28475.0,
    "t_end": 28485.800000000003,
    "text": "as you know provides\na machine learning. Engineer master's program now\nthat is aligned in such a way that will get you acquainted\nin all the skills that are required\nto become a machine learning engine and that too\nin the correct form.",
    "title": "YouTube:GwIo3gDZCVQ"
  }
]